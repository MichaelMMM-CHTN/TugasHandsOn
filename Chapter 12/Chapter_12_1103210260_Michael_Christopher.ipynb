{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Chapter 12: Custom Models and Training with TensorFlow\n",
        "\n",
        "This notebook provides a comprehensive exploration of TensorFlow's lower-level API, including:\n",
        "- TensorFlow fundamentals and architecture\n",
        "- Custom loss functions, metrics, layers, and models\n",
        "- Automatic differentiation and gradient computation\n",
        "- Custom training loops\n",
        "- TensorFlow Functions and graph optimization\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this notebook, you will understand:\n",
        "1. TensorFlow's architecture and core components\n",
        "2. How to create custom components for deep learning models\n",
        "3. Mathematical foundations of automatic differentiation\n",
        "4. Implementation of custom training algorithms\n",
        "5. Graph optimization and TensorFlow Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## Setup and Imports\n",
        "\n",
        "First, let's set up our environment with the necessary imports and configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Install required packages for Google Colab\n",
        "# Attempting a different TensorFlow version for Python 3.11 compatibility\n",
        "!pip install -q tensorflow==2.16.1 tensorflow-probability matplotlib scikit-learn pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "main_imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446b84f4-d84a-4b00-fea8-816f0691cc9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.16.1\n",
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "GPU available: []\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Configure TensorFlow\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# Set matplotlib style\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "theory_intro"
      },
      "source": [
        "## 1. TensorFlow Architecture and Fundamentals\n",
        "\n",
        "### 1.1 Overview of TensorFlow\n",
        "\n",
        "TensorFlow is a powerful library for numerical computation, particularly well-suited for large-scale Machine Learning. According to the text, TensorFlow offers several key features:\n",
        "\n",
        "**Core Features:**\n",
        "1. **NumPy-like core with GPU support**: TensorFlow's core is similar to NumPy but can leverage GPU acceleration\n",
        "2. **Distributed computing**: Supports computation across multiple devices and servers\n",
        "3. **Just-in-time (JIT) compilation**: Optimizes computations for speed and memory usage\n",
        "4. **Portable computation graphs**: Can train in one environment and deploy in another\n",
        "5. **Automatic differentiation**: Implements autodiff with excellent optimizers\n",
        "\n",
        "### 1.2 TensorFlow Architecture\n",
        "\n",
        "The architecture follows a hierarchical structure:\n",
        "- **High-level APIs**: tf.keras, tf.data (95% of use cases)\n",
        "- **Low-level Python API**: Direct tensor manipulation\n",
        "- **C++ operations**: Highly efficient implementations\n",
        "- **Hardware**: CPU, GPU, and TPU kernels\n",
        "\n",
        "### 1.3 Mathematical Foundation\n",
        "\n",
        "TensorFlow operations work on tensors, which are multidimensional arrays. For a tensor $\\mathbf{T}$ with shape $(d_1, d_2, ..., d_n)$:\n",
        "\n",
        "$$\\mathbf{T} \\in \\mathbb{R}^{d_1 \\times d_2 \\times ... \\times d_n}$$\n",
        "\n",
        "Basic operations include:\n",
        "- **Element-wise operations**: $\\mathbf{C} = \\mathbf{A} \\odot \\mathbf{B}$ (where $\\odot$ represents element-wise multiplication)\n",
        "- **Matrix multiplication**: $\\mathbf{C} = \\mathbf{A} \\mathbf{B}$\n",
        "- **Reduction operations**: $s = \\sum_{i,j} \\mathbf{A}_{i,j}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "tensor_basics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6b57db-c97c-4dd4-888a-9b04536e3ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TensorFlow Tensor Operations ===\n",
            "Matrix shape: (2, 3)\n",
            "Matrix dtype: <dtype: 'float32'>\n",
            "Matrix:\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "\n",
            "Scalar: 42\n",
            "Vector: [1. 2. 3.]\n",
            "\n",
            "=== Basic Operations ===\n",
            "Matrix + 10:\n",
            "[[11. 12. 13.]\n",
            " [14. 15. 16.]]\n",
            "Matrix squared:\n",
            "[[ 1.  4.  9.]\n",
            " [16. 25. 36.]]\n",
            "Matrix transpose:\n",
            "[[1. 4.]\n",
            " [2. 5.]\n",
            " [3. 6.]]\n",
            "Matrix @ transpose:\n",
            "[[14. 32.]\n",
            " [32. 77.]]\n",
            "\n",
            "=== Indexing ===\n",
            "Matrix[:, 1:]:\n",
            "[[2. 3.]\n",
            " [5. 6.]]\n",
            "Matrix[..., 1, tf.newaxis]:\n",
            "[[2.]\n",
            " [5.]]\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate basic TensorFlow operations\n",
        "print(\"=== TensorFlow Tensor Operations ===\")\n",
        "\n",
        "# Create tensors\n",
        "matrix = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "scalar = tf.constant(42)\n",
        "vector = tf.constant([1., 2., 3.])\n",
        "\n",
        "print(f\"Matrix shape: {matrix.shape}\")\n",
        "print(f\"Matrix dtype: {matrix.dtype}\")\n",
        "print(f\"Matrix:\\n{matrix}\")\n",
        "\n",
        "print(f\"\\nScalar: {scalar}\")\n",
        "print(f\"Vector: {vector}\")\n",
        "\n",
        "# Basic operations\n",
        "print(\"\\n=== Basic Operations ===\")\n",
        "print(f\"Matrix + 10:\\n{matrix + 10}\")\n",
        "print(f\"Matrix squared:\\n{tf.square(matrix)}\")\n",
        "print(f\"Matrix transpose:\\n{tf.transpose(matrix)}\")\n",
        "print(f\"Matrix @ transpose:\\n{matrix @ tf.transpose(matrix)}\")\n",
        "\n",
        "# Indexing (similar to NumPy)\n",
        "print(\"\\n=== Indexing ===\")\n",
        "print(f\"Matrix[:, 1:]:\\n{matrix[:, 1:]}\")\n",
        "print(f\"Matrix[..., 1, tf.newaxis]:\\n{matrix[..., 1, tf.newaxis]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tensor_numpy"
      },
      "source": [
        "### 1.4 Tensors and NumPy Interoperability\n",
        "\n",
        "TensorFlow tensors integrate seamlessly with NumPy arrays. However, there are important precision considerations:\n",
        "\n",
        "- **NumPy default**: 64-bit precision\n",
        "- **TensorFlow default**: 32-bit precision (sufficient for neural networks, faster, uses less RAM)\n",
        "\n",
        "**Type Conversion Rules:**\n",
        "TensorFlow does not perform automatic type conversions to avoid performance issues. You must explicitly cast types when needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "numpy_interop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375a5d97-b4b0-4d08-a7b6-db4849dfff1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NumPy Interoperability ===\n",
            "NumPy array dtype: float64\n",
            "TensorFlow tensor dtype: <dtype: 'float64'>\n",
            "Back to NumPy dtype: float64\n",
            "\n",
            "=== Cross-library Operations ===\n",
            "TensorFlow operation on NumPy: [ 4. 16. 25.]\n",
            "NumPy operation on TensorFlow: [ 4. 16. 25.]\n",
            "\n",
            "=== Type Conversion ===\n",
            "Type mismatch error: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor...\n",
            "Correct casting result: 42.0\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate NumPy interoperability\n",
        "print(\"=== NumPy Interoperability ===\")\n",
        "\n",
        "# Create NumPy array\n",
        "numpy_array = np.array([2., 4., 5.])\n",
        "print(f\"NumPy array dtype: {numpy_array.dtype}\")\n",
        "\n",
        "# Convert to TensorFlow tensor\n",
        "tf_tensor = tf.constant(numpy_array)\n",
        "print(f\"TensorFlow tensor dtype: {tf_tensor.dtype}\")\n",
        "\n",
        "# Convert back to NumPy\n",
        "back_to_numpy = tf_tensor.numpy()\n",
        "print(f\"Back to NumPy dtype: {back_to_numpy.dtype}\")\n",
        "\n",
        "# Cross-library operations\n",
        "print(\"\\n=== Cross-library Operations ===\")\n",
        "print(f\"TensorFlow operation on NumPy: {tf.square(numpy_array)}\")\n",
        "print(f\"NumPy operation on TensorFlow: {np.square(tf_tensor)}\")\n",
        "\n",
        "# Type conversion demonstration\n",
        "print(\"\\n=== Type Conversion ===\")\n",
        "try:\n",
        "    # This will raise an error\n",
        "    result = tf.constant(2.) + tf.constant(40)\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "    print(f\"Type mismatch error: {str(e)[:100]}...\")\n",
        "\n",
        "# Correct way: explicit casting\n",
        "t2 = tf.constant(40., dtype=tf.float64)\n",
        "result = tf.constant(2.0) + tf.cast(t2, tf.float32)\n",
        "print(f\"Correct casting result: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "variables_theory"
      },
      "source": [
        "### 1.5 Variables\n",
        "\n",
        "Unlike regular tensors which are immutable, `tf.Variable` objects are mutable and designed for model parameters that need to be updated during training.\n",
        "\n",
        "**Mathematical Context:**\n",
        "In neural networks, we need to update weights $\\mathbf{W}$ and biases $\\mathbf{b}$ using gradient descent:\n",
        "\n",
        "$$\\mathbf{W}_{t+1} = \\mathbf{W}_t - \\eta \\nabla_{\\mathbf{W}} \\mathcal{L}$$\n",
        "$$\\mathbf{b}_{t+1} = \\mathbf{b}_t - \\eta \\nabla_{\\mathbf{b}} \\mathcal{L}$$\n",
        "\n",
        "where $\\eta$ is the learning rate and $\\mathcal{L}$ is the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "variables_demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d25cfdb-8f17-4720-9c01-5a74ec563c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TensorFlow Variables ===\n",
            "Original variable:\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[1., 2., 3.],\n",
            "       [4., 5., 6.]], dtype=float32)>\n",
            "Variable shape: (2, 3)\n",
            "Variable dtype: <dtype: 'float32'>\n",
            "\n",
            "Variable operations work like tensors:\n",
            "v * 2:\n",
            "[[ 2.  4.  6.]\n",
            " [ 8. 10. 12.]]\n",
            "tf.square(v):\n",
            "[[ 1.  4.  9.]\n",
            " [16. 25. 36.]]\n",
            "\n",
            "=== In-place Modifications ===\n",
            "After v.assign(2 * v):\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[ 2.,  4.,  6.],\n",
            "       [ 8., 10., 12.]], dtype=float32)>\n",
            "After v.assign_add(ones):\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[ 3.,  5.,  7.],\n",
            "       [ 9., 11., 13.]], dtype=float32)>\n",
            "After v[0, 1].assign(42):\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[ 3., 42.,  7.],\n",
            "       [ 9., 11., 13.]], dtype=float32)>\n",
            "After slice assignment:\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[ 3., 42.,  0.],\n",
            "       [ 9., 11.,  1.]], dtype=float32)>\n",
            "After scatter_nd_update:\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[100.,  42.,   0.],\n",
            "       [  9.,  11., 200.]], dtype=float32)>\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate TensorFlow Variables\n",
        "print(\"=== TensorFlow Variables ===\")\n",
        "\n",
        "# Create a variable\n",
        "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
        "print(f\"Original variable:\\n{v}\")\n",
        "print(f\"Variable shape: {v.shape}\")\n",
        "print(f\"Variable dtype: {v.dtype}\")\n",
        "\n",
        "# Variable operations (similar to tensors)\n",
        "print(f\"\\nVariable operations work like tensors:\")\n",
        "print(f\"v * 2:\\n{v * 2}\")\n",
        "print(f\"tf.square(v):\\n{tf.square(v)}\")\n",
        "\n",
        "# In-place modifications\n",
        "print(\"\\n=== In-place Modifications ===\")\n",
        "\n",
        "# assign() method\n",
        "v.assign(2 * v)\n",
        "print(f\"After v.assign(2 * v):\\n{v}\")\n",
        "\n",
        "# assign_add() and assign_sub()\n",
        "v.assign_add(tf.ones_like(v))\n",
        "print(f\"After v.assign_add(ones):\\n{v}\")\n",
        "\n",
        "# Individual cell assignment\n",
        "v[0, 1].assign(42)\n",
        "print(f\"After v[0, 1].assign(42):\\n{v}\")\n",
        "\n",
        "# Slice assignment\n",
        "v[:, 2].assign([0., 1.])\n",
        "print(f\"After slice assignment:\\n{v}\")\n",
        "\n",
        "# scatter_nd_update for multiple indices\n",
        "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])\n",
        "print(f\"After scatter_nd_update:\\n{v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_loss_theory"
      },
      "source": [
        "## 2. Custom Loss Functions\n",
        "\n",
        "### 2.1 Theory of Loss Functions\n",
        "\n",
        "Loss functions measure the difference between predicted and actual values. Common loss functions include:\n",
        "\n",
        "1. **Mean Squared Error (MSE)**: $\\mathcal{L}_{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
        "2. **Mean Absolute Error (MAE)**: $\\mathcal{L}_{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$\n",
        "3. **Huber Loss**: Combines MSE and MAE benefits\n",
        "\n",
        "### 2.2 Huber Loss Mathematical Foundation\n",
        "\n",
        "The Huber loss is defined as:\n",
        "\n",
        "$$\\mathcal{L}_{\\delta}(y, \\hat{y}) = \\begin{cases}\n",
        "\\frac{1}{2}(y - \\hat{y})^2 & \\text{if } |y - \\hat{y}| \\leq \\delta \\\\\n",
        "\\delta |y - \\hat{y}| - \\frac{1}{2}\\delta^2 & \\text{otherwise}\n",
        "\\end{cases}$$\n",
        "\n",
        "where $\\delta$ is the threshold parameter.\n",
        "\n",
        "**Benefits:**\n",
        "- **Small errors**: Behaves like MSE (differentiable, precise)\n",
        "- **Large errors**: Behaves like MAE (robust to outliers)\n",
        "- **Gradient**: $\\frac{\\partial \\mathcal{L}_{\\delta}}{\\partial \\hat{y}} = \\begin{cases} -(y - \\hat{y}) & \\text{if } |y - \\hat{y}| \\leq \\delta \\\\ -\\delta \\cdot \\text{sign}(y - \\hat{y}) & \\text{otherwise} \\end{cases}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "custom_loss_implementation",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "9b4a4388-4b66-4873-e8e6-6526ac17365f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Huber Loss Demonstration ===\n",
            "Close predictions:\n",
            "MSE: 0.0220, MAE: 0.1400, Huber: 0.0110\n",
            "\n",
            "Predictions with outliers:\n",
            "MSE: 7.2100, MAE: 2.0600, Huber: 1.7050\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Implement custom Huber loss function\n",
        "def huber_fn(y_true, y_pred, threshold=1.0):\n",
        "    \"\"\"\n",
        "    Huber loss function implementation.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels\n",
        "        y_pred: Predicted values\n",
        "        threshold: Threshold for switching between squared and linear loss\n",
        "\n",
        "    Returns:\n",
        "        Huber loss for each sample\n",
        "    \"\"\"\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < threshold\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "# Demonstrate the Huber loss\n",
        "print(\"=== Huber Loss Demonstration ===\")\n",
        "\n",
        "# Create sample data\n",
        "y_true = tf.constant([1., 2., 3., 4., 5.])\n",
        "y_pred_close = tf.constant([1.1, 2.2, 2.9, 4.1, 4.8])  # Close predictions\n",
        "y_pred_far = tf.constant([1.1, 2.2, 5.0, 8.0, 1.0])   # Some outliers\n",
        "\n",
        "# Compare different loss functions\n",
        "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "mae_loss_fn = tf.keras.losses.MeanAbsoluteError()\n",
        "\n",
        "mse_close = mse_loss_fn(y_true, y_pred_close)\n",
        "mae_close = mae_loss_fn(y_true, y_pred_close)\n",
        "huber_close = tf.reduce_mean(huber_fn(y_true, y_pred_close))\n",
        "\n",
        "mse_far = mse_loss_fn(y_true, y_pred_far)\n",
        "mae_far = mae_loss_fn(y_true, y_pred_far)\n",
        "huber_far = tf.reduce_mean(huber_fn(y_true, y_pred_far))\n",
        "\n",
        "print(\"Close predictions:\")\n",
        "print(f\"MSE: {mse_close:.4f}, MAE: {mae_close:.4f}, Huber: {huber_close:.4f}\")\n",
        "\n",
        "print(\"\\nPredictions with outliers:\")\n",
        "print(f\"MSE: {mse_far:.4f}, MAE: {mae_far:.4f}, Huber: {huber_far:.4f}\")\n",
        "\n",
        "# Visualize loss functions\n",
        "errors = tf.linspace(-3., 3., 100)\n",
        "mse_losses = tf.square(errors)\n",
        "mae_losses = tf.abs(errors)\n",
        "huber_losses = [huber_fn(0., -error, threshold=1.0) for error in errors]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(errors, mse_losses, label='MSE', linewidth=2)\n",
        "plt.plot(errors, mae_losses, label='MAE', linewidth=2)\n",
        "plt.plot(errors, huber_losses, label='Huber (=1)', linewidth=2)\n",
        "plt.xlabel('Error (y_true - y_pred)')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Comparison of Loss Functions')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlim(-3, 3)\n",
        "plt.ylim(0, 5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_loss_class"
      },
      "source": [
        "### 2.3 Custom Loss Class Implementation\n",
        "\n",
        "For more complex loss functions that need to save hyperparameters, we can subclass `keras.losses.Loss`. This ensures proper serialization and deserialization of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "huber_loss_class",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a8a99b-cbd6-475d-9d61-f470b1b51f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Custom Huber Loss Class ===\n",
            "Huber loss values: 1.1483333110809326\n",
            "Mean Huber loss: 1.1483333110809326\n",
            "\n",
            "Loss configuration: {'name': 'huber_loss_3', 'reduction': 'sum_over_batch_size', 'threshold': 2.0}\n",
            "Recreated loss threshold: 2.0\n"
          ]
        }
      ],
      "source": [
        "class HuberLoss(tf.keras.losses.Loss):\n",
        "    \"\"\"\n",
        "    Custom Huber Loss class that can be saved with the model.\n",
        "\n",
        "    The Huber loss is less sensitive to outliers than MSE.\n",
        "    It's quadratic for small errors and linear for large errors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize Huber loss.\n",
        "\n",
        "        Args:\n",
        "            threshold: Point where the loss changes from quadratic to linear\n",
        "            **kwargs: Additional arguments passed to parent class\n",
        "        \"\"\"\n",
        "        self.threshold = threshold\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Compute the Huber loss.\n",
        "\n",
        "        Args:\n",
        "            y_true: Ground truth values\n",
        "            y_pred: Predicted values\n",
        "\n",
        "        Returns:\n",
        "            Huber loss for each sample\n",
        "        \"\"\"\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < self.threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Return configuration for serialization.\n",
        "        \"\"\"\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}\n",
        "\n",
        "# Test the custom loss class\n",
        "print(\"=== Custom Huber Loss Class ===\")\n",
        "\n",
        "# Create instance\n",
        "huber_loss = HuberLoss(threshold=2.0)\n",
        "\n",
        "# Test with sample data\n",
        "y_true = tf.constant([[1.], [2.], [3.]])\n",
        "y_pred = tf.constant([[1.5], [2.8], [0.5]])\n",
        "\n",
        "loss_value = huber_loss(y_true, y_pred)\n",
        "print(f\"Huber loss values: {loss_value}\")\n",
        "print(f\"Mean Huber loss: {tf.reduce_mean(loss_value)}\")\n",
        "\n",
        "# Test configuration saving/loading\n",
        "config = huber_loss.get_config()\n",
        "print(f\"\\nLoss configuration: {config}\")\n",
        "\n",
        "# Create new instance from config\n",
        "huber_loss_2 = HuberLoss.from_config(config)\n",
        "print(f\"Recreated loss threshold: {huber_loss_2.threshold}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_metrics_theory"
      },
      "source": [
        "## 3. Custom Metrics\n",
        "\n",
        "### 3.1 Difference Between Losses and Metrics\n",
        "\n",
        "**Losses vs Metrics:**\n",
        "- **Losses**: Used for optimization, must be differentiable, gradients should not be zero everywhere\n",
        "- **Metrics**: Used for evaluation, should be interpretable, can be non-differentiable\n",
        "\n",
        "### 3.2 Streaming Metrics\n",
        "\n",
        "Some metrics cannot be simply averaged across batches. For example, precision:\n",
        "\n",
        "$$\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}$$\n",
        "\n",
        "**Problem with naive averaging:**\n",
        "- Batch 1: 4/5 = 80% precision\n",
        "- Batch 2: 0/3 = 0% precision\n",
        "- Naive average: (80% + 0%) / 2 = 40%\n",
        "- Correct overall: 4/(5+3) = 50%\n",
        "\n",
        "**Solution:** Streaming metrics maintain state across batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "streaming_metrics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f26fbd-80be-42a0-bd4c-c2d5ff990cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Streaming Metrics Demonstration ===\n",
            "After batch 1 - Precision: 0.800\n",
            "Variables: TP=4, FP=1\n",
            "After batch 2 - Precision: 0.500\n",
            "Variables: TP=4, FP=4\n",
            "\n",
            "Manual calculation: 4/8 = 0.500\n",
            "Streaming metric result: 0.500\n",
            "Naive average would be: 0.400\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate streaming metrics\n",
        "print(\"=== Streaming Metrics Demonstration ===\")\n",
        "\n",
        "# Create a streaming precision metric\n",
        "precision = tf.keras.metrics.Precision()\n",
        "\n",
        "# Simulate the problematic case\n",
        "# Batch 1: 5 positive predictions, 4 correct (80% precision)\n",
        "y_true_1 = tf.constant([0, 1, 1, 1, 0, 1, 0, 1], dtype=tf.float32) # Ensure float32 dtype\n",
        "y_pred_1 = tf.constant([1, 1, 0, 1, 0, 1, 0, 1], dtype=tf.float32)  # 5 positive predictions, 4 correct\n",
        "\n",
        "precision_1 = precision(y_true_1, y_pred_1)\n",
        "print(f\"After batch 1 - Precision: {precision_1:.3f}\")\n",
        "print(f\"Variables: TP={precision.true_positives.numpy()[0]:.0f}, FP={precision.false_positives.numpy()[0]:.0f}\") # Access scalar values\n",
        "\n",
        "# Batch 2: 3 positive predictions, 0 correct (0% precision)\n",
        "y_true_2 = tf.constant([0, 1, 0, 0, 1, 0, 1, 1], dtype=tf.float32) # Ensure float32 dtype\n",
        "y_pred_2 = tf.constant([1, 0, 1, 1, 0, 0, 0, 0], dtype=tf.float32)  # 3 positive predictions, 0 correct\n",
        "\n",
        "precision_2 = precision(y_true_2, y_pred_2)\n",
        "print(f\"After batch 2 - Precision: {precision_2:.3f}\")\n",
        "print(f\"Variables: TP={precision.true_positives.numpy()[0]:.0f}, FP={precision.false_positives.numpy()[0]:.0f}\") # Access scalar values\n",
        "\n",
        "# Show that the result is the correct overall precision\n",
        "total_tp = precision.true_positives.numpy()[0] # Extract scalar\n",
        "total_fp = precision.false_positives.numpy()[0] # Extract scalar\n",
        "manual_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0 # Handle division by zero\n",
        "print(f\"\\nManual calculation: {total_tp:.0f}/{total_tp + total_fp:.0f} = {manual_precision:.3f}\") # Format scalar values\n",
        "print(f\"Streaming metric result: {precision_2:.3f}\")\n",
        "print(f\"Naive average would be: {(0.8 + 0.0) / 2:.3f}\")\n",
        "\n",
        "# Reset the metric\n",
        "# precision.reset_states() # Call the reset_states method - Commented out due to AttributeError in TF 2.16.1\n",
        "# print(f\"\\nAfter reset: TP={precision.true_positives.numpy()[0]:.0f}, FP={precision.false_positives.numpy()[0]:.0f}\") # Access scalar values - Commented out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "custom_streaming_metric",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c33f22-de99-41ed-ccda-f516b18f8c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Custom Streaming Metric Test ===\n",
            "After batch 1: 0.0466\n",
            "After batch 2: 0.0699\n",
            "After batch 3: 0.0904\n",
            "Final metric variables: total=2.7118, count=30.0\n",
            "After reset: nan\n"
          ]
        }
      ],
      "source": [
        "class HuberMetric(tf.keras.metrics.Metric):\n",
        "    \"\"\"\n",
        "    Custom streaming metric for Huber loss.\n",
        "\n",
        "    This metric accumulates the total Huber loss and count across batches\n",
        "    to compute the mean Huber loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, threshold=1.0, name='huber_metric', **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the Huber metric.\n",
        "Args:\n",
        "            threshold: Threshold for Huber loss calculation\n",
        "            name: Name of the metric\n",
        "        \"\"\"\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.threshold = threshold\n",
        "\n",
        "        # Create variables to track total loss and count\n",
        "        self.total = self.add_weight(name=\"total\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        \"\"\"\n",
        "        Update metric state with a batch of data.\n",
        "\n",
        "        Args:\n",
        "            y_true: True labels\n",
        "            y_pred: Predicted values\n",
        "            sample_weight: Optional sample weights\n",
        "        \"\"\"\n",
        "        # Compute Huber loss for this batch\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < self.threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
        "        huber_loss = tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "        # Update total and count\n",
        "        self.total.assign_add(tf.reduce_sum(huber_loss))\n",
        "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        \"\"\"\n",
        "        Compute the final metric result.\n",
        "\n",
        "        Returns:\n",
        "            Mean Huber loss across all batches\n",
        "        \"\"\"\n",
        "        return self.total / self.count\n",
        "\n",
        "    def reset_states(self):\n",
        "        \"\"\"\n",
        "        Reset all metric variables.\n",
        "        \"\"\"\n",
        "        self.total.assign(0.0)\n",
        "        self.count.assign(0.0)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Return configuration for serialization.\n",
        "        \"\"\"\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}\n",
        "\n",
        "# Test the custom streaming metric\n",
        "print(\"=== Custom Streaming Metric Test ===\")\n",
        "\n",
        "huber_metric = HuberMetric(threshold=1.5)\n",
        "\n",
        "# Simulate multiple batches\n",
        "for i in range(3):\n",
        "    y_true = tf.random.normal((10, 1))\n",
        "    y_pred = y_true + tf.random.normal((10, 1), stddev=0.5)\n",
        "\n",
        "    huber_metric.update_state(y_true, y_pred)\n",
        "    print(f\"After batch {i+1}: {huber_metric.result():.4f}\")\n",
        "\n",
        "print(f\"Final metric variables: total={huber_metric.total.numpy():.4f}, count={huber_metric.count.numpy()}\")\n",
        "\n",
        "# Reset and verify\n",
        "huber_metric.reset_states()\n",
        "print(f\"After reset: {huber_metric.result():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_layers_theory"
      },
      "source": [
        "## 4. Custom Layers\n",
        "\n",
        "### 4.1 Theory of Neural Network Layers\n",
        "\n",
        "A neural network layer performs a transformation:\n",
        "$$\\mathbf{y} = f(\\mathbf{x}; \\boldsymbol{\\theta})$$\n",
        "\n",
        "where:\n",
        "- $\\mathbf{x}$ is the input\n",
        "- $\\mathbf{y}$ is the output\n",
        "- $\\boldsymbol{\\theta}$ represents the layer's parameters (weights and biases)\n",
        "- $f$ is the layer's function\n",
        "\n",
        "### 4.2 Dense Layer Mathematical Foundation\n",
        "\n",
        "For a dense (fully connected) layer:\n",
        "$$\\mathbf{y} = \\sigma(\\mathbf{x} \\mathbf{W} + \\mathbf{b})$$\n",
        "\n",
        "where:\n",
        "- $\\mathbf{W} \\in \\mathbb{R}^{n_{in} \\times n_{out}}$ is the weight matrix\n",
        "- $\\mathbf{b} \\in \\mathbb{R}^{n_{out}}$ is the bias vector\n",
        "- $\\sigma$ is the activation function\n",
        "- $n_{in}$ is the number of input features\n",
        "- $n_{out}$ is the number of output features\n",
        "\n",
        "### 4.3 Types of Custom Layers\n",
        "\n",
        "1. **Stateless layers**: No trainable parameters (e.g., activation functions)\n",
        "2. **Stateful layers**: Have trainable parameters (e.g., Dense, Conv2D)\n",
        "3. **Dynamic layers**: Behavior changes during training vs inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "simple_custom_layer",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "2c127aea-c2bf-476e-a0e0-f4ef56311534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Stateless Custom Layer ===\n",
            "Input: [[1. 2. 3.]]\n",
            "Exponential output: [[ 2.7182817  7.389056  20.085537 ]]\n",
            "Manual verification: [[ 2.7182817  7.389056  20.085537 ]]\n",
            "\n",
            "Model with custom activation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_42 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                          \u001b[38;5;34m20\u001b[0m \n",
              "\n",
              " lambda_5 (\u001b[38;5;33mLambda\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_43 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                           \u001b[38;5;34m6\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> \n",
              "\n",
              " lambda_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26\u001b[0m (104.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> (104.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26\u001b[0m (104.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> (104.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# Simple stateless custom layer using Lambda\n",
        "print(\"=== Stateless Custom Layer ===\")\n",
        "\n",
        "# Create an exponential layer\n",
        "exponential_layer = tf.keras.layers.Lambda(lambda x: tf.exp(x))\n",
        "\n",
        "# Test the layer\n",
        "test_input = tf.constant([[1.0, 2.0, 3.0]])\n",
        "output = exponential_layer(test_input)\n",
        "print(f\"Input: {test_input}\")\n",
        "print(f\"Exponential output: {output}\")\n",
        "print(f\"Manual verification: {tf.exp(test_input)}\")\n",
        "\n",
        "# Alternative: direct function usage\n",
        "def exponential_activation(x):\n",
        "    \"\"\"Custom exponential activation function.\"\"\"\n",
        "    return tf.exp(x)\n",
        "\n",
        "# Create a simple model with custom activation\n",
        "model_with_custom_activation = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, input_shape=(3,)),\n",
        "    tf.keras.layers.Lambda(exponential_activation),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "print(f\"\\nModel with custom activation:\")\n",
        "print(model_with_custom_activation.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "custom_dense_layer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637ed94f-2f03-4520-fe16-07ec51992977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Custom Dense Layer Test ===\n",
            "Input shape: (5, 3)\n",
            "Output shape: (5, 4)\n",
            "Output:\n",
            "[[0.         0.         0.06277205 0.07777292]\n",
            " [0.         1.1126729  0.         0.        ]\n",
            " [0.7243442  0.         0.         0.6176762 ]\n",
            " [0.7547236  0.7969121  0.         0.        ]\n",
            " [0.19377469 0.         0.05350849 0.3102726 ]]\n",
            "\n",
            "Kernel shape: (3, 4)\n",
            "Bias shape: (4,)\n",
            "Number of trainable variables: 2\n",
            "\n",
            "Keras Dense output shape: (5, 4)\n",
            "Shapes match: True\n"
          ]
        }
      ],
      "source": [
        "class MyDense(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom implementation of a Dense layer.\n",
        "\n",
        "    This demonstrates how to create stateful layers with trainable parameters.\n",
        "    Mathematical operation: output = activation(input @ kernel + bias)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the custom dense layer.\n",
        "\n",
        "        Args:\n",
        "            units: Number of output units\n",
        "            activation: Activation function\n",
        "            **kwargs: Additional arguments for parent class\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        \"\"\"\n",
        "        Create the layer's weights.\n",
        "\n",
        "        Args:\n",
        "            batch_input_shape: Shape of input including batch dimension\n",
        "        \"\"\"\n",
        "        # Kernel weight matrix: [input_dim, units]\n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\",\n",
        "            shape=[batch_input_shape[-1], self.units],\n",
        "            initializer=\"glorot_normal\",  # Xavier initialization\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        # Bias vector: [units]\n",
        "        self.bias = self.add_weight(\n",
        "            name=\"bias\",\n",
        "            shape=[self.units],\n",
        "            initializer=\"zeros\",\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        # Must call parent build at the end\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass computation.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input tensor\n",
        "\n",
        "        Returns:\n",
        "            Output tensor after linear transformation and activation\n",
        "        \"\"\"\n",
        "        # Linear transformation: X @ W + b\n",
        "        linear_output = tf.matmul(inputs, self.kernel) + self.bias\n",
        "\n",
        "        # Apply activation function\n",
        "        return self.activation(linear_output)\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        \"\"\"\n",
        "        Compute output shape given input shape.\n",
        "\n",
        "        Args:\n",
        "            batch_input_shape: Input shape including batch dimension\n",
        "\n",
        "        Returns:\n",
        "            Output shape\n",
        "        \"\"\"\n",
        "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Return layer configuration for serialization.\n",
        "        \"\"\"\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"units\": self.units,\n",
        "            \"activation\": tf.keras.activations.serialize(self.activation)\n",
        "        }\n",
        "\n",
        "# Test the custom Dense layer\n",
        "print(\"=== Custom Dense Layer Test ===\")\n",
        "\n",
        "# Create test data\n",
        "X_test = tf.random.normal((5, 3))  # 5 samples, 3 features\n",
        "print(f\"Input shape: {X_test.shape}\")\n",
        "\n",
        "# Create custom layer\n",
        "custom_dense = MyDense(units=4, activation='relu')\n",
        "\n",
        "# Forward pass\n",
        "output = custom_dense(X_test)\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Output:\\n{output}\")\n",
        "\n",
        "# Check weights\n",
        "print(f\"\\nKernel shape: {custom_dense.kernel.shape}\")\n",
        "print(f\"Bias shape: {custom_dense.bias.shape}\")\n",
        "print(f\"Number of trainable variables: {len(custom_dense.trainable_variables)}\")\n",
        "\n",
        "# Compare with standard Keras Dense layer\n",
        "keras_dense = tf.keras.layers.Dense(units=4, activation='relu')\n",
        "keras_output = keras_dense(X_test)\n",
        "print(f\"\\nKeras Dense output shape: {keras_output.shape}\")\n",
        "print(f\"Shapes match: {output.shape == keras_output.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "multi_input_output_layer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0269ec-a4d2-4ba9-83b7-eb266a50f041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Multi-Input/Output Layer Test ===\n",
            "Input 1:\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "Input 2:\n",
            "[[2. 1. 2.]\n",
            " [1. 3. 2.]]\n",
            "\n",
            "Output 1 (Sum):\n",
            "[[3. 3. 5.]\n",
            " [5. 8. 8.]]\n",
            "Output 2 (Product):\n",
            "[[ 2.  2.  6.]\n",
            " [ 4. 15. 12.]]\n",
            "Output 3 (Division):\n",
            "[[0.5       1.9999998 1.5      ]\n",
            " [3.9999995 1.6666666 3.       ]]\n",
            "\n",
            "Manual verification:\n",
            "Sum: [[3. 3. 5.]\n",
            " [5. 8. 8.]]\n",
            "Product: [[ 2.  2.  6.]\n",
            " [ 4. 15. 12.]]\n",
            "Division: [[0.5       1.9999998 1.5      ]\n",
            " [3.9999995 1.6666666 3.       ]]\n"
          ]
        }
      ],
      "source": [
        "class MyMultiLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom layer with multiple inputs and outputs.\n",
        "\n",
        "    This layer takes two inputs and produces three outputs:\n",
        "    - Sum of inputs\n",
        "    - Element-wise product of inputs\n",
        "    - Element-wise division of first by second input\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass with multiple inputs and outputs.\n",
        "\n",
        "        Args:\n",
        "            inputs: Tuple of (input1, input2)\n",
        "\n",
        "        Returns:\n",
        "            List of [sum, product, division] outputs\n",
        "        \"\"\"\n",
        "        X1, X2 = inputs\n",
        "        return [\n",
        "            X1 + X2,                    # Sum\n",
        "            X1 * X2,                    # Element-wise product\n",
        "            X1 / (X2 + 1e-7)           # Division with small epsilon\n",
        "        ]\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        \"\"\"\n",
        "        Compute output shapes for multiple outputs.\n",
        "\n",
        "        Args:\n",
        "            batch_input_shape: Tuple of input shapes\n",
        "\n",
        "        Returns:\n",
        "            List of output shapes\n",
        "        \"\"\"\n",
        "        b1, b2 = batch_input_shape\n",
        "        # All outputs have the same shape as the first input\n",
        "        return [b1, b1, b1]\n",
        "\n",
        "# Test multi-input/output layer\n",
        "print(\"=== Multi-Input/Output Layer Test ===\")\n",
        "\n",
        "# Create test inputs\n",
        "input1 = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "input2 = tf.constant([[2., 1., 2.], [1., 3., 2.]])\n",
        "\n",
        "print(f\"Input 1:\\n{input1}\")\n",
        "print(f\"Input 2:\\n{input2}\")\n",
        "\n",
        "# Apply custom layer\n",
        "multi_layer = MyMultiLayer()\n",
        "outputs = multi_layer([input1, input2])\n",
        "\n",
        "print(f\"\\nOutput 1 (Sum):\\n{outputs[0]}\")\n",
        "print(f\"Output 2 (Product):\\n{outputs[1]}\")\n",
        "print(f\"Output 3 (Division):\\n{outputs[2]}\")\n",
        "\n",
        "# Verify calculations manually\n",
        "print(f\"\\nManual verification:\")\n",
        "print(f\"Sum: {input1 + input2}\")\n",
        "print(f\"Product: {input1 * input2}\")\n",
        "print(f\"Division: {input1 / (input2 + 1e-7)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "gaussian_noise_layer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebb2407-2a5d-4519-c580-66ce2811c56d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Gaussian Noise Layer Test ===\n",
            "Original input:\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "\n",
            "With noise (training=True):\n",
            "[[1.1144209 1.8391021 2.8652778]\n",
            " [3.9383066 5.0845466 6.015746 ]]\n",
            "Noise added: [[ 0.11442089 -0.16089785 -0.13472223]\n",
            " [-0.06169343  0.08454657  0.01574612]]\n",
            "\n",
            "Without noise (training=False):\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "Same as input: True\n",
            "\n",
            "Second noisy output:\n",
            "[[0.8411654 2.080656  2.9700024]\n",
            " [3.9438875 4.994624  6.0803585]]\n",
            "Different noise: True\n"
          ]
        }
      ],
      "source": [
        "class MyGaussianNoise(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom Gaussian noise layer for regularization.\n",
        "\n",
        "    Adds Gaussian noise during training but does nothing during inference.\n",
        "    This helps prevent overfitting by adding stochasticity to the inputs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, stddev, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize Gaussian noise layer.\n",
        "\n",
        "        Args:\n",
        "            stddev: Standard deviation of the noise\n",
        "            **kwargs: Additional arguments for parent class\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"\n",
        "        Forward pass with conditional noise addition.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input tensor\n",
        "            training: Boolean indicating training vs inference mode\n",
        "\n",
        "        Returns:\n",
        "            Noisy inputs during training, clean inputs during inference\n",
        "        \"\"\"\n",
        "        if training:\n",
        "            # Add Gaussian noise during training\n",
        "            noise = tf.random.normal(\n",
        "                shape=tf.shape(inputs),\n",
        "                stddev=self.stddev,\n",
        "                dtype=inputs.dtype\n",
        "            )\n",
        "            return inputs + noise\n",
        "        else:\n",
        "            # Return inputs unchanged during inference\n",
        "            return inputs\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        \"\"\"\n",
        "        Output shape is the same as input shape.\n",
        "        \"\"\"\n",
        "        return batch_input_shape\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Return configuration for serialization.\n",
        "        \"\"\"\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"stddev\": self.stddev}\n",
        "\n",
        "# Test Gaussian noise layer\n",
        "print(\"=== Gaussian Noise Layer Test ===\")\n",
        "\n",
        "# Create test input\n",
        "test_input = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "print(f\"Original input:\\n{test_input}\")\n",
        "\n",
        "# Create noise layer\n",
        "noise_layer = MyGaussianNoise(stddev=0.1)\n",
        "\n",
        "# Test in training mode\n",
        "noisy_output = noise_layer(test_input, training=True)\n",
        "print(f\"\\nWith noise (training=True):\\n{noisy_output}\")\n",
        "print(f\"Noise added: {noisy_output - test_input}\")\n",
        "\n",
        "# Test in inference mode\n",
        "clean_output = noise_layer(test_input, training=False)\n",
        "print(f\"\\nWithout noise (training=False):\\n{clean_output}\")\n",
        "print(f\"Same as input: {tf.reduce_all(tf.equal(clean_output, test_input))}\")\n",
        "\n",
        "# Test multiple calls in training mode (should produce different noise)\n",
        "noisy_output_2 = noise_layer(test_input, training=True)\n",
        "print(f\"\\nSecond noisy output:\\n{noisy_output_2}\")\n",
        "print(f\"Different noise: {not tf.reduce_all(tf.equal(noisy_output, noisy_output_2))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_models_theory"
      },
      "source": [
        "## 5. Custom Models\n",
        "\n",
        "### 5.1 Model vs Layer Distinction\n",
        "\n",
        "**Models** provide additional functionality beyond layers:\n",
        "- `compile()`, `fit()`, `evaluate()`, `predict()` methods\n",
        "- `save()` and loading capabilities\n",
        "- `get_layers()` method\n",
        "- Model cloning support\n",
        "\n",
        "**Design Principle:**\n",
        "- **Layers**: Internal components and reusable blocks\n",
        "- **Models**: Complete architectures ready for training\n",
        "\n",
        "### 5.2 Residual Connections Theory\n",
        "\n",
        "Residual connections help with:\n",
        "1. **Gradient flow**: Prevent vanishing gradients\n",
        "2. **Identity mapping**: Allow layers to learn deviations from identity\n",
        "3. **Deep networks**: Enable training of very deep architectures\n",
        "\n",
        "**Mathematical formulation:**\n",
        "$$\\mathbf{y} = \\mathcal{F}(\\mathbf{x}) + \\mathbf{x}$$\n",
        "\n",
        "where $\\mathcal{F}(\\mathbf{x})$ is the residual function and $\\mathbf{x}$ is the identity shortcut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "residual_block",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "865016e6-7599-462c-f9f9-93fdfd320a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Residual Block Test ===\n",
            "Input shape: (4, 30)\n",
            "Output shape: (4, 30)\n",
            "Output equals input: False\n",
            "Mean absolute difference: 0.9256\n",
            "Number of trainable variables: 4\n",
            "Total parameters: 1860\n"
          ]
        }
      ],
      "source": [
        "class ResidualBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Residual block implementation.\n",
        "\n",
        "    A residual block consists of multiple layers with a skip connection\n",
        "    that adds the input to the output: output = F(x) + x\n",
        "\n",
        "    This helps with gradient flow and enables training deeper networks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize residual block.\n",
        "\n",
        "        Args:\n",
        "            n_layers: Number of hidden layers in the block\n",
        "            n_neurons: Number of neurons per layer\n",
        "            **kwargs: Additional arguments for parent class\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Create the hidden layers\n",
        "        self.hidden = [\n",
        "            tf.keras.layers.Dense(\n",
        "                n_neurons,\n",
        "                activation=\"elu\",\n",
        "                kernel_initializer=\"he_normal\"\n",
        "            )\n",
        "            for _ in range(n_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass through residual block.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input tensor\n",
        "\n",
        "        Returns:\n",
        "            Output tensor with residual connection: F(x) + x\n",
        "        \"\"\"\n",
        "        Z = inputs\n",
        "\n",
        "        # Pass through all hidden layers\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "\n",
        "        # Add residual connection (skip connection)\n",
        "        return inputs + Z\n",
        "\n",
        "# Test residual block\n",
        "print(\"=== Residual Block Test ===\")\n",
        "\n",
        "# Create test input\n",
        "test_input = tf.random.normal((4, 30))  # Batch of 4, 30 features\n",
        "print(f\"Input shape: {test_input.shape}\")\n",
        "\n",
        "# Create residual block\n",
        "residual_block = ResidualBlock(n_layers=2, n_neurons=30)\n",
        "\n",
        "# Forward pass\n",
        "output = residual_block(test_input)\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "\n",
        "# Verify residual connection\n",
        "# The output should be different from input due to the learned transformation\n",
        "print(f\"Output equals input: {tf.reduce_all(tf.equal(output, test_input))}\")\n",
        "print(f\"Mean absolute difference: {tf.reduce_mean(tf.abs(output - test_input)):.4f}\")\n",
        "\n",
        "# Check that block has trainable parameters\n",
        "print(f\"Number of trainable variables: {len(residual_block.trainable_variables)}\")\n",
        "print(f\"Total parameters: {sum(tf.size(var) for var in residual_block.trainable_variables)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "custom_model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f5f67a-4bfb-461d-f73c-ec79092698fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Custom Residual Model Test ===\n",
            "Input shape: (10, 8)\n",
            "Predictions shape: (10, 1)\n",
            "Sample predictions: [ 5.7834334 -8.270904  18.611135   3.4524736 10.936957 ]\n",
            "\n",
            "Model summary:\n",
            "Total trainable parameters: 4021\n",
            "\n",
            "Model layers:\n",
            " 0: dense_47 - Dense\n",
            " 1: residual_block_7 - ResidualBlock\n",
            " 2: residual_block_8 - ResidualBlock\n",
            " 3: dense_52 - Dense\n"
          ]
        }
      ],
      "source": [
        "class ResidualRegressor(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Custom model with residual connections.\n",
        "\n",
        "    Architecture:\n",
        "    Input -> Dense -> ResidualBlock (4x) -> ResidualBlock -> Dense -> Output\n",
        "\n",
        "    This model demonstrates:\n",
        "    - Custom model architecture\n",
        "    - Reusable residual blocks\n",
        "    - Loop structures in model definition\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the residual regressor.\n",
        "\n",
        "        Args:\n",
        "            output_dim: Number of output units\n",
        "            **kwargs: Additional arguments for parent class\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Define layers\n",
        "        self.hidden1 = tf.keras.layers.Dense(\n",
        "            30, activation=\"elu\", kernel_initializer=\"he_normal\"\n",
        "        )\n",
        "        self.block1 = ResidualBlock(2, 30)  # First residual block\n",
        "        self.block2 = ResidualBlock(2, 30)  # Second residual block\n",
        "        self.out = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass through the model.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input tensor\n",
        "\n",
        "        Returns:\n",
        "            Model predictions\n",
        "        \"\"\"\n",
        "        # Initial transformation\n",
        "        Z = self.hidden1(inputs)\n",
        "\n",
        "        # Pass through first block multiple times\n",
        "        for _ in range(1 + 3):  # 4 times total\n",
        "            Z = self.block1(Z)\n",
        "\n",
        "        # Pass through second block\n",
        "        Z = self.block2(Z)\n",
        "\n",
        "        # Final output\n",
        "        return self.out(Z)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Return model configuration for serialization.\n",
        "        \"\"\"\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"output_dim\": self.out.units}\n",
        "\n",
        "# Test custom model\n",
        "print(\"=== Custom Residual Model Test ===\")\n",
        "\n",
        "# Create sample data for testing\n",
        "X_sample = tf.random.normal((10, 8))  # 10 samples, 8 features\n",
        "print(f\"Input shape: {X_sample.shape}\")\n",
        "\n",
        "# Create model\n",
        "model = ResidualRegressor(output_dim=1)\n",
        "\n",
        "# Forward pass\n",
        "predictions = model(X_sample)\n",
        "print(f\"Predictions shape: {predictions.shape}\")\n",
        "print(f\"Sample predictions: {predictions[:5].numpy().flatten()}\")\n",
        "\n",
        "# Model summary (build the model first)\n",
        "model.build(input_shape=(None, 8))\n",
        "print(f\"\\nModel summary:\")\n",
        "print(f\"Total trainable parameters: {model.count_params()}\")\n",
        "\n",
        "# Check model structure\n",
        "print(f\"\\nModel layers:\")\n",
        "for i, layer in enumerate(model.layers):\n",
        "    print(f\" {i}: {layer.name} - {type(layer).__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_internals_theory"
      },
      "source": [
        "### 5.3 Models with Internal Losses\n",
        "\n",
        "Sometimes we need losses based on model internals for regularization or auxiliary tasks. The reconstruction loss is an example:\n",
        "\n",
        "$\\mathcal{L}_{reconstruction} = \\frac{1}{n} \\sum_{i=1}^{n} ||\\mathbf{x}_i - \\hat{\\mathbf{x}}_i||^2$\n",
        "\n",
        "where $\\hat{\\mathbf{x}}_i$ is the reconstructed input from hidden representations.\n",
        "\n",
        "**Benefits:**\n",
        "- Encourages information preservation through hidden layers\n",
        "- Acts as regularization\n",
        "- Can improve generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "reconstructing_model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e8870f-afbc-4746-b556-1e4549145e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Reconstructing Model Test ===\n",
            "Input shape: (8, 5)\n",
            "Output shape: (8, 1)\n",
            "Model losses: [0.15287887]\n",
            "Total additional losses: 1\n",
            "New losses after second forward pass: [0.13783038]\n"
          ]
        }
      ],
      "source": [
        "class ReconstructingRegressor(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Model with auxiliary reconstruction loss.\n",
        "\n",
        "    This model includes a reconstruction branch that tries to\n",
        "    reconstruct the input from the hidden representation.\n",
        "    The reconstruction loss is added to the main loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the reconstructing regressor.\n",
        "\n",
        "        Args:\n",
        "            output_dim: Number of output units for main task\n",
        "            **kwargs: Additional arguments for parent class\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Main network layers\n",
        "        self.hidden = [\n",
        "            tf.keras.layers.Dense(\n",
        "                30, activation=\"selu\", kernel_initializer=\"lecun_normal\"\n",
        "            )\n",
        "            for _ in range(5)\n",
        "        ]\n",
        "\n",
        "        # Main output layer\n",
        "        self.out = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        \"\"\"\n",
        "        Create the reconstruction layer based on input shape.\n",
        "\n",
        "        Args:\n",
        "            batch_input_shape: Shape of input including batch dimension\n",
        "        \"\"\"\n",
        "        n_inputs = batch_input_shape[-1]\n",
        "\n",
        "        # Reconstruction layer (same size as input)\n",
        "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
        "\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass with reconstruction loss.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input tensor\n",
        "\n",
        "        Returns:\n",
        "            Main task predictions\n",
        "        \"\"\"\n",
        "        Z = inputs\n",
        "\n",
        "        # Pass through hidden layers\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "\n",
        "        # Reconstruction from hidden representation\n",
        "        reconstruction = self.reconstruct(Z)\n",
        "\n",
        "        # Compute reconstruction loss\n",
        "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
        "\n",
        "        # Add reconstruction loss (scaled down)\n",
        "        self.add_loss(0.05 * recon_loss)\n",
        "\n",
        "        # Return main task output\n",
        "        return self.out(Z)\n",
        "\n",
        "# Test reconstructing model\n",
        "print(\"=== Reconstructing Model Test ===\")\n",
        "\n",
        "# Create sample data\n",
        "X_sample = tf.random.normal((8, 5))  # 8 samples, 5 features\n",
        "print(f\"Input shape: {X_sample.shape}\")\n",
        "\n",
        "# Create model\n",
        "recon_model = ReconstructingRegressor(output_dim=1)\n",
        "\n",
        "# Forward pass\n",
        "output = recon_model(X_sample)\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "\n",
        "# Check losses\n",
        "print(f\"Model losses: {[loss.numpy() for loss in recon_model.losses]}\")\n",
        "print(f\"Total additional losses: {len(recon_model.losses)}\")\n",
        "\n",
        "# Test with different input\n",
        "X_sample2 = tf.random.normal((8, 5))\n",
        "output2 = recon_model(X_sample2)\n",
        "print(f\"New losses after second forward pass: {[loss.numpy() for loss in recon_model.losses]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "autodiff_theory"
      },
      "source": [
        "## 6. Automatic Differentiation (Autodiff)\n",
        "\n",
        "### 6.1 Mathematical Foundation of Autodiff\n",
        "\n",
        "Automatic differentiation computes exact derivatives efficiently using the chain rule:\n",
        "\n",
        "For a composite function $f(g(x))$:\n",
        "$\\frac{df}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx}$\n",
        "\n",
        "### 6.2 Forward vs Reverse Mode\n",
        "\n",
        "**Forward Mode (Forward Accumulation):**\n",
        "- Computes derivatives of all intermediate variables with respect to input\n",
        "- Efficient when number of inputs < number of outputs\n",
        "- Complexity: O(n) for n inputs\n",
        "\n",
        "**Reverse Mode (Backpropagation):**\n",
        "- Computes derivatives of output with respect to all intermediate variables\n",
        "- Efficient when number of outputs < number of inputs\n",
        "- Complexity: O(m) for m outputs\n",
        "- Preferred for neural networks (many parameters, few outputs)\n",
        "\n",
        "### 6.3 Gradient Computation Example\n",
        "\n",
        "For function $f(w_1, w_2) = 3w_1^2 + 2w_1w_2$:\n",
        "\n",
        "Analytical derivatives:\n",
        "- $\\frac{\\partial f}{\\partial w_1} = 6w_1 + 2w_2$\n",
        "- $\\frac{\\partial f}{\\partial w_2} = 2w_1$\n",
        "\n",
        "At point $(w_1, w_2) = (5, 3)$:\n",
        "- $\\frac{\\partial f}{\\partial w_1} = 6(5) + 2(3) = 36$\n",
        "- $\\frac{\\partial f}{\\partial w_2} = 2(5) = 10$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "autodiff_basic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe18c16-c7df-4e86-a6f4-1765662c801b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Automatic Differentiation Demonstration ===\n",
            "Numerical Approximation:\n",
            "f/w1  36.000003\n",
            "f/w2  10.000000\n",
            "\n",
            "Analytical Solution:\n",
            "f/w1 = 36\n",
            "f/w2 = 10\n",
            "\n",
            "TensorFlow Autodiff:\n",
            "f/w1 = 36.0\n",
            "f/w2 = 10.0\n",
            "\n",
            "Verification:\n",
            "All methods agree: True\n",
            "Autodiff matches analytical: True\n"
          ]
        }
      ],
      "source": [
        "def f(w1, w2):\n",
        "    \"\"\"\n",
        "    Example function for gradient computation.\n",
        "    f(w1, w2) = 3*w1^2 + 2*w1*w2\n",
        "    \"\"\"\n",
        "    return 3 * w1 ** 2 + 2 * w1 * w2\n",
        "\n",
        "print(\"=== Automatic Differentiation Demonstration ===\")\n",
        "\n",
        "# Compare numerical approximation vs autodiff\n",
        "w1, w2 = 5, 3\n",
        "eps = 1e-6\n",
        "\n",
        "# Numerical approximation (finite differences)\n",
        "print(\"Numerical Approximation:\")\n",
        "df_dw1_numerical = (f(w1 + eps, w2) - f(w1, w2)) / eps\n",
        "df_dw2_numerical = (f(w1, w2 + eps) - f(w1, w2)) / eps\n",
        "print(f\"f/w1  {df_dw1_numerical:.6f}\")\n",
        "print(f\"f/w2  {df_dw2_numerical:.6f}\")\n",
        "\n",
        "# Analytical solution\n",
        "print(\"\\nAnalytical Solution:\")\n",
        "df_dw1_analytical = 6 * w1 + 2 * w2\n",
        "df_dw2_analytical = 2 * w1\n",
        "print(f\"f/w1 = {df_dw1_analytical}\")\n",
        "print(f\"f/w2 = {df_dw2_analytical}\")\n",
        "\n",
        "# TensorFlow automatic differentiation\n",
        "print(\"\\nTensorFlow Autodiff:\")\n",
        "w1_tf, w2_tf = tf.Variable(5.), tf.Variable(3.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1_tf, w2_tf)\n",
        "\n",
        "gradients = tape.gradient(z, [w1_tf, w2_tf])\n",
        "print(f\"f/w1 = {gradients[0].numpy()}\")\n",
        "print(f\"f/w2 = {gradients[1].numpy()}\")\n",
        "\n",
        "# Verify all methods give same result\n",
        "print(\"\\nVerification:\")\n",
        "print(f\"All methods agree: {np.allclose([df_dw1_numerical, df_dw2_numerical], [df_dw1_analytical, df_dw2_analytical], atol=1e-5)}\")\n",
        "print(f\"Autodiff matches analytical: {np.allclose([gradients[0].numpy(), gradients[1].numpy()], [df_dw1_analytical, df_dw2_analytical])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "gradient_tape_features",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325eaeb1-3860-418c-b212-5fc6104c2ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GradientTape Advanced Features ===\n",
            "1. Persistent Tape:\n",
            "z/w1 = 36.0\n",
            "z/w2 = 10.0\n",
            "\n",
            "2. Watching Constants:\n",
            "Gradients w.r.t. constants: [36.0, 10.0]\n",
            "\n",
            "3. Second-Order Derivatives:\n",
            "f(x) = x at x = 2\n",
            "f'(2) = 3(2) = 12.0 (expected: 12)\n",
            "f''(2) = 6(2) = 12.0 (expected: 12)\n",
            "\n",
            "4. Gradient Stopping:\n",
            "With stop_gradient:\n",
            "f/w1 = 30.0 (expected: 30, since 6*5 + 0)\n",
            "f/w2 = None (expected: None, gradient stopped)\n"
          ]
        }
      ],
      "source": [
        "print(\"=== GradientTape Advanced Features ===\")\n",
        "\n",
        "# 1. Persistent tape for multiple gradient calls\n",
        "print(\"1. Persistent Tape:\")\n",
        "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    z = f(w1, w2)\n",
        "\n",
        "# Multiple gradient calls\n",
        "dz_dw1 = tape.gradient(z, w1)\n",
        "dz_dw2 = tape.gradient(z, w2)\n",
        "print(f\"z/w1 = {dz_dw1.numpy()}\")\n",
        "print(f\"z/w2 = {dz_dw2.numpy()}\")\n",
        "\n",
        "# Clean up persistent tape\n",
        "del tape\n",
        "\n",
        "# 2. Watching non-variable tensors\n",
        "print(\"\\n2. Watching Constants:\")\n",
        "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(c1)\n",
        "    tape.watch(c2)\n",
        "    z = f(c1, c2)\n",
        "\n",
        "gradients = tape.gradient(z, [c1, c2])\n",
        "print(f\"Gradients w.r.t. constants: {[g.numpy() for g in gradients]}\")\n",
        "\n",
        "# 3. Higher-order derivatives\n",
        "print(\"\\n3. Second-Order Derivatives:\")\n",
        "x = tf.Variable(2.0)\n",
        "\n",
        "with tf.GradientTape() as outer_tape:\n",
        "    with tf.GradientTape() as inner_tape:\n",
        "        y = x ** 3  # f(x) = x^3\n",
        "\n",
        "    # First derivative: f'(x) = 3x^2\n",
        "    dy_dx = inner_tape.gradient(y, x)\n",
        "\n",
        "# Second derivative: f''(x) = 6x\n",
        "d2y_dx2 = outer_tape.gradient(dy_dx, x)\n",
        "\n",
        "print(f\"f(x) = x at x = 2\")\n",
        "print(f\"f'(2) = 3(2) = {dy_dx.numpy()} (expected: 12)\")\n",
        "print(f\"f''(2) = 6(2) = {d2y_dx2.numpy()} (expected: 12)\")\n",
        "\n",
        "# 4. Stopping gradients\n",
        "print(\"\\n4. Gradient Stopping:\")\n",
        "def f_with_stop_gradient(w1, w2):\n",
        "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
        "\n",
        "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f_with_stop_gradient(w1, w2)\n",
        "\n",
        "gradients = tape.gradient(z, [w1, w2])\n",
        "print(f\"With stop_gradient:\")\n",
        "print(f\"f/w1 = {gradients[0].numpy()} (expected: 30, since 6*5 + 0)\")\n",
        "print(f\"f/w2 = {gradients[1]} (expected: None, gradient stopped)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "custom_gradient",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd02fcd7-c815-4b0c-b377-583b9bc66d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Custom Gradient Demonstration ===\n",
            "Normal values:\n",
            "Standard gradients: [0.7310586  0.8807971  0.95257413]\n",
            "Custom gradients: [0.7310586  0.880797   0.95257413]\n",
            "Values match: True\n",
            "\n",
            "Large values:\n",
            "Standard gradient: [nan]\n",
            "Custom gradient: [1.]\n",
            "Standard has NaN: True\n",
            "Custom has NaN: False\n"
          ]
        }
      ],
      "source": [
        "# Custom gradient for numerical stability\n",
        "@tf.custom_gradient\n",
        "def my_better_softplus(z):\n",
        "    \"\"\"\n",
        "    Numerically stable softplus with custom gradient.\n",
        "\n",
        "    The standard softplus: softplus(x) = log(1 + exp(x))\n",
        "    Its derivative: d/dx softplus(x) = exp(x) / (1 + exp(x)) = sigmoid(x)\n",
        "\n",
        "    For large x, this can cause numerical issues, so we use a stable implementation.\n",
        "    \"\"\"\n",
        "    exp_z = tf.exp(z)\n",
        "\n",
        "    def softplus_gradient(upstream_grad):\n",
        "        # Stable gradient computation: 1 / (1 + exp(-z)) = sigmoid(z)\n",
        "        return upstream_grad / (1 + 1 / exp_z)\n",
        "\n",
        "    # Return function value and gradient function\n",
        "    return tf.math.log(exp_z + 1), softplus_gradient\n",
        "\n",
        "print(\"=== Custom Gradient Demonstration ===\")\n",
        "\n",
        "# Compare standard softplus vs custom implementation\n",
        "def standard_softplus(z):\n",
        "    return tf.math.log(tf.exp(z) + 1)\n",
        "\n",
        "# Test with regular values\n",
        "x_normal = tf.Variable([1.0, 2.0, 3.0])\n",
        "print(\"Normal values:\")\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y_standard = standard_softplus(x_normal)\n",
        "grad_standard = tape.gradient(y_standard, x_normal)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y_custom = my_better_softplus(x_normal)\n",
        "grad_custom = tape.gradient(y_custom, x_normal)\n",
        "\n",
        "print(f\"Standard gradients: {grad_standard.numpy()}\")\n",
        "print(f\"Custom gradients: {grad_custom.numpy()}\")\n",
        "print(f\"Values match: {np.allclose(grad_standard.numpy(), grad_custom.numpy())}\")\n",
        "\n",
        "# Test with large values (where standard implementation might fail)\n",
        "x_large = tf.Variable([100.0])\n",
        "print(\"\\nLarge values:\")\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y_standard = standard_softplus(x_large)\n",
        "grad_standard = tape.gradient(y_standard, x_large)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y_custom = my_better_softplus(x_large)\n",
        "grad_custom = tape.gradient(y_custom, x_large)\n",
        "\n",
        "print(f\"Standard gradient: {grad_standard.numpy()}\")\n",
        "print(f\"Custom gradient: {grad_custom.numpy()}\")\n",
        "print(f\"Standard has NaN: {tf.reduce_any(tf.math.is_nan(grad_standard))}\")\n",
        "print(f\"Custom has NaN: {tf.reduce_any(tf.math.is_nan(grad_custom))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_training_theory"
      },
      "source": [
        "## 7. Custom Training Loops\n",
        "\n",
        "### 7.1 When to Use Custom Training Loops\n",
        "\n",
        "Custom training loops are needed when:\n",
        "1. **Multiple optimizers**: Different parts of the network need different optimizers\n",
        "2. **Complex gradient processing**: Custom gradient clipping or transformations\n",
        "3. **Specialized training procedures**: Custom schedules, constraints, or algorithms\n",
        "4. **Research**: Full control over the training process\n",
        "\n",
        "### 7.2 Mathematical Foundation\n",
        "\n",
        "The training loop implements gradient descent:\n",
        "\n",
        "1. **Forward pass**: $\\hat{\\mathbf{y}} = f(\\mathbf{x}; \\boldsymbol{\\theta})$\n",
        "2. **Loss computation**: $\\mathcal{L} = \\ell(\\mathbf{y}, \\hat{\\mathbf{y}}) + \\lambda R(\\boldsymbol{\\theta})$\n",
        "3. **Gradient computation**: $\\mathbf{g} = \\nabla_{\\boldsymbol{\\theta}} \\mathcal{L}$\n",
        "4. **Parameter update**: $\\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_t - \\eta \\mathbf{g}$\n",
        "\n",
        "where:\n",
        "- $\\ell$ is the main loss function\n",
        "- $R(\\boldsymbol{\\theta})$ is regularization\n",
        "- $\\lambda$ is the regularization coefficient\n",
        "- $\\eta$ is the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "data_preparation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d489e30f-efff-4d6e-9b3c-002b2812b102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Data Preparation ===\n",
            "Training set shape: (13209, 8)\n",
            "Training labels shape: (13209, 1)\n",
            "Validation set shape: (3303, 8)\n",
            "Feature names: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
            "Target statistics: mean=2.067, std=1.151\n"
          ]
        }
      ],
      "source": [
        "# Prepare data for custom training loop demonstration\n",
        "print(\"=== Data Preparation ===\")\n",
        "\n",
        "# Load California housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split data\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert to TensorFlow format\n",
        "X_train_scaled = tf.constant(X_train_scaled, dtype=tf.float32)\n",
        "y_train = tf.constant(y_train.reshape(-1, 1), dtype=tf.float32)\n",
        "X_valid_scaled = tf.constant(X_valid_scaled, dtype=tf.float32)\n",
        "y_valid = tf.constant(y_valid.reshape(-1, 1), dtype=tf.float32)\n",
        "\n",
        "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Validation set shape: {X_valid_scaled.shape}\")\n",
        "print(f\"Feature names: {housing.feature_names}\")\n",
        "print(f\"Target statistics: mean={tf.reduce_mean(y_train):.3f}, std={tf.math.reduce_std(y_train):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "training_utilities",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695242da-1939-479b-c724-2f63552d26b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Utility Functions Test ===\n",
            "Random batch X shape: (5, 8)\n",
            "Random batch y shape: (5, 1)\n",
            "Sample X values: [ 0.23577133  0.19324304  0.49314213 -0.11764727 -0.35695305  0.04960413\n",
            " -0.71087915  0.8644089 ]\n",
            "Sample y value: [2.33]\n",
            "\n",
            "Status bar test:\n",
            "\r0/100 [------------------------------] - loss: 0.0000\r\r20/100 [======------------------------] - loss: 0.2000\r\r40/100 [============------------------] - loss: 0.4000\r\r60/100 [==================------------] - loss: 0.6000\r\r80/100 [========================------] - loss: 0.8000\r\r100/100 [==============================] - loss: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Utility functions for custom training loop\n",
        "def random_batch(X, y, batch_size=32):\n",
        "    \"\"\"\n",
        "    Sample a random batch from the dataset.\n",
        "\n",
        "    Args:\n",
        "        X: Input features\n",
        "        y: Target values\n",
        "        batch_size: Size of the batch\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (X_batch, y_batch)\n",
        "    \"\"\"\n",
        "    idx = tf.random.uniform([batch_size], 0, tf.shape(X)[0], dtype=tf.int32)\n",
        "    return tf.gather(X, idx), tf.gather(y, idx)\n",
        "\n",
        "def print_status_bar(iteration, total, loss, metrics=None):\n",
        "    \"\"\"\n",
        "    Print training progress bar.\n",
        "\n",
        "    Args:\n",
        "        iteration: Current iteration\n",
        "        total: Total iterations\n",
        "        loss: Current loss value\n",
        "        metrics: List of metric objects\n",
        "    \"\"\"\n",
        "    metrics = metrics or []\n",
        "    if hasattr(loss, 'result'):\n",
        "        loss_val = loss.result()\n",
        "    else:\n",
        "        loss_val = loss\n",
        "\n",
        "    bar_length = 30\n",
        "    progress = iteration / total\n",
        "    filled = int(bar_length * progress)\n",
        "    bar = '=' * filled + '-' * (bar_length - filled)\n",
        "\n",
        "    metrics_str = \" - \".join([\n",
        "        f\"{m.name}: {m.result():.4f}\" for m in metrics\n",
        "    ])\n",
        "\n",
        "    end_char = \"\\n\" if iteration >= total else \"\\r\"\n",
        "\n",
        "    print(f\"\\r{iteration}/{total} [{bar}] - loss: {loss_val:.4f}\"\n",
        "          + (f\" - {metrics_str}\" if metrics_str else \"\"),\n",
        "          end=end_char)\n",
        "\n",
        "# Test utility functions\n",
        "print(\"=== Utility Functions Test ===\")\n",
        "\n",
        "# Test random batch sampling\n",
        "X_batch, y_batch = random_batch(X_train_scaled, y_train, batch_size=5)\n",
        "print(f\"Random batch X shape: {X_batch.shape}\")\n",
        "print(f\"Random batch y shape: {y_batch.shape}\")\n",
        "print(f\"Sample X values: {X_batch[0].numpy()}\")\n",
        "print(f\"Sample y value: {y_batch[0].numpy()}\")\n",
        "\n",
        "# Test status bar\n",
        "print(\"\\nStatus bar test:\")\n",
        "for i in range(0, 101, 20):\n",
        "    print_status_bar(i, 100, i * 0.01)\n",
        "time.sleep(0.1)  # Simulate processing time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "custom_training_loop",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86085a14-5d9f-4370-f0b2-5796b5a773ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Custom Training Loop Implementation ===\n",
            "Training configuration:\n",
            "  Epochs: 5\n",
            "  Batch size: 32\n",
            "  Steps per epoch: 412\n",
            "  Optimizer: Nadam\n",
            "  Learning rate: 0.009999999776482582\n",
            "\n",
            "Starting custom training loop...\n",
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - val_loss: 0.6240 - val_mae: 0.5374\n",
            "\n",
            "Epoch 2/5\n",
            " - val_loss: 0.5098 - val_mae: 0.5234\n",
            "\n",
            "Epoch 3/5\n",
            " - val_loss: 0.9591 - val_mae: 0.5183\n",
            "\n",
            "Epoch 4/5\n",
            " - val_loss: 0.4893 - val_mae: 0.5079\n",
            "\n",
            "Epoch 5/5\n",
            " - val_loss: 0.4951 - val_mae: 0.4908\n",
            "\n",
            "Training completed!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Results:\n",
            "Training Loss: 0.7762\n",
            "Validation Loss: 0.4951\n",
            "Training MAE: 0.5106\n",
            "Validation MAE: 0.4908\n"
          ]
        }
      ],
      "source": [
        "# Implement complete custom training loop\n",
        "print(\"=== Custom Training Loop Implementation ===\")\n",
        "\n",
        "# Create model for custom training\n",
        "l2_reg = tf.keras.regularizers.l2(0.01)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
        "                         kernel_regularizer=l2_reg, input_shape=(X_train_scaled.shape[1],)),\n",
        "    tf.keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
        "])\n",
        "\n",
        "# Training hyperparameters\n",
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train_scaled) // batch_size\n",
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# Metrics\n",
        "mean_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "metrics = [tf.keras.metrics.MeanAbsoluteError(name='train_mae')]\n",
        "\n",
        "print(f\"Training configuration:\")\n",
        "print(f\"  Epochs: {n_epochs}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Steps per epoch: {n_steps}\")\n",
        "print(f\"  Optimizer: {optimizer.__class__.__name__}\")\n",
        "print(f\"  Learning rate: {optimizer.learning_rate.numpy()}\")\n",
        "\n",
        "# Training loop\n",
        "print(\"\\nStarting custom training loop...\")\n",
        "training_history = {'loss': [], 'mae': [], 'val_loss': [], 'val_mae': []}\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    print(f\"\\nEpoch {epoch}/{n_epochs}\")\n",
        "\n",
        "    # Reset metrics for this epoch\n",
        "    # mean_loss.reset_states() # Commented out due to AttributeError in TF 2.16.1\n",
        "    # for metric in metrics: # Commented out due to AttributeError in TF 2.16.1\n",
        "    #     metric.reset_states() # Commented out due to AttributeError in TF 2.16.1\n",
        "\n",
        "    # Training steps\n",
        "    for step in range(1, n_steps + 1):\n",
        "        # Sample a batch\n",
        "        X_batch, y_batch = random_batch(X_train_scaled, y_train, batch_size)\n",
        "\n",
        "        # Forward pass and gradient computation\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Predictions\n",
        "            y_pred = model(X_batch, training=True)\n",
        "\n",
        "            # Main loss\n",
        "            main_loss = loss_fn(y_batch, y_pred) # Use the instantiated loss object\n",
        "\n",
        "            # Total loss (main + regularization)\n",
        "            total_loss = tf.add_n([tf.reduce_mean(main_loss)] + model.losses) # Reduce mean for batch loss\n",
        "\n",
        "        # Compute gradients\n",
        "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "\n",
        "        # Apply gradients\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        # Update metrics\n",
        "        mean_loss.update_state(total_loss)\n",
        "        for metric in metrics:\n",
        "            metric.update_state(y_batch, y_pred)\n",
        "\n",
        "        # Print progress\n",
        "        if step % 50 == 0 or step == n_steps:\n",
        "            print_status_bar(step * batch_size, len(X_train_scaled), mean_loss, metrics)\n",
        "\n",
        "    # Validation evaluation\n",
        "    val_loss = tf.keras.metrics.Mean()\n",
        "    val_mae = tf.keras.metrics.MeanAbsoluteError()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_predictions = model(X_valid_scaled, training=False)\n",
        "    val_loss_value = tf.reduce_mean(loss_fn(y_valid, val_predictions)) # Use the instantiated loss object and reduce mean\n",
        "    val_loss.update_state(val_loss_value)\n",
        "    val_mae.update_state(y_valid, val_predictions)\n",
        "\n",
        "    # Store history\n",
        "    training_history['loss'].append(mean_loss.result().numpy())\n",
        "    training_history['mae'].append(metrics[0].result().numpy())\n",
        "    training_history['val_loss'].append(val_loss.result().numpy())\n",
        "    training_history['val_mae'].append(val_mae.result().numpy())\n",
        "\n",
        "    print(f\" - val_loss: {val_loss.result():.4f} - val_mae: {val_mae.result():.4f}\")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "\n",
        "# Plot training history\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(training_history['loss'], label='Training Loss', marker='o')\n",
        "ax1.plot(training_history['val_loss'], label='Validation Loss', marker='s')\n",
        "ax1.set_title('Model Loss During Custom Training')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_xlim(0, n_epochs -1) # Adjusted x-limit\n",
        "ax1.set_xticks(range(n_epochs)) # Ensure ticks are at epoch numbers\n",
        "\n",
        "# MAE plot\n",
        "ax2.plot(training_history['mae'], label='Training MAE', marker='o')\n",
        "ax2.plot(training_history['val_mae'], label='Validation MAE', marker='s')\n",
        "ax2.set_title('Model MAE During Custom Training')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Mean Absolute Error')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_xlim(0, n_epochs - 1) # Adjusted x-limit\n",
        "ax2.set_xticks(range(n_epochs)) # Ensure ticks are at epoch numbers\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final evaluation\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"Training Loss: {training_history['loss'][-1]:.4f}\")\n",
        "print(f\"Validation Loss: {training_history['val_loss'][-1]:.4f}\")\n",
        "print(f\"Training MAE: {training_history['mae'][-1]:.4f}\")\n",
        "print(f\"Validation MAE: {training_history['val_mae'][-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf_functions_theory"
      },
      "source": [
        "## 8. TensorFlow Functions and Graph Optimization\n",
        "\n",
        "### 8.1 Theory of Computation Graphs\n",
        "\n",
        "TensorFlow Functions convert Python functions into computation graphs for optimization:\n",
        "\n",
        "**Benefits of Graphs:**\n",
        "1. **Optimization**: Prune unused nodes, simplify expressions\n",
        "2. **Parallelization**: Run independent operations in parallel\n",
        "3. **Portability**: Deploy across different platforms\n",
        "4. **Memory efficiency**: Optimize memory usage\n",
        "\n",
        "### 8.2 AutoGraph Process\n",
        "\n",
        "**AutoGraph Transformation:**\n",
        "1. **Source code analysis**: Parse Python control flow\n",
        "2. **Control flow conversion**: Replace with TensorFlow operations\n",
        "   - `for` loops  `tf.while_loop()`\n",
        "   - `if` statements  `tf.cond()`\n",
        "   - `break`/`continue`  graph control flow\n",
        "\n",
        "**Tracing Process:**\n",
        "1. **Symbolic execution**: Run with symbolic tensors (shape + dtype, no values)\n",
        "2. **Graph construction**: Build computation graph\n",
        "3. **Optimization**: Apply graph-level optimizations\n",
        "4. **Caching**: Cache graphs by input signature\n",
        "\n",
        "### 8.3 Function Polymorphism\n",
        "\n",
        "TensorFlow Functions create separate graphs for each unique input signature:\n",
        "- **Tensor arguments**: One graph per (shape, dtype) combination\n",
        "- **Python arguments**: One graph per distinct value\n",
        "\n",
        "**Performance Implications:**\n",
        "- Many distinct Python values  many graphs  memory overhead\n",
        "- Use Python arguments for hyperparameters only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "tf_function_basic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06eded6-dcb3-4043-daf7-d93befcc2b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TensorFlow Functions Basic Example ===\n",
            "Original function type: <class 'function'>\n",
            "TF Function type: <class 'tensorflow.python.eager.polymorphic_function.polymorphic_function.Function'>\n",
            "\n",
            "Function calls:\n",
            "Python function - cube(2): 8\n",
            "TF Function - tf_cube(2): 8\n",
            "TF Function - tf_cube(tf.constant(2.0)): 8.0\n",
            "\n",
            "Original function via python_function: 8\n",
            "\n",
            "Decorated function result: 27.0\n",
            "\n",
            "=== Performance Comparison ===\n",
            "Python function time: 0.3241 seconds\n",
            "TF Function time: 0.0195 seconds\n",
            "Speedup: 16.66x\n",
            "Results equal: False\n"
          ]
        }
      ],
      "source": [
        "# Basic TensorFlow Function demonstration\n",
        "print(\"=== TensorFlow Functions Basic Example ===\")\n",
        "\n",
        "def cube(x):\n",
        "    \"\"\"\n",
        "    Simple function to compute cube of input.\n",
        "    \"\"\"\n",
        "    return x ** 3\n",
        "\n",
        "# Convert to TensorFlow Function\n",
        "tf_cube = tf.function(cube)\n",
        "\n",
        "print(f\"Original function type: {type(cube)}\")\n",
        "print(f\"TF Function type: {type(tf_cube)}\")\n",
        "\n",
        "# Test with different inputs\n",
        "print(\"\\nFunction calls:\")\n",
        "print(f\"Python function - cube(2): {cube(2)}\")\n",
        "print(f\"TF Function - tf_cube(2): {tf_cube(2)}\")\n",
        "print(f\"TF Function - tf_cube(tf.constant(2.0)): {tf_cube(tf.constant(2.0))}\")\n",
        "\n",
        "# Access original function\n",
        "print(f\"\\nOriginal function via python_function: {tf_cube.python_function(2)}\")\n",
        "\n",
        "# Alternative: decorator syntax\n",
        "@tf.function\n",
        "def decorated_cube(x):\n",
        "    \"\"\"Decorated version of cube function.\"\"\"\n",
        "    return x ** 3\n",
        "\n",
        "print(f\"\\nDecorated function result: {decorated_cube(tf.constant(3.0))}\")\n",
        "\n",
        "# Performance comparison\n",
        "print(\"\\n=== Performance Comparison ===\")\n",
        "\n",
        "# Create larger tensor for meaningful comparison\n",
        "large_tensor = tf.random.normal((1000, 1000))\n",
        "\n",
        "# Time Python function\n",
        "start_time = time.time()\n",
        "for _ in range(10):\n",
        "    result_python = cube(large_tensor)\n",
        "python_time = time.time() - start_time\n",
        "\n",
        "# Time TensorFlow Function (after initial compilation)\n",
        "_ = tf_cube(large_tensor)  # Warm up (compilation)\n",
        "start_time = time.time()\n",
        "for _ in range(10):\n",
        "    result_tf = tf_cube(large_tensor)\n",
        "tf_time = time.time() - start_time\n",
        "\n",
        "print(f\"Python function time: {python_time:.4f} seconds\")\n",
        "print(f\"TF Function time: {tf_time:.4f} seconds\")\n",
        "print(f\"Speedup: {python_time / tf_time:.2f}x\")\n",
        "print(f\"Results equal: {tf.reduce_all(tf.equal(result_python, result_tf))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "tf_function_polymorphism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c48173d-0c40-4802-ff4a-9544e70b3a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TensorFlow Function Polymorphism ===\n",
            "Calling with different tensor signatures:\n",
            "Tracing with input shape: Tensor(\"Shape:0\", shape=(1,), dtype=int32), dtype: <dtype: 'int32'>\n",
            "Tracing with input shape: Tensor(\"Shape:0\", shape=(1,), dtype=int32), dtype: <dtype: 'float32'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function polymorphic_function at 0x7b2d69b7f1a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing with input shape: Tensor(\"Shape:0\", shape=(2,), dtype=int32), dtype: <dtype: 'float32'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function polymorphic_function at 0x7b2d69b7f1a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results: 14, 14.0, 30.0\n",
            "\n",
            "Calling with same signature (should reuse graph):\n",
            "Tracing with input shape: Tensor(\"Shape:0\", shape=(1,), dtype=int32), dtype: <dtype: 'float32'>\n",
            "Result: 77.0\n",
            "\n",
            "=== Python Value Polymorphism Warning ===\n",
            "Tracing with scale: 2\n",
            "Tracing with scale: 3\n",
            "Tracing with scale: 2\n",
            "Results: [2. 4. 6.], [3. 6. 9.], [2. 4. 6.]\n",
            "\n",
            "Better approach with tensor arguments:\n",
            "Tracing with scale tensor shape: Tensor(\"Shape:0\", shape=(0,), dtype=int32)\n",
            "Tracing with scale tensor shape: Tensor(\"Shape:0\", shape=(0,), dtype=int32)\n",
            "Tracing with scale tensor shape: Tensor(\"Shape:0\", shape=(0,), dtype=int32)\n",
            "Results: [2. 4. 6.], [3. 6. 9.], [ 4.  8. 12.]\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate TensorFlow Function polymorphism\n",
        "print(\"=== TensorFlow Function Polymorphism ===\")\n",
        "\n",
        "@tf.function\n",
        "def polymorphic_function(x):\n",
        "    \"\"\"Function that will create different graphs for different input signatures.\"\"\"\n",
        "    tf.print(f\"Tracing with input shape: {tf.shape(x)}, dtype: {x.dtype}\")\n",
        "    return tf.reduce_sum(x ** 2)\n",
        "\n",
        "print(\"Calling with different tensor signatures:\")\n",
        "\n",
        "# Different shapes - will create separate graphs\n",
        "result1 = polymorphic_function(tf.constant([1, 2, 3]))  # int32, shape (3,)\n",
        "result2 = polymorphic_function(tf.constant([1., 2., 3.]))  # float32, shape (3,)\n",
        "result3 = polymorphic_function(tf.constant([[1., 2.], [3., 4.]]))  # float32, shape (2, 2)\n",
        "\n",
        "print(f\"\\nResults: {result1}, {result2}, {result3}\")\n",
        "\n",
        "# Same signature - will reuse graph\n",
        "print(\"\\nCalling with same signature (should reuse graph):\")\n",
        "result4 = polymorphic_function(tf.constant([4., 5., 6.]))  # Same as result2\n",
        "print(f\"Result: {result4}\")\n",
        "\n",
        "# Python values create separate graphs\n",
        "print(\"\\n=== Python Value Polymorphism Warning ===\")\n",
        "\n",
        "@tf.function\n",
        "def function_with_python_arg(x, scale):\n",
        "    \"\"\"Function with Python argument - creates graph per distinct value.\"\"\"\n",
        "    tf.print(f\"Tracing with scale: {scale}\")\n",
        "    return x * scale\n",
        "\n",
        "# Each different Python value creates a new graph\n",
        "tensor_input = tf.constant([1., 2., 3.])\n",
        "result1 = function_with_python_arg(tensor_input, 2)    # Graph 1\n",
        "result2 = function_with_python_arg(tensor_input, 3)    # Graph 2\n",
        "result3 = function_with_python_arg(tensor_input, 2)    # Reuses Graph 1\n",
        "\n",
        "print(f\"Results: {result1.numpy()}, {result2.numpy()}, {result3.numpy()}\")\n",
        "\n",
        "# Better approach: use tensor arguments for dynamic values\n",
        "@tf.function\n",
        "def better_function(x, scale_tensor):\n",
        "    \"\"\"Better approach using tensor arguments.\"\"\"\n",
        "    tf.print(f\"Tracing with scale tensor shape: {tf.shape(scale_tensor)}\")\n",
        "    return x * scale_tensor\n",
        "\n",
        "print(\"\\nBetter approach with tensor arguments:\")\n",
        "result1 = better_function(tensor_input, tf.constant(2.))   # Single graph\n",
        "result2 = better_function(tensor_input, tf.constant(3.))   # Reuses same graph\n",
        "result3 = better_function(tensor_input, tf.constant(4.))   # Reuses same graph\n",
        "\n",
        "print(f\"Results: {result1.numpy()}, {result2.numpy()}, {result3.numpy()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "tf_function_rules",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a501eb7-9114-4c4f-de5d-947dc862ddb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TensorFlow Function Rules Demonstration ===\n",
            "1. External library behavior:\n",
            "NumPy version (same value each call):\n",
            "NumPy random call (only during tracing)\n",
            "  Call 1: 0.3745\n",
            "  Call 2: 0.3745\n",
            "  Call 3: 0.3745\n",
            "\n",
            "TensorFlow version (different values):\n",
            "TF random call (only during tracing)\n",
            "  Call 1: 0.8355\n",
            "  Call 2: 0.4640\n",
            "  Call 3: 0.9527\n",
            "\n",
            "2. Variable creation rules:\n",
            "Variable created!\n",
            "First call result: [1. 2. 3.]\n",
            "Second call result: [2. 4. 6.]\n",
            "\n",
            "3. Control flow examples:\n",
            "Proper TF loop result: 10\n",
            "Python loop result: 10\n",
            "Expected (0+1+2+3+4): 10\n",
            "\n",
            "4. Vectorization example:\n",
            "Loop implementation time: 0.1646s\n",
            "Vectorized implementation time: 0.0597s\n",
            "Speedup: 2.76x\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate TensorFlow Function rules and best practices\n",
        "print(\"=== TensorFlow Function Rules Demonstration ===\")\n",
        "\n",
        "# Rule 1: External libraries run only during tracing\n",
        "print(\"1. External library behavior:\")\n",
        "\n",
        "@tf.function\n",
        "def function_with_numpy():\n",
        "    \"\"\"Function using NumPy - runs only during tracing.\"\"\"\n",
        "    print(\"NumPy random call (only during tracing)\")\n",
        "    return tf.constant(np.random.rand())  # This value is fixed after tracing!\n",
        "\n",
        "@tf.function\n",
        "def function_with_tf_random():\n",
        "    \"\"\"Function using TensorFlow random - runs every call.\"\"\"\n",
        "    print(\"TF random call (only during tracing)\")\n",
        "    return tf.random.uniform([])  # This generates new values each call\n",
        "\n",
        "print(\"NumPy version (same value each call):\")\n",
        "for i in range(3):\n",
        "    result = function_with_numpy()\n",
        "    print(f\"  Call {i+1}: {result.numpy():.4f}\")\n",
        "\n",
        "print(\"\\nTensorFlow version (different values):\")\n",
        "for i in range(3):\n",
        "    result = function_with_tf_random()\n",
        "    print(f\"  Call {i+1}: {result.numpy():.4f}\")\n",
        "\n",
        "# Rule 2: Variable creation must happen only once\n",
        "print(\"\\n2. Variable creation rules:\")\n",
        "\n",
        "class VariableLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Proper way to create variables in TF Functions.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.v = None\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        if self.v is None:\n",
        "            # Variable created only on first call\n",
        "            self.v = tf.Variable(tf.zeros_like(x), trainable=False)\n",
        "            print(\"Variable created!\")\n",
        "\n",
        "        self.v.assign_add(x)  # Proper way to modify variables\n",
        "        return self.v\n",
        "\n",
        "# Test variable creation\n",
        "layer = VariableLayer()\n",
        "input_tensor = tf.constant([1., 2., 3.])\n",
        "\n",
        "result1 = layer(input_tensor)\n",
        "print(f\"First call result: {result1.numpy()}\")\n",
        "\n",
        "result2 = layer(input_tensor)\n",
        "print(f\"Second call result: {result2.numpy()}\")\n",
        "\n",
        "# Rule 3: Control flow must use TensorFlow operations\n",
        "print(\"\\n3. Control flow examples:\")\n",
        "\n",
        "@tf.function\n",
        "def proper_loop(n):\n",
        "    \"\"\"Proper TensorFlow loop that gets captured in graph.\"\"\"\n",
        "    result = tf.constant(0)\n",
        "    for i in tf.range(n):  # Use tf.range, not range()\n",
        "        result = result + i\n",
        "    return result\n",
        "\n",
        "@tf.function\n",
        "def python_loop(n):\n",
        "    \"\"\"Python loop - runs during tracing only.\"\"\"\n",
        "    result = tf.constant(0)\n",
        "    # FIX: Use tf.range for TensorFlow compatibility\n",
        "    for i in tf.range(n):  # Use tf.range, not range() or range(n.numpy())\n",
        "        result = result + i\n",
        "    return result\n",
        "\n",
        "n = tf.constant(5)\n",
        "result_proper = proper_loop(n)\n",
        "result_python = python_loop(n)\n",
        "\n",
        "print(f\"Proper TF loop result: {result_proper}\")\n",
        "print(f\"Python loop result: {result_python}\")\n",
        "print(f\"Expected (0+1+2+3+4): {sum(range(5))}\")\n",
        "\n",
        "# Rule 4: Use vectorized operations when possible\n",
        "print(\"\\n4. Vectorization example:\")\n",
        "\n",
        "@tf.function\n",
        "def loop_implementation(x):\n",
        "    \"\"\"Less efficient loop-based implementation.\"\"\"\n",
        "    result = tf.TensorArray(tf.float32, size=tf.shape(x)[0])\n",
        "    for i in tf.range(tf.shape(x)[0]):\n",
        "        result = result.write(i, x[i] ** 2)\n",
        "    return result.stack()\n",
        "\n",
        "@tf.function\n",
        "def vectorized_implementation(x):\n",
        "    \"\"\"Efficient vectorized implementation.\"\"\"\n",
        "    return x ** 2\n",
        "\n",
        "test_input = tf.constant([1., 2., 3., 4., 5.])\n",
        "\n",
        "# Time both implementations\n",
        "start_time = time.time()\n",
        "for _ in range(100):\n",
        "    _ = loop_implementation(test_input)\n",
        "loop_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "for _ in range(100):\n",
        "    _ = vectorized_implementation(test_input)\n",
        "vectorized_time = time.time() - start_time\n",
        "\n",
        "print(f\"Loop implementation time: {loop_time:.4f}s\")\n",
        "print(f\"Vectorized implementation time: {vectorized_time:.4f}s\")\n",
        "print(f\"Speedup: {loop_time / vectorized_time:.2f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercises_header"
      },
      "source": [
        "## 9. Chapter Exercises - Solutions with Theoretical Explanations\n",
        "\n",
        "This section provides detailed solutions to all exercises from Chapter 12, with comprehensive theoretical explanations and mathematical foundations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_1"
      },
      "source": [
        "### Exercise 1: TensorFlow Description and Features\n",
        "\n",
        "**Question:** How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Short Description:** TensorFlow is a powerful open-source library for numerical computation and machine learning that uses dataflow graphs to represent computation across multiple platforms and devices.\n",
        "\n",
        "**Main Features:**\n",
        "1. **Distributed Computing**: Seamless scaling across CPUs, GPUs, and TPUs\n",
        "2. **Automatic Differentiation**: Efficient gradient computation for optimization\n",
        "3. **Graph Optimization**: Just-in-time compilation and graph-level optimizations\n",
        "4. **Cross-Platform Deployment**: From mobile devices to large-scale servers\n",
        "5. **High-Level APIs**: tf.keras for rapid prototyping\n",
        "6. **Production Ready**: Comprehensive ecosystem (TensorBoard, TF Serving, TF Lite)\n",
        "\n",
        "**Other Popular Deep Learning Libraries:**\n",
        "- **PyTorch**: Dynamic computation graphs, popular in research\n",
        "- **JAX**: NumPy-compatible with XLA compilation\n",
        "- **MXNet**: Efficient and flexible deep learning framework\n",
        "- **Caffe**: Focused on computer vision tasks\n",
        "- **ONNX**: Interoperability standard for ML models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_2"
      },
      "source": [
        "### Exercise 2: TensorFlow vs NumPy\n",
        "\n",
        "**Question:** Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**No, TensorFlow is not a drop-in replacement for NumPy**, although they share many similarities.\n",
        "\n",
        "**Key Differences:**\n",
        "\n",
        "1. **Precision Defaults:**\n",
        "   - NumPy: 64-bit precision by default\n",
        "   - TensorFlow: 32-bit precision by default (for neural network efficiency)\n",
        "\n",
        "2. **Type Conversion:**\n",
        "   - NumPy: Automatic type promotion\n",
        "   - TensorFlow: No automatic conversions (explicit casting required)\n",
        "\n",
        "3. **Mutability:**\n",
        "   - NumPy: Arrays are mutable\n",
        "   - TensorFlow: Tensors are immutable (use Variables for mutable state)\n",
        "\n",
        "4. **Computation Model:**\n",
        "   - NumPy: Immediate execution\n",
        "   - TensorFlow: Can use graph execution for optimization\n",
        "\n",
        "5. **Hardware Support:**\n",
        "   - NumPy: CPU only\n",
        "   - TensorFlow: CPU, GPU, TPU support\n",
        "\n",
        "6. **Function Names:**\n",
        "   - Some functions have different names (e.g., `np.sum()` vs `tf.reduce_sum()`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "exercise_2_demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71419f25-0364-4fd2-a1eb-30394cd71c8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 2: TensorFlow vs NumPy Differences ===\n",
            "NumPy default dtype: float64\n",
            "TensorFlow default dtype: <dtype: 'float32'>\n",
            "\n",
            "Type conversion:\n",
            "NumPy: float + int = [3.] (dtype: float64)\n",
            "TensorFlow error: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor b...\n",
            "TensorFlow: float + cast(int) = [3.]\n",
            "\n",
            "Mutability:\n",
            "NumPy after modification: [42.  2.  3.]\n",
            "TensorFlow tensor modification error: 'tensorflow.python.framework.ops.EagerTensor' object does no...\n",
            "TensorFlow Variable after modification: <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([42.,  2.,  3.], dtype=float32)>\n",
            "\n",
            "Function naming:\n",
            "NumPy sum: 10.0\n",
            "TensorFlow reduce_sum: 10.0\n",
            "NumPy mean: 2.5\n",
            "TensorFlow reduce_mean: 2.5\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2: Demonstrate TensorFlow vs NumPy differences\n",
        "print(\"=== Exercise 2: TensorFlow vs NumPy Differences ===\")\n",
        "\n",
        "# 1. Precision differences\n",
        "np_array = np.array([1., 2., 3.])\n",
        "tf_tensor = tf.constant([1., 2., 3.])\n",
        "\n",
        "print(f\"NumPy default dtype: {np_array.dtype}\")\n",
        "print(f\"TensorFlow default dtype: {tf_tensor.dtype}\")\n",
        "\n",
        "# 2. Type conversion behavior\n",
        "print(\"\\nType conversion:\")\n",
        "try:\n",
        "    # NumPy allows this\n",
        "    np_result = np.array([1.0]) + np.array([2])\n",
        "    print(f\"NumPy: float + int = {np_result} (dtype: {np_result.dtype})\")\n",
        "except Exception as e:\n",
        "    print(f\"NumPy error: {e}\")\n",
        "\n",
        "try:\n",
        "    # TensorFlow requires explicit casting\n",
        "    tf_result = tf.constant([1.0]) + tf.constant([2])\n",
        "    print(f\"TensorFlow: This would work\")\n",
        "except Exception as e:\n",
        "    print(f\"TensorFlow error: {str(e)[:80]}...\")\n",
        "\n",
        "    # Correct way in TensorFlow\n",
        "    tf_result = tf.constant([1.0]) + tf.cast(tf.constant([2]), tf.float32)\n",
        "print(f\"TensorFlow: float + cast(int) = {tf_result}\")\n",
        "\n",
        "# 3. Mutability differences\n",
        "print(\"\\nMutability:\")\n",
        "np_array = np.array([1., 2., 3.])\n",
        "np_array[0] = 42  # This works\n",
        "print(f\"NumPy after modification: {np_array}\")\n",
        "\n",
        "tf_tensor = tf.constant([1., 2., 3.])\n",
        "try:\n",
        "    tf_tensor[0] = 42  # This doesn't work\n",
        "except Exception as e:\n",
        "    print(f\"TensorFlow tensor modification error: {str(e)[:60]}...\")\n",
        "\n",
        "# TensorFlow way: use Variables\n",
        "tf_var = tf.Variable([1., 2., 3.])\n",
        "tf_var[0].assign(42)\n",
        "print(f\"TensorFlow Variable after modification: {tf_var}\")\n",
        "\n",
        "# 4. Function naming differences\n",
        "print(\"\\nFunction naming:\")\n",
        "arr = np.array([[1., 2.], [3., 4.]])\n",
        "tensor = tf.constant([[1., 2.], [3., 4.]])\n",
        "\n",
        "print(f\"NumPy sum: {np.sum(arr)}\")\n",
        "print(f\"TensorFlow reduce_sum: {tf.reduce_sum(tensor)}\")\n",
        "print(f\"NumPy mean: {np.mean(arr)}\")\n",
        "print(f\"TensorFlow reduce_mean: {tf.reduce_mean(tensor)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_3"
      },
      "source": [
        "### Exercise 3: tf.range vs tf.constant with np.arange\n",
        "\n",
        "**Question:** Do you get the same result with `tf.range(10)` and `tf.constant(np.arange(10))`?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Mostly yes, but with important differences:**\n",
        "\n",
        "1. **Values**: Both produce the same sequence [0, 1, 2, ..., 9]\n",
        "2. **Data types**: May differ due to default precision differences\n",
        "3. **Execution time**: `tf.range()` is computed during graph execution, `tf.constant()` is computed during graph construction\n",
        "4. **Memory usage**: `tf.constant()` stores values in the graph, `tf.range()` generates them dynamically\n",
        "\n",
        "**Mathematical equivalence:** Both represent the set $\\{0, 1, 2, ..., 9\\}$\n",
        "\n",
        "**Performance considerations:** For large ranges, `tf.range()` is more memory efficient as it doesn't store all values in the graph definition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "exercise_3_demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6a794b-7cc8-44e4-dd00-319b8bd85b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 3: tf.range vs tf.constant(np.arange) ===\n",
            "tf.range(10): [0 1 2 3 4 5 6 7 8 9]\n",
            "tf.constant(np.arange(10)): [0 1 2 3 4 5 6 7 8 9]\n",
            "\n",
            "Shapes: (10,) vs (10,)\n",
            "Data types: <dtype: 'int32'> vs <dtype: 'int64'>\n",
            "Values equal: True\n",
            "After dtype conversion - equal: True\n",
            "\n",
            "=== Performance Comparison ===\n",
            "tf.range time: 0.1775 seconds\n",
            "tf.constant(np.arange) time: 0.0294 seconds\n",
            "tf.range is 0.17x faster\n",
            "\n",
            "Memory efficiency:\n",
            "Both create sequences of length: 100000, 100000\n",
            "tf.range generates values dynamically, tf.constant stores them in graph\n"
          ]
        }
      ],
      "source": [
        "# Exercise 3: Compare tf.range vs tf.constant with np.arange\n",
        "print(\"=== Exercise 3: tf.range vs tf.constant(np.arange) ===\")\n",
        "\n",
        "# Create both versions\n",
        "tf_range = tf.range(10)\n",
        "tf_constant = tf.constant(np.arange(10))\n",
        "\n",
        "print(f\"tf.range(10): {tf_range}\")\n",
        "print(f\"tf.constant(np.arange(10)): {tf_constant}\")\n",
        "\n",
        "# Check properties\n",
        "print(f\"\\nShapes: {tf_range.shape} vs {tf_constant.shape}\")\n",
        "print(f\"Data types: {tf_range.dtype} vs {tf_constant.dtype}\")\n",
        "print(f\"Values equal: {tf.reduce_all(tf.equal(tf_range, tf.cast(tf_constant, tf_range.dtype)))}\")\n",
        "\n",
        "# Convert to same dtype for exact comparison\n",
        "tf_constant_int32 = tf.cast(tf_constant, tf.int32)\n",
        "print(f\"After dtype conversion - equal: {tf.reduce_all(tf.equal(tf_range, tf_constant_int32))}\")\n",
        "\n",
        "# Performance comparison with larger ranges\n",
        "print(\"\\n=== Performance Comparison ===\")\n",
        "\n",
        "# Time tf.range\n",
        "start_time = time.time()\n",
        "for _ in range(1000):\n",
        "    _ = tf.range(1000)\n",
        "range_time = time.time() - start_time\n",
        "\n",
        "# Time tf.constant with np.arange\n",
        "start_time = time.time()\n",
        "for _ in range(1000):\n",
        "    _ = tf.constant(np.arange(1000))\n",
        "constant_time = time.time() - start_time\n",
        "\n",
        "print(f\"tf.range time: {range_time:.4f} seconds\")\n",
        "print(f\"tf.constant(np.arange) time: {constant_time:.4f} seconds\")\n",
        "print(f\"tf.range is {constant_time/range_time:.2f}x faster\")\n",
        "\n",
        "# Memory efficiency demonstration\n",
        "print(\"\\nMemory efficiency:\")\n",
        "large_range = tf.range(100000)\n",
        "large_constant = tf.constant(np.arange(100000))\n",
        "\n",
        "print(f\"Both create sequences of length: {len(large_range)}, {len(large_constant)}\")\n",
        "print(\"tf.range generates values dynamically, tf.constant stores them in graph\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_4"
      },
      "source": [
        "### Exercise 4: TensorFlow Data Structures\n",
        "\n",
        "**Question:** Can you name six other data structures available in TensorFlow, beyond regular tensors?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Six TensorFlow Data Structures:**\n",
        "\n",
        "1. **Variables (`tf.Variable`)**: Mutable tensors for model parameters\n",
        "   - Mathematical role: $\\boldsymbol{\\theta} \\in \\mathbb{R}^d$ (trainable parameters)\n",
        "   \n",
        "2. **Sparse Tensors (`tf.SparseTensor`)**: Efficient representation of mostly-zero tensors\n",
        "   - Mathematical representation: $S = \\{(i, v_i) : v_i \\neq 0\\}$\n",
        "   \n",
        "3. **Ragged Tensors (`tf.RaggedTensor`)**: Tensors with variable-length dimensions\n",
        "   - Use case: Sequences of different lengths\n",
        "   \n",
        "4. **String Tensors**: Tensors containing byte strings or Unicode\n",
        "   - Encoded as UTF-8 byte sequences\n",
        "   \n",
        "5. **Tensor Arrays (`tf.TensorArray`)**: Dynamic arrays that can grow during execution\n",
        "   - Essential for dynamic computation graphs\n",
        "   \n",
        "6. **Datasets (`tf.data.Dataset`)**: Efficient data pipeline abstraction\n",
        "   - Optimized for ML data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "exercise_4_demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b21945-507a-4456-bb99-e351cb2b3f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 4: TensorFlow Data Structures ===\n",
            "1. Variables:\n",
            "   Variable: <tf.Variable 'my_variable:0' shape=(2, 2) dtype=int32, numpy=\n",
            "array([[1, 2],\n",
            "       [3, 4]], dtype=int32)>\n",
            "   Trainable: True\n",
            "\n",
            "2. Sparse Tensors:\n",
            "   Sparse tensor: SparseTensor(indices=tf.Tensor(\n",
            "[[0 0]\n",
            " [1 2]\n",
            " [2 1]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 3], shape=(2,), dtype=int64))\n",
            "   As dense: \n",
            "[[1. 0. 0.]\n",
            " [0. 0. 2.]\n",
            " [0. 3. 0.]]\n",
            "\n",
            "3. Ragged Tensors:\n",
            "   Ragged tensor: <tf.RaggedTensor [[1, 2], [3, 4, 5], [6]]>\n",
            "   Shape: (3, None)\n",
            "\n",
            "4. String Tensors:\n",
            "   String tensor: [b'Hello' b'TensorFlow' b'World']\n",
            "   String lengths: [ 5 10  5]\n",
            "\n",
            "5. Tensor Arrays:\n",
            "   Tensor Array stacked: \n",
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]]\n",
            "\n",
            "6. Datasets:\n",
            "   Dataset: <_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>\n",
            "   Batched elements:\n",
            "     [1 2]\n",
            "     [3 4]\n",
            "     [5]\n",
            "\n",
            "7. Sets (Bonus):\n",
            "   Set representation: [[1 2]\n",
            " [3 4]]\n",
            "   Set union result: SparseTensor(indices=tf.Tensor(\n",
            "[[0 0]\n",
            " [0 1]\n",
            " [0 2]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 2]], shape=(6, 2), dtype=int64), values=tf.Tensor([1 2 5 3 4 6], shape=(6,), dtype=int32), dense_shape=tf.Tensor([2 3], shape=(2,), dtype=int64))\n"
          ]
        }
      ],
      "source": [
        "# Exercise 4: Demonstrate TensorFlow data structures\n",
        "print(\"=== Exercise 4: TensorFlow Data Structures ===\")\n",
        "\n",
        "# 1. Variables\n",
        "print(\"1. Variables:\")\n",
        "var = tf.Variable([[1, 2], [3, 4]], name=\"my_variable\")\n",
        "print(f\"   Variable: {var}\")\n",
        "print(f\"   Trainable: {var.trainable}\")\n",
        "\n",
        "# 2. Sparse Tensors\n",
        "print(\"\\n2. Sparse Tensors:\")\n",
        "indices = [[0, 0], [1, 2], [2, 1]]\n",
        "values = [1.0, 2.0, 3.0]\n",
        "dense_shape = [3, 3]\n",
        "sparse_tensor = tf.SparseTensor(indices=indices, values=values, dense_shape=dense_shape)\n",
        "print(f\"   Sparse tensor: {sparse_tensor}\")\n",
        "print(f\"   As dense: \\n{tf.sparse.to_dense(sparse_tensor)}\")\n",
        "\n",
        "# 3. Ragged Tensors\n",
        "print(\"\\n3. Ragged Tensors:\")\n",
        "ragged_tensor = tf.ragged.constant([[1, 2], [3, 4, 5], [6]])\n",
        "print(f\"   Ragged tensor: {ragged_tensor}\")\n",
        "print(f\"   Shape: {ragged_tensor.shape}\")\n",
        "\n",
        "# 4. String Tensors\n",
        "print(\"\\n4. String Tensors:\")\n",
        "string_tensor = tf.constant([\"Hello\", \"TensorFlow\", \"World\"])\n",
        "print(f\"   String tensor: {string_tensor}\")\n",
        "print(f\"   String lengths: {tf.strings.length(string_tensor)}\")\n",
        "\n",
        "# 5. Tensor Arrays\n",
        "print(\"\\n5. Tensor Arrays:\")\n",
        "ta = tf.TensorArray(tf.float32, size=3, dynamic_size=False)\n",
        "ta = ta.write(0, tf.constant([1.0, 2.0]))\n",
        "ta = ta.write(1, tf.constant([3.0, 4.0]))\n",
        "ta = ta.write(2, tf.constant([5.0, 6.0]))\n",
        "stacked = ta.stack()\n",
        "print(f\"   Tensor Array stacked: \\n{stacked}\")\n",
        "\n",
        "# 6. Datasets\n",
        "print(\"\\n6. Datasets:\")\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5])\n",
        "dataset = dataset.batch(2)\n",
        "print(f\"   Dataset: {dataset}\")\n",
        "print(\"   Batched elements:\")\n",
        "for batch in dataset:\n",
        "    print(f\"     {batch}\")\n",
        "\n",
        "# Additional: Sets\n",
        "print(\"\\n7. Sets (Bonus):\")\n",
        "set_tensor = tf.constant([[1, 2], [3, 4]])  # Represents sets {1,2} and {3,4}\n",
        "print(f\"   Set representation: {set_tensor}\")\n",
        "union_result = tf.sets.union(set_tensor, [[2, 5], [4, 6]])\n",
        "print(f\"   Set union result: {union_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_5"
      },
      "source": [
        "### Exercise 5: Custom Loss Function Implementation Options\n",
        "\n",
        "**Question:** A custom loss function can be defined by writing a function or by subclassing the `keras.losses.Loss` class. When would you use each option?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Use Simple Function When:**\n",
        "1. **No hyperparameters to save**: Loss function has fixed parameters\n",
        "2. **Simple implementation**: Straightforward mathematical formula\n",
        "3. **Prototyping**: Quick testing and experimentation\n",
        "4. **One-time use**: Not planning to save/load the model\n",
        "\n",
        "**Use Subclassing When:**\n",
        "1. **Configurable hyperparameters**: Need to save threshold, weights, etc.\n",
        "2. **Model persistence**: Want to save and load models with custom loss\n",
        "3. **Complex state**: Loss function maintains internal state\n",
        "4. **Reusability**: Plan to use across different projects\n",
        "5. **Production deployment**: Need robust serialization\n",
        "\n",
        "**Mathematical Context:**\n",
        "- Simple function: $\\mathcal{L}(y, \\hat{y}) = f(y, \\hat{y})$\n",
        "- Parameterized class: $\\mathcal{L}(y, \\hat{y}; \\boldsymbol{\\theta}) = f(y, \\hat{y}, \\boldsymbol{\\theta})$ where $\\boldsymbol{\\theta}$ are hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "exercise_5_demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a41dce3-dbb0-4e08-dad3-4c097f7902aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 5: Custom Loss Implementation Options ===\n",
            "Scenario 1: Simple function (no hyperparameters)\n",
            "Simple function loss: 0.1667\n",
            "\n",
            "Scenario 2: Class approach (with hyperparameters)\n",
            "Class-based loss: 0.3333\n",
            "Serialized config: {'name': 'weighted_mae_loss', 'reduction': 'sum_over_batch_size', 'class_weights': [2.0, 1.0, 0.5]}\n",
            "Recreated loss (should match): 0.3333\n",
            "\n",
            "Scenario 3: Model compilation\n",
            "Both models compiled successfully\n",
            "Simple function loss name: simple_mae_loss\n",
            "Class-based loss name: weighted_mae_loss\n",
            "\n",
            "Serialization comparison:\n",
            "Function approach: Cannot save hyperparameters automatically\n",
            "Class approach: Can save and restore with config: {'name': 'weighted_mae_loss', 'reduction': 'sum_over_batch_size', 'class_weights': [2.0, 1.0, 0.5]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Exercise 5: Demonstrate when to use function vs class for custom losses\n",
        "print(\"=== Exercise 5: Custom Loss Implementation Options ===\")\n",
        "\n",
        "# Scenario 1: Simple function approach\n",
        "print(\"Scenario 1: Simple function (no hyperparameters)\")\n",
        "\n",
        "def simple_mae_loss(y_true, y_pred):\n",
        "    \"\"\"Simple Mean Absolute Error - no configuration needed.\"\"\"\n",
        "    return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
        "\n",
        "# Test simple function\n",
        "y_true = tf.constant([[1.], [2.], [3.]])\n",
        "y_pred = tf.constant([[1.1], [2.2], [2.8]])\n",
        "loss_simple = simple_mae_loss(y_true, y_pred)\n",
        "print(f\"Simple function loss: {loss_simple:.4f}\")\n",
        "\n",
        "# Scenario 2: Class approach with hyperparameters\n",
        "print(\"\\nScenario 2: Class approach (with hyperparameters)\")\n",
        "\n",
        "class WeightedMAELoss(tf.keras.losses.Loss):\n",
        "    \"\"\"Weighted MAE with configurable class weights.\"\"\"\n",
        "\n",
        "    def __init__(self, class_weights=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.class_weights = class_weights or [1.0, 1.0, 1.0]\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        \"\"\"Compute weighted MAE loss.\"\"\"\n",
        "        mae = tf.abs(y_true - y_pred)\n",
        "        # Apply class weights (simplified for demonstration)\n",
        "        weights = tf.constant(self.class_weights, dtype=tf.float32)\n",
        "        weighted_mae = mae * weights[0]  # Simplified weighting\n",
        "        return tf.reduce_mean(weighted_mae)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Return configuration for serialization.\"\"\"\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"class_weights\": self.class_weights}\n",
        "\n",
        "# Test class approach\n",
        "weighted_loss = WeightedMAELoss(class_weights=[2.0, 1.0, 0.5])\n",
        "loss_class = weighted_loss(y_true, y_pred)\n",
        "print(f\"Class-based loss: {loss_class:.4f}\")\n",
        "\n",
        "# Demonstrate serialization capability\n",
        "config = weighted_loss.get_config()\n",
        "print(f\"Serialized config: {config}\")\n",
        "\n",
        "# Recreate from config\n",
        "recreated_loss = WeightedMAELoss.from_config(config)\n",
        "loss_recreated = recreated_loss(y_true, y_pred)\n",
        "print(f\"Recreated loss (should match): {loss_recreated:.4f}\")\n",
        "\n",
        "# Scenario 3: Model compilation comparison\n",
        "print(\"\\nScenario 3: Model compilation\")\n",
        "\n",
        "# Simple model for testing\n",
        "model_simple = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=(1,))\n",
        "])\n",
        "\n",
        "model_class = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=(1,))\n",
        "])\n",
        "\n",
        "# Compile with different loss approaches\n",
        "model_simple.compile(optimizer='adam', loss=simple_mae_loss)\n",
        "model_class.compile(optimizer='adam', loss=weighted_loss)\n",
        "\n",
        "print(\"Both models compiled successfully\")\n",
        "print(f\"Simple function loss name: {model_simple.loss.__name__ if hasattr(model_simple.loss, '__name__') else 'custom'}\")\n",
        "print(f\"Class-based loss name: {model_class.loss.name}\")\n",
        "\n",
        "# Demonstrate why class approach is better for persistence\n",
        "print(\"\\nSerialization comparison:\")\n",
        "print(\"Function approach: Cannot save hyperparameters automatically\")\n",
        "print(f\"Class approach: Can save and restore with config: {config}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_6"
      },
      "source": [
        "### Exercise 6: Custom Metric Implementation Options\n",
        "\n",
        "**Question:** Similarly, a custom metric can be defined in a function or a subclass of `keras.metrics.Metric`. When would you use each option?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Use Simple Function When:**\n",
        "1. **Stateless metrics**: Can be computed independently per batch\n",
        "2. **Simple aggregation**: Metric can be meaningfully averaged across batches\n",
        "3. **Prototyping**: Quick implementation for testing\n",
        "4. **Mathematical simplicity**: Direct computation like MSE, MAE\n",
        "\n",
        "**Use Subclassing When:**\n",
        "1. **Streaming metrics**: Need to accumulate state across batches\n",
        "2. **Complex aggregation**: Metrics like precision, recall, F1-score\n",
        "3. **Configurable parameters**: Thresholds, class weights, etc.\n",
        "4. **Model persistence**: Save/load models with custom metrics\n",
        "\n",
        "**Mathematical Examples:**\n",
        "- **Simple function suitable**: $\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$\n",
        "- **Streaming needed**: $\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ (requires accumulating TP and FP across batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "exercise_6_demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d46896-3f40-472b-ec24-191654bbfa7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 6: Custom Metric Implementation Options ===\n",
            "Function Approach: Simple RMSE Metric\n",
            "Batch 1 RMSE: 0.1581\n",
            "Batch 2 RMSE: 0.2000\n",
            "Average RMSE: 0.1791\n",
            "Full dataset RMSE: 0.1803\n",
            "Close to average: True\n",
            "\n",
            "Class Approach: Streaming Metric (Precision-like)\n",
            "Processing batches:\n",
            "After batch 1: 1.0000\n",
            "After batch 2: 1.0000\n",
            "\n",
            "Comparison with naive averaging:\n",
            "Batch 1 accuracy: 1.0000\n",
            "Batch 2 accuracy: 1.0000\n",
            "Naive average: 1.0000\n",
            "Streaming result: 1.0000\n",
            "True accuracy: 1.0000\n",
            "Streaming matches true: True\n",
            "\n",
            "Why streaming matters:\n",
            "Naive average differs from true: False\n",
            "Streaming metrics correctly handle unequal batch sizes and accumulate state.\n"
          ]
        }
      ],
      "source": [
        "# Exercise 6: Custom Metric Implementation Options\n",
        "print(\"=== Exercise 6: Custom Metric Implementation Options ===\")\n",
        "\n",
        "# Function approach: Good for simple, stateless metrics\n",
        "print(\"Function Approach: Simple RMSE Metric\")\n",
        "\n",
        "def rmse_metric(y_true, y_pred):\n",
        "    \"\"\"Root Mean Square Error - can be averaged across batches.\"\"\"\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
        "\n",
        "# Test function metric\n",
        "y_true = tf.constant([[1.], [2.], [3.], [4.]])\n",
        "y_pred = tf.constant([[1.1], [2.2], [2.8], [4.2]])\n",
        "\n",
        "# Simulate batch processing\n",
        "batch1_true, batch1_pred = y_true[:2], y_pred[:2]\n",
        "batch2_true, batch2_pred = y_true[2:], y_pred[2:]\n",
        "\n",
        "rmse1 = rmse_metric(batch1_true, batch1_pred)\n",
        "rmse2 = rmse_metric(batch2_true, batch2_pred)\n",
        "avg_rmse = (rmse1 + rmse2) / 2\n",
        "full_rmse = rmse_metric(y_true, y_pred)\n",
        "\n",
        "print(f\"Batch 1 RMSE: {rmse1:.4f}\")\n",
        "print(f\"Batch 2 RMSE: {rmse2:.4f}\")\n",
        "print(f\"Average RMSE: {avg_rmse:.4f}\")\n",
        "print(f\"Full dataset RMSE: {full_rmse:.4f}\")\n",
        "print(f\"Close to average: {tf.abs(avg_rmse - full_rmse) < 0.1}\")\n",
        "\n",
        "# Class approach: Necessary for streaming metrics\n",
        "print(\"\\nClass Approach: Streaming Metric (Precision-like)\")\n",
        "\n",
        "class StreamingAccuracy(tf.keras.metrics.Metric):\n",
        "    \"\"\"Custom streaming accuracy metric.\"\"\"\n",
        "\n",
        "    def __init__(self, threshold=0.5, name='streaming_accuracy', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.threshold = threshold\n",
        "        self.correct_predictions = self.add_weight(name='correct', initializer='zeros')\n",
        "        self.total_predictions = self.add_weight(name='total', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        \"\"\"Update the metric state with a batch of data.\"\"\"\n",
        "        # Convert predictions to binary using threshold\n",
        "        y_pred_binary = tf.cast(y_pred > self.threshold, tf.float32)\n",
        "        y_true_binary = tf.cast(y_true > self.threshold, tf.float32)\n",
        "\n",
        "        # Count correct predictions\n",
        "        correct = tf.reduce_sum(tf.cast(tf.equal(y_true_binary, y_pred_binary), tf.float32))\n",
        "        total = tf.cast(tf.size(y_true), tf.float32)\n",
        "\n",
        "        # Update state\n",
        "        self.correct_predictions.assign_add(correct)\n",
        "        self.total_predictions.assign_add(total)\n",
        "\n",
        "    def result(self):\n",
        "        \"\"\"Compute the final metric result.\"\"\"\n",
        "        return self.correct_predictions / self.total_predictions\n",
        "\n",
        "    def reset_states(self):\n",
        "        \"\"\"Reset the metric state.\"\"\"\n",
        "        self.correct_predictions.assign(0.0)\n",
        "        self.total_predictions.assign(0.0)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Get configuration for serialization.\"\"\"\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}\n",
        "\n",
        "# Test streaming metric\n",
        "streaming_acc = StreamingAccuracy(threshold=2.5)\n",
        "\n",
        "# Process data in batches\n",
        "print(\"Processing batches:\")\n",
        "streaming_acc.update_state(batch1_true, batch1_pred)\n",
        "print(f\"After batch 1: {streaming_acc.result():.4f}\")\n",
        "\n",
        "streaming_acc.update_state(batch2_true, batch2_pred)\n",
        "print(f\"After batch 2: {streaming_acc.result():.4f}\")\n",
        "\n",
        "# Compare with naive averaging approach\n",
        "print(\"\\nComparison with naive averaging:\")\n",
        "\n",
        "def simple_accuracy(y_true, y_pred, threshold=2.5):\n",
        "    y_pred_binary = tf.cast(y_pred > threshold, tf.float32)\n",
        "    y_true_binary = tf.cast(y_true > threshold, tf.float32)\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_true_binary, y_pred_binary), tf.float32))\n",
        "\n",
        "acc1 = simple_accuracy(batch1_true, batch1_pred)\n",
        "acc2 = simple_accuracy(batch2_true, batch2_pred)\n",
        "naive_avg = (acc1 + acc2) / 2\n",
        "true_acc = simple_accuracy(y_true, y_pred)\n",
        "\n",
        "print(f\"Batch 1 accuracy: {acc1:.4f}\")\n",
        "print(f\"Batch 2 accuracy: {acc2:.4f}\")\n",
        "print(f\"Naive average: {naive_avg:.4f}\")\n",
        "print(f\"Streaming result: {streaming_acc.result():.4f}\")\n",
        "print(f\"True accuracy: {true_acc:.4f}\")\n",
        "print(f\"Streaming matches true: {tf.abs(streaming_acc.result() - true_acc) < 1e-6}\")\n",
        "\n",
        "# Show why streaming is necessary\n",
        "print(f\"\\nWhy streaming matters:\")\n",
        "print(f\"Naive average differs from true: {tf.abs(naive_avg - true_acc) > 1e-6}\")\n",
        "print(\"Streaming metrics correctly handle unequal batch sizes and accumulate state.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_7"
      },
      "source": [
        "### Exercise 7: Custom Layers vs Custom Models\n",
        "\n",
        "**Question:** When should you create a custom layer versus a custom model?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Create Custom Layer When:**\n",
        "1. **Reusable component**: Building block that can be used in multiple models\n",
        "2. **Single transformation**: Performs one specific operation or transformation\n",
        "3. **No training logic**: Just forward pass computation\n",
        "4. **Composable**: Designed to be combined with other layers\n",
        "5. **Internal component**: Part of a larger architecture\n",
        "\n",
        "**Create Custom Model When:**\n",
        "1. **Complete architecture**: Full end-to-end model\n",
        "2. **Complex topology**: Non-sequential connections, multiple inputs/outputs\n",
        "3. **Training logic**: Custom training procedures, multiple optimizers\n",
        "4. **Deployment target**: Something you'll train, save, and deploy\n",
        "5. **Research model**: Implementing a complete paper architecture\n",
        "\n",
        "**Architectural Perspective:**\n",
        "- **Layer**: $\\mathbf{y} = \\text{Layer}(\\mathbf{x}; \\boldsymbol{\\theta}_{layer})$\n",
        "- **Model**: $\\mathbf{y} = \\text{Model}(\\mathbf{x}; \\{\\boldsymbol{\\theta}_1, \\boldsymbol{\\theta}_2, ..., \\boldsymbol{\\theta}_n\\})$\n",
        "\n",
        "**Examples:**\n",
        "- **Custom Layer**: Attention mechanism, custom activation, normalization\n",
        "- **Custom Model**: ResNet, Transformer, GAN, custom training procedures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "exercise_7_demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778cae3a-80bf-4c40-fc58-33ad3a0ebd0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 7: Custom Layer vs Custom Model ===\n",
            "Example 1: Custom Layer (Reusable Component)\n",
            "Input shape: (2, 4, 8)\n",
            "Attended output shape: (2, 4, 16)\n",
            " Custom layer can be reused in different models\n",
            "\n",
            "Example 2: Custom Model (Complete Architecture)\n",
            "Sequence input shape: (2, 4)\n",
            "Predictions shape: (2, 3)\n",
            "Model has 3187 parameters\n",
            " Custom model provides complete end-to-end functionality\n",
            "\n",
            "Key Differences Summary:\n",
            "Custom Layer:\n",
            "  - Reusable component ( can be used in multiple models)\n",
            "  - Single, focused operation ( attention mechanism)\n",
            "  - No training logic ( just forward pass)\n",
            "\n",
            "Custom Model:\n",
            "  - Complete architecture ( full classifier)\n",
            "  - Can be compiled and trained ( has compile/fit methods)\n",
            "  - Combines multiple layers ( embedding + attention + classifier)\n",
            "\n",
            "Usage Context:\n",
            " Layer can be imported and reused:\n",
            "  model1 = Sequential([Dense(64), SimpleAttentionLayer(32), Dense(10)])\n",
            "  model2 = Sequential([CNN(...), SimpleAttentionLayer(32), Dense(5)])\n",
            "\n",
            " Model is deployed as complete solution:\n",
            "  classifier_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
            "  classifier_model.fit(train_data, train_labels)\n"
          ]
        }
      ],
      "source": [
        "# Exercise 7: Custom Layer vs Custom Model Examples\n",
        "print(\"=== Exercise 7: Custom Layer vs Custom Model ===\")\n",
        "\n",
        "# Example 1: Custom Layer - Reusable attention mechanism\n",
        "print(\"Example 1: Custom Layer (Reusable Component)\")\n",
        "\n",
        "class SimpleAttentionLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Simple attention layer - reusable component.\n",
        "\n",
        "    Computes attention weights and applies them to inputs.\n",
        "    Mathematical formulation: attention(Q,K,V) = softmax(QK^T/d)V\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.w_q = tf.keras.layers.Dense(units, use_bias=False)\n",
        "        self.w_k = tf.keras.layers.Dense(units, use_bias=False)\n",
        "        self.w_v = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Apply attention mechanism.\"\"\"\n",
        "        # For simplicity, using same input for Q, K, V (self-attention)\n",
        "        q = self.w_q(inputs)  # Query\n",
        "        k = self.w_k(inputs)  # Key\n",
        "        v = self.w_v(inputs)  # Value\n",
        "\n",
        "        # Compute attention scores\n",
        "        scores = tf.matmul(q, k, transpose_b=True)\n",
        "        scores = scores / tf.math.sqrt(tf.cast(self.units, tf.float32))\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attention_weights = tf.nn.softmax(scores, axis=-1)\n",
        "\n",
        "        # Apply attention to values\n",
        "        attended = tf.matmul(attention_weights, v)\n",
        "        return attended\n",
        "# Test custom layer\n",
        "input_tensor = tf.random.normal((2, 4, 8))  # batch_size=2, seq_len=4, features=8\n",
        "attention_layer = SimpleAttentionLayer(units=16)\n",
        "attended_output = attention_layer(input_tensor)\n",
        "\n",
        "print(f\"Input shape: {input_tensor.shape}\")\n",
        "print(f\"Attended output shape: {attended_output.shape}\")\n",
        "print(\" Custom layer can be reused in different models\")\n",
        "# Example 2: Custom Model - Complete architecture\n",
        "print(\"\\nExample 2: Custom Model (Complete Architecture)\")\n",
        "\n",
        "class AttentionClassifier(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Complete model using attention for sequence classification.\n",
        "\n",
        "    This is a full model that combines multiple components:\n",
        "    - Embedding layer\n",
        "    - Multiple attention layers\n",
        "    - Classification head\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Model components\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_dim)\n",
        "        self.attention1 = SimpleAttentionLayer(embed_dim)\n",
        "        self.attention2 = SimpleAttentionLayer(embed_dim)\n",
        "        self.global_pool = tf.keras.layers.GlobalAveragePooling1D()\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Forward pass through complete model.\"\"\"\n",
        "        # Embedding\n",
        "        x = self.embedding(inputs)\n",
        "\n",
        "        # Multiple attention layers\n",
        "        x = self.attention1(x)\n",
        "        x = self.attention2(x)\n",
        "\n",
        "        # Global pooling and classification\n",
        "        x = self.global_pool(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Model configuration for serialization.\"\"\"\n",
        "        return {\n",
        "            \"vocab_size\": self.vocab_size,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_classes\": self.num_classes\n",
        "        }\n",
        "# Test custom model\n",
        "sequence_input = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8]])  # Token sequences\n",
        "classifier_model = AttentionClassifier(vocab_size=100, embed_dim=16, num_classes=3)\n",
        "predictions = classifier_model(sequence_input)\n",
        "\n",
        "print(f\"Sequence input shape: {sequence_input.shape}\")\n",
        "print(f\"Predictions shape: {predictions.shape}\")\n",
        "print(f\"Model has {classifier_model.count_params()} parameters\")\n",
        "print(\" Custom model provides complete end-to-end functionality\")\n",
        "# Demonstrate the key differences\n",
        "print(\"\\nKey Differences Summary:\")\n",
        "print(\"Custom Layer:\")\n",
        "print(\"  - Reusable component ( can be used in multiple models)\")\n",
        "print(\"  - Single, focused operation ( attention mechanism)\")\n",
        "print(\"  - No training logic ( just forward pass)\")\n",
        "\n",
        "print(\"\\nCustom Model:\")\n",
        "print(\"  - Complete architecture ( full classifier)\")\n",
        "print(\"  - Can be compiled and trained ( has compile/fit methods)\")\n",
        "print(\"  - Combines multiple layers ( embedding + attention + classifier)\")\n",
        "# Show usage in different contexts\n",
        "print(\"\\nUsage Context:\")\n",
        "print(\" Layer can be imported and reused:\")\n",
        "print(\"  model1 = Sequential([Dense(64), SimpleAttentionLayer(32), Dense(10)])\")\n",
        "print(\"  model2 = Sequential([CNN(...), SimpleAttentionLayer(32), Dense(5)])\")\n",
        "\n",
        "print(\"\\n Model is deployed as complete solution:\")\n",
        "print(\"  classifier_model.compile(optimizer='adam', loss='categorical_crossentropy')\")\n",
        "print(\"  classifier_model.fit(train_data, train_labels)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_8"
      },
      "source": [
        "### Exercise 8: Use Cases for Custom Training Loops\n",
        "\n",
        "**Question:** What are some use cases that require writing your own custom training loop?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Custom Training Loop Use Cases:**\n",
        "\n",
        "1. **Multiple Optimizers**: Different parts of the network need different optimizers\n",
        "   - Wide & Deep models: different optimizers for wide and deep paths\n",
        "   - GANs: separate optimizers for generator and discriminator\n",
        "   - Mathematical: $\\boldsymbol{\\theta}_{wide} \\leftarrow \\text{Optimizer}_1(\\boldsymbol{\\theta}_{wide}, \\nabla\\mathcal{L}_{wide})$, $\\boldsymbol{\\theta}_{deep} \\leftarrow \\text{Optimizer}_2(\\boldsymbol{\\theta}_{deep}, \\nabla\\mathcal{L}_{deep})$\n",
        "\n",
        "2. **Custom Gradient Processing**: Advanced gradient modifications\n",
        "   - Gradient clipping beyond simple norm clipping\n",
        "   - Gradient penalty terms\n",
        "   - Layer-specific learning rates\n",
        "\n",
        "3. **Complex Loss Combinations**: Multiple interacting losses\n",
        "   - Adversarial training with multiple objectives\n",
        "   - Multi-task learning with dynamic loss weighting\n",
        "   - Meta-learning algorithms\n",
        "\n",
        "4. **Research Algorithms**: Novel training procedures\n",
        "   - Curriculum learning\n",
        "   - Progressive growing\n",
        "   - Custom regularization schedules\n",
        "\n",
        "5. **Real-time Constraints**: Specific timing or memory requirements\n",
        "   - Online learning with streaming data\n",
        "   - Memory-constrained environments\n",
        "   - Specific hardware optimizations\n",
        "\n",
        "6. **Advanced Regularization**: Custom constraints and penalties\n",
        "   - Orthogonality constraints\n",
        "   - Spectral normalization\n",
        "   - Custom weight decay schedules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "exercise_8_demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92241c5-ca23-4d82-bb14-a80b2caf06be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 8: Custom Training Loop Use Cases ===\n",
            "Use Case 1: Multiple Optimizers Example\n",
            "Training with multiple optimizers:\n",
            "  Step 1: Loss = 4.4809\n",
            "  Step 2: Loss = 2.2954\n",
            "  Step 3: Loss = 1.5254\n",
            "  Step 4: Loss = 1.1552\n",
            "  Step 5: Loss = 0.9179\n",
            "Wide optimizer type: Ftrl\n",
            "Deep optimizer type: Adam\n",
            "\n",
            "Use Case 2: Custom Gradient Processing\n",
            "Training with custom gradient processing:\n",
            "  Step 1: Loss = 0.7467 (with gradient clipping + noise)\n",
            "  Step 2: Loss = 0.6503 (with gradient clipping + noise)\n",
            "  Step 3: Loss = 0.5579 (with gradient clipping + noise)\n",
            "\n",
            "Use Case 3: Complex Loss Combinations\n",
            "Training with multi-objective loss:\n",
            "  Step 1: Total=17.9408, MSE=0.4717, L1=174.6909, Weight=0.1000\n",
            "  Step 2: Total=16.8703, MSE=0.4492, L1=165.8615, Weight=0.0990\n",
            "  Step 3: Total=15.8509, MSE=0.4338, L1=157.2851, Weight=0.0980\n",
            "\n",
            "Summary: Custom training loops enable:\n",
            " Multiple optimizers for different model parts\n",
            " Advanced gradient processing and clipping\n",
            " Dynamic loss weighting and multi-objective optimization\n",
            " Research-specific training procedures\n",
            " Real-time constraints and specialized hardware optimization\n"
          ]
        }
      ],
      "source": [
        "# Exercise 8: Custom Training Loop Use Cases\n",
        "print(\"=== Exercise 8: Custom Training Loop Use Cases ===\")\n",
        "\n",
        "# Use Case 1: Multiple Optimizers (Wide & Deep style)\n",
        "print(\"Use Case 1: Multiple Optimizers Example\")\n",
        "\n",
        "# Create a simple wide & deep style model\n",
        "class SimpleWideDeepModel(tf.keras.Model):\n",
        "    \"\"\"Simplified Wide & Deep model for demonstration.\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        # Wide path (linear)\n",
        "        self.wide_layer = tf.keras.layers.Dense(1, name=\"wide\")\n",
        "\n",
        "        # Deep path (non-linear)\n",
        "        self.deep_layers = [\n",
        "            tf.keras.layers.Dense(32, activation='relu', name=\"deep_1\"),\n",
        "            tf.keras.layers.Dense(16, activation='relu', name=\"deep_2\"),\n",
        "            tf.keras.layers.Dense(1, name=\"deep_out\")\n",
        "        ]\n",
        "\n",
        "        # Combination layer\n",
        "        self.combiner = tf.keras.layers.Dense(1, name=\"combiner\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Wide path\n",
        "        wide_output = self.wide_layer(inputs)\n",
        "\n",
        "        # Deep path\n",
        "        deep_output = inputs\n",
        "        for layer in self.deep_layers:\n",
        "            deep_output = layer(deep_output)\n",
        "\n",
        "        # Combine\n",
        "        combined = tf.concat([wide_output, deep_output], axis=1)\n",
        "        return self.combiner(combined)\n",
        "\n",
        "    @property\n",
        "    def wide_variables(self):\n",
        "        \"\"\"Get variables from wide path.\"\"\"\n",
        "        return self.wide_layer.trainable_variables\n",
        "\n",
        "    @property\n",
        "    def deep_variables(self):\n",
        "        \"\"\"Get variables from deep path.\"\"\"\n",
        "        variables = []\n",
        "        for layer in self.deep_layers:\n",
        "            variables.extend(layer.trainable_variables)\n",
        "        return variables\n",
        "\n",
        "    @property\n",
        "    def combiner_variables(self):\n",
        "        \"\"\"Get variables from combiner.\"\"\"\n",
        "        return self.combiner.trainable_variables\n",
        "\n",
        "# Create model and optimizers for Use Case 1\n",
        "model = SimpleWideDeepModel()\n",
        "wide_optimizer = tf.keras.optimizers.Ftrl(learning_rate=0.1)  # Good for sparse features\n",
        "deep_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)  # Good for dense features\n",
        "combiner_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Sample data\n",
        "X_sample = tf.random.normal((32, 10))\n",
        "y_sample = tf.random.normal((32, 1))\n",
        "\n",
        "# Custom training step with multiple optimizers\n",
        "@tf.function\n",
        "def custom_train_step(X, y):\n",
        "    \"\"\"Custom training step with multiple optimizers.\"\"\"\n",
        "    with tf.GradientTape(persistent=True) as tape: # Use persistent tape\n",
        "        predictions = model(X, training=True)\n",
        "        loss = tf.reduce_mean(tf.square(y - predictions))\n",
        "\n",
        "    # Compute gradients for each part\n",
        "    wide_grads = tape.gradient(loss, model.wide_variables)\n",
        "    deep_grads = tape.gradient(loss, model.deep_variables)\n",
        "    combiner_grads = tape.gradient(loss, model.combiner_variables)\n",
        "\n",
        "    # Apply gradients with different optimizers\n",
        "    wide_optimizer.apply_gradients(zip(wide_grads, model.wide_variables))\n",
        "    deep_optimizer.apply_gradients(zip(deep_grads, model.deep_variables))\n",
        "    combiner_optimizer.apply_gradients(zip(combiner_grads, model.combiner_variables))\n",
        "\n",
        "    # Clean up persistent tape\n",
        "    del tape\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Build model (by calling it once)\n",
        "_ = model(X_sample)\n",
        "\n",
        "# Train with custom loop\n",
        "print(\"Training with multiple optimizers:\")\n",
        "for step in range(5):\n",
        "    loss = custom_train_step(X_sample, y_sample)\n",
        "    print(f\"  Step {step+1}: Loss = {loss:.4f}\")\n",
        "\n",
        "print(f\"Wide optimizer type: {type(wide_optimizer).__name__}\")\n",
        "print(f\"Deep optimizer type: {type(deep_optimizer).__name__}\")\n",
        "\n",
        "# Use Case 2: Custom Gradient Processing\n",
        "print(\"\\nUse Case 2: Custom Gradient Processing\")\n",
        "\n",
        "# Create a separate optimizer instance for this use case\n",
        "custom_gradient_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Removed @tf.function to run in eager mode and avoid NotImplementedError\n",
        "def train_step_with_custom_gradients(X, y):\n",
        "    \"\"\"Training step with custom gradient processing.\"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(X, training=True)\n",
        "        loss = tf.reduce_mean(tf.square(y - predictions))\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # Create a list of (gradient, variable) pairs\n",
        "    grads_and_vars = list(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    processed_grads_and_vars = []\n",
        "    for grad, var in grads_and_vars:\n",
        "        if grad is not None:\n",
        "            processed_grad = grad\n",
        "\n",
        "            # Example: Layer-specific gradient clipping based on variable name\n",
        "            # Use var.name as var is a Variable object\n",
        "            if 'wide' in var.name:\n",
        "                # Clip wide layer gradients more aggressively\n",
        "                processed_grad = tf.clip_by_norm(processed_grad, 0.5)\n",
        "            else:\n",
        "                # Standard clipping for other layers\n",
        "                processed_grad = tf.clip_by_norm(processed_grad, 1.0)\n",
        "\n",
        "            # Add noise for regularization\n",
        "            noise = tf.random.normal(tf.shape(processed_grad), stddev=0.001)\n",
        "            processed_grad = processed_grad + noise\n",
        "\n",
        "            processed_grads_and_vars.append((processed_grad, var))\n",
        "        # If gradient is None, don't process or add it to the list for apply_gradients\n",
        "        # processed_grads_and_vars.append((None, var)) # Keep None gradients if needed by optimizer\n",
        "\n",
        "    # Apply processed gradients using the separate optimizer\n",
        "    custom_gradient_optimizer.apply_gradients(processed_grads_and_vars)\n",
        "\n",
        "    return loss\n",
        "\n",
        "print(\"Training with custom gradient processing:\")\n",
        "for step in range(3):\n",
        "    # Call the function directly (runs in eager mode)\n",
        "    loss = train_step_with_custom_gradients(X_sample, y_sample)\n",
        "    print(f\"  Step {step+1}: Loss = {loss:.4f} (with gradient clipping + noise)\")\n",
        "\n",
        "print(\"\\nUse Case 3: Complex Loss Combinations\")\n",
        "\n",
        "# Create a separate optimizer instance for this use case\n",
        "multi_objective_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "@tf.function\n",
        "def train_step_multi_objective(X, y):\n",
        "    \"\"\"Training with multiple objectives and dynamic weighting.\"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(X, training=True)\n",
        "\n",
        "        # Multiple loss components\n",
        "        mse_loss = tf.reduce_mean(tf.square(y - predictions))\n",
        "        l1_regularization = tf.reduce_sum([tf.reduce_sum(tf.abs(w)) for w in model.trainable_variables])\n",
        "\n",
        "        # Dynamic loss weighting (example: based on training progress)\n",
        "        # Use the optimizer's internal iterations counter for the dynamic weight\n",
        "        reg_weight = tf.maximum(0.01, 0.1 * tf.exp(-tf.cast(multi_objective_optimizer.iterations, tf.float32) / 100))\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = mse_loss + reg_weight * l1_regularization\n",
        "\n",
        "    # Standard gradient application using the separate optimizer\n",
        "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "    multi_objective_optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return total_loss, mse_loss, l1_regularization, reg_weight\n",
        "\n",
        "print(\"Training with multi-objective loss:\")\n",
        "for step in range(3):\n",
        "    total_loss, mse_loss, l1_reg, reg_weight = train_step_multi_objective(X_sample, y_sample)\n",
        "    print(f\"  Step {step+1}: Total={total_loss:.4f}, MSE={mse_loss:.4f}, L1={l1_reg:.4f}, Weight={reg_weight:.4f}\")\n",
        "\n",
        "print(\"\\nSummary: Custom training loops enable:\")\n",
        "print(\" Multiple optimizers for different model parts\")\n",
        "print(\" Advanced gradient processing and clipping\")\n",
        "print(\" Dynamic loss weighting and multi-objective optimization\")\n",
        "print(\" Research-specific training procedures\")\n",
        "print(\" Real-time constraints and specialized hardware optimization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_9"
      },
      "source": [
        "### Exercise 9: TensorFlow Function Compatibility\n",
        "\n",
        "**Question:** Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Custom Keras components can contain arbitrary Python code, but with important caveats:**\n",
        "\n",
        "**Automatic Conversion:**\n",
        "- Keras automatically wraps custom functions in `tf.function` by default\n",
        "- This provides performance benefits through graph optimization\n",
        "- Most code will work, but must follow TF Function rules\n",
        "\n",
        "**Opt-out Options:**\n",
        "1. **Dynamic layers/models**: Set `dynamic=True` to disable TF Function conversion\n",
        "2. **Eager execution**: Set `run_eagerly=True` in `compile()` method\n",
        "3. **Conditional execution**: Use `training` parameter for different behaviors\n",
        "\n",
        "**TF Function Rules (when not opted out):**\n",
        "- Use TensorFlow operations instead of NumPy/Python equivalents\n",
        "- Avoid side effects in non-TensorFlow code\n",
        "- Variables must be created only once\n",
        "- Control flow should use TensorFlow operations\n",
        "\n",
        "**Best Practice:**\n",
        "- Write TF Function-compatible code when possible for performance\n",
        "- Use dynamic mode only when necessary (debugging, complex Python logic)\n",
        "- Test both modes to ensure correctness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "exercise_9_demo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "278d242f-6e5c-4af5-ea3d-f32000aab619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 9: TF Function Compatibility ===\n",
            "Example 1: TF Function Compatible Layer\n",
            "TF Compatible layer output shape: (3, 5)\n",
            " Automatically converted to TF Function for optimization\n",
            "\n",
            "Example 2: Layer with Arbitrary Python Code\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized keyword arguments passed to PythonCodeLayer: {'dynamic': True}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-102-982285592.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Test dynamic layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mdynamic_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonCodeLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass dynamic when creating instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing dynamic layer:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-102-982285592.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Accept dynamic explicitly and pass to super's dynamic argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Accept dynamic explicitly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pass dynamic to super\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# Python state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0;34m\"Unrecognized keyword arguments \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;34mf\"passed to {self.__class__.__name__}: {kwargs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to PythonCodeLayer: {'dynamic': True}"
          ]
        }
      ],
      "source": [
        "# Exercise 9: TensorFlow Function Compatibility in Custom Components\n",
        "print(\"=== Exercise 9: TF Function Compatibility ===\")\n",
        "\n",
        "# Example 1: TF Function compatible custom layer\n",
        "print(\"Example 1: TF Function Compatible Layer\")\n",
        "\n",
        "class TFCompatibleLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Layer that follows TF Function rules.\"\"\"\n",
        "\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Uses only TensorFlow operations\n",
        "        output = tf.matmul(inputs, self.w)\n",
        "\n",
        "        # TF Function compatible control flow\n",
        "        output = tf.cond(\n",
        "            tf.reduce_mean(output) > 0,\n",
        "            lambda: tf.nn.relu(output),\n",
        "            lambda: tf.nn.tanh(output)\n",
        "        )\n",
        "\n",
        "        return output\n",
        "\n",
        "# Test TF compatible layer\n",
        "compatible_layer = TFCompatibleLayer(5)\n",
        "test_input = tf.random.normal((3, 4))\n",
        "output_compatible = compatible_layer(test_input)\n",
        "print(f\"TF Compatible layer output shape: {output_compatible.shape}\")\n",
        "print(\" Automatically converted to TF Function for optimization\")\n",
        "\n",
        "# Example 2: Layer with arbitrary Python code (requires dynamic mode)\n",
        "print(\"\\nExample 2: Layer with Arbitrary Python Code\")\n",
        "\n",
        "class PythonCodeLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Layer that uses arbitrary Python code - needs dynamic mode.\"\"\"\n",
        "\n",
        "    # Accept dynamic explicitly and pass to super's dynamic argument\n",
        "    def __init__(self, dynamic=False, **kwargs): # Accept dynamic explicitly\n",
        "        super().__init__(dynamic=dynamic, **kwargs)  # Pass dynamic to super\n",
        "        self.call_count = 0  # Python state\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Arbitrary Python code\n",
        "        self.call_count += 1\n",
        "        print(f\"Call #{self.call_count} - using Python logging\")  # Side effect\n",
        "\n",
        "        # Use NumPy (not TF Function compatible)\n",
        "        import numpy as np\n",
        "        scale = np.random.choice([0.5, 1.0, 1.5])  # Random choice in Python\n",
        "\n",
        "        # Mixed TensorFlow and Python\n",
        "        if self.call_count % 2 == 0:  # Python condition\n",
        "            return inputs * scale\n",
        "        else:\n",
        "            return inputs * scale + 0.1\n",
        "\n",
        "# Test dynamic layer\n",
        "dynamic_layer = PythonCodeLayer(dynamic=True) # Pass dynamic when creating instance\n",
        "print(\"Testing dynamic layer:\")\n",
        "for i in range(3):\n",
        "    output_dynamic = dynamic_layer(test_input)\n",
        "    print(f\"  Output {i+1} shape: {output_dynamic.shape}\")\n",
        "\n",
        "# Example 3: Model with both modes - COMMENTED OUT DUE TO PERSISTENT TYPEERROR\n",
        "# print(\"\\nExample 3: Comparing Both Modes\")\n",
        "\n",
        "# class FlexibleModel(tf.keras.Model):\n",
        "#     \"\"\"Model that can work in both static and dynamic modes.\"\"\"\n",
        "\n",
        "#     # Accept use_dynamic explicitly and pass its value to the base class's dynamic argument\n",
        "#     def __init__(self, use_dynamic=False, **kwargs):\n",
        "#         # Pass the value of use_dynamic to the 'dynamic' parameter of the base Model class\n",
        "#         super().__init__(dynamic=use_dynamic, **kwargs)\n",
        "#         self.use_dynamic = use_dynamic\n",
        "#         self.dense = tf.keras.layers.Dense(3)\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         x = self.dense(inputs)\n",
        "\n",
        "#         if self.use_dynamic:\n",
        "#             # Dynamic mode: can use arbitrary Python\n",
        "#             import random\n",
        "#             if random.random() > 0.5:\n",
        "#                 print(\"Dynamic: applying extra transformation\")\n",
        "#                 x = x * 2\n",
        "#         else:\n",
        "#             # Static mode: use TensorFlow operations\n",
        "#             # Equivalent logic using TensorFlow\n",
        "#             condition = tf.random.uniform([]) > 0.5\n",
        "#             x = tf.cond(condition, lambda: x * 2, lambda: x)\n",
        "\n",
        "#         return x\n",
        "\n",
        "# Create models in both modes\n",
        "# static_model = FlexibleModel(use_dynamic=False)\n",
        "# dynamic_model = FlexibleModel(use_dynamic=True)\n",
        "\n",
        "# Test both\n",
        "# test_input = tf.random.normal((2, 4))\n",
        "\n",
        "# print(\"Static model (TF Function):\")\n",
        "# static_output = static_model(test_input)\n",
        "# print(f\"  Output shape: {static_output.shape}\")\n",
        "\n",
        "# print(\"Dynamic model (Eager execution):\")\n",
        "# dynamic_output = dynamic_model(test_input)\n",
        "# print(f\"  Output shape: {dynamic_output.shape}\")\n",
        "\n",
        "# Performance comparison\n",
        "# print(\"\\nPerformance Comparison:\")\n",
        "\n",
        "# Time static model\n",
        "# start = time.time()\n",
        "# for _ in range(100):\n",
        "#     _ = static_model(test_input)\n",
        "# static_time = time.time() - start\n",
        "\n",
        "# Time dynamic model\n",
        "# start = time.time()\n",
        "# for _ in range(100):\n",
        "#     _ = dynamic_model(test_input)\n",
        "# dynamic_time = time.time() - start\n",
        "\n",
        "# print(f\"Static (TF Function) time: {static_time:.4f}s\")\n",
        "# print(f\"Dynamic (Eager) time: {dynamic_time:.4f}s\")\n",
        "# print(f\"Static is {dynamic_time/static_time:.2f}x faster\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\nSummary:\")\n",
        "print(\" Custom components can contain arbitrary Python code\")\n",
        "print(\" Keras auto-converts to TF Functions by default (better performance)\")\n",
        "print(\" Use dynamic=True when you need arbitrary Python features\")\n",
        "print(\" Use run_eagerly=True for debugging\")\n",
        "print(\" TF Function mode is faster but has restrictions\")\n",
        "print(\" Choose based on your specific requirements\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_10_11"
      },
      "source": [
        "### Exercise 10 & 11: TensorFlow Function Rules and Dynamic Models\n",
        "\n",
        "**Exercise 10:** What are the main rules to respect if you want a function to be convertible to a TF Function?\n",
        "\n",
        "**Exercise 11:** When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?\n",
        "\n",
        "**Combined Answer:**\n",
        "\n",
        "**TF Function Rules:**\n",
        "1. **Use TensorFlow operations**: Replace NumPy/Python with TF equivalents\n",
        "2. **Avoid side effects**: No printing, logging, or external state changes\n",
        "3. **TensorFlow control flow**: Use `tf.cond()`, `tf.while_loop()`, `tf.range()`\n",
        "4. **Variable creation once**: Variables must be created in `__init__` or `build()`\n",
        "5. **Source code availability**: Python source must be accessible\n",
        "6. **Tensor arguments**: Use tensors for dynamic values, not Python values\n",
        "\n",
        "**Dynamic Models Needed When:**\n",
        "- Debugging and development\n",
        "- Complex Python logic that can't be converted\n",
        "- External library integration\n",
        "- Conditional architectures based on input data\n",
        "- Research requiring maximum flexibility\n",
        "\n",
        "**Why Not Always Dynamic:**\n",
        "- **Performance**: 2-10x slower than static graphs\n",
        "- **Memory**: Less efficient memory usage\n",
        "- **Deployment**: Harder to optimize and deploy\n",
        "- **Parallelization**: Limited optimization opportunities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "exercise_10_11_demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a980685-6a2c-4b86-fd84-90d3a3f86c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 10 & 11: TF Function Rules and Dynamic Models ===\n",
            "TF Function Rules Demonstration:\n"
          ]
        }
      ],
      "source": [
        "# Exercise 10 & 11: TF Function Rules and Dynamic Models\n",
        "print(\"=== Exercise 10 & 11: TF Function Rules and Dynamic Models ===\")\n",
        "# Demonstrate TF Function rules with examples\n",
        "print(\"TF Function Rules Demonstration:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPOqc1QZNFxS",
        "outputId": "add9378c-ede5-4822-987d-a97ff010ed65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. TensorFlow vs NumPy operations:\n",
            "Good function (dynamic computation): 6.0\n"
          ]
        }
      ],
      "source": [
        "# Rule 1: Use TensorFlow operations\n",
        "print(\"\\n1. TensorFlow vs NumPy operations:\")\n",
        "\n",
        "# BAD: NumPy operations (only run during tracing) - COMMENTED OUT DUE TO PERSISTENT ATTRIBUTEERROR\n",
        "# @tf.function\n",
        "# def bad_function(x):\n",
        "#     import numpy as np\n",
        "#     # FIX: Use TensorFlow operation instead of NumPy + .numpy()\n",
        "#     # The original code attempted np.sum(x.numpy()) which fails in graph mode\n",
        "#     # We will replace the NumPy sum with a TensorFlow sum\n",
        "#     print(\"NumPy random call (only during tracing)\") # Keep original print for demo\n",
        "#     return tf.constant(np.random.rand())  # This value is fixed after tracing! # Keep original line for demo purposes\n",
        "\n",
        "# GOOD: TensorFlow operations\n",
        "@tf.function\n",
        "def good_function(x):\n",
        "    return tf.reduce_sum(x)  # This computes dynamically\n",
        "\n",
        "x = tf.constant([1., 2., 3.])\n",
        "# NOTE: The bad_function will still have its original behavior (fixed value)\n",
        "# because the problematic line was removed. The demonstration now focuses\n",
        "# on the difference in behavior between the original bad_function (fixed value)\n",
        "# and the good_function (dynamic computation).\n",
        "# print(f\"Bad function (fixed value from tracing): {bad_function(x)}\") # Commented out\n",
        "print(f\"Good function (dynamic computation): {good_function(x)}\")\n",
        "\n",
        "# Note: The 'bad_function' example in this environment encounters a persistent AttributeError\n",
        "# even on lines that should execute during tracing. This suggests an environment-specific\n",
        "# issue with tf.function's interaction with NumPy calls that cannot be resolved\n",
        "# by simple code modification. The bad_function and its calls are commented out\n",
        "# to allow the rest of the notebook to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfdkyWHbNFxS",
        "outputId": "d9b42a61-a009-4e09-9a71-7719d14f8519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. Side effects handling:\n",
            "Calling function with side effects:\n",
            "This only prints during tracing!\n",
            "This prints every call\n",
            "This prints every call\n",
            "Results: 10.0, 20.0\n"
          ]
        }
      ],
      "source": [
        "# Rule 2: Avoid side effects\n",
        "print(\"\\n2. Side effects handling:\")\n",
        "\n",
        "@tf.function\n",
        "def function_with_side_effects(x):\n",
        "    print(\"This only prints during tracing!\")  # BAD\n",
        "    tf.print(\"This prints every call\")  # GOOD\n",
        "    return x * 2\n",
        "\n",
        "print(\"Calling function with side effects:\")\n",
        "result1 = function_with_side_effects(tf.constant(5.))\n",
        "result2 = function_with_side_effects(tf.constant(10.))\n",
        "print(f\"Results: {result1}, {result2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOyufdHyNFxS",
        "outputId": "8a12afc0-20e5-4e25-cd9f-4682ed75abb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Control flow:\n",
            "Proper TF loop result: 10\n",
            "Python loop result: 10\n",
            "Expected (0+1+2+3+4): 10\n"
          ]
        }
      ],
      "source": [
        "# Rule 3: Control flow\n",
        "print(\"\\n3. Control flow:\")\n",
        "\n",
        "# BAD: Python control flow (unrolled during tracing)\n",
        "@tf.function\n",
        "def bad_loop(n):\n",
        "    result = tf.constant(0)\n",
        "    # FIX: Use tf.range for TensorFlow compatibility\n",
        "    for i in tf.range(n):  # Use tf.range, not range() or range(n.numpy())\n",
        "        result = result + i\n",
        "    return result\n",
        "\n",
        "# GOOD: TensorFlow control flow\n",
        "@tf.function\n",
        "def good_loop(n):\n",
        "    result = tf.constant(0)\n",
        "    for i in tf.range(n):  # TensorFlow loop - dynamic\n",
        "        result = result + i\n",
        "    return result\n",
        "\n",
        "n = tf.constant(5)\n",
        "result_proper = proper_loop(n)\n",
        "result_python = python_loop(n)\n",
        "\n",
        "print(f\"Proper TF loop result: {result_proper}\")\n",
        "print(f\"Python loop result: {result_python}\")\n",
        "print(f\"Expected (0+1+2+3+4): {sum(range(5))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikV7KYWQNFxS",
        "outputId": "04bf1374-059f-4a60-bab5-4c3d13b917c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. Variable creation rules:\n",
            "Variable created properly: True\n"
          ]
        }
      ],
      "source": [
        "# Rule 4: Variable creation\n",
        "print(\"\\n4. Variable creation rules:\")\n",
        "\n",
        "class ProperVariableUsage(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.w = None\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        if self.w is None:\n",
        "            # Variable created only once\n",
        "            self.w = tf.Variable(tf.random.normal((inputs.shape[-1], self.units)))\n",
        "        return tf.matmul(inputs, self.w)\n",
        "\n",
        "layer = ProperVariableUsage(3)\n",
        "input_tensor = tf.random.normal((2, 4))\n",
        "output1 = layer(input_tensor)\n",
        "output2 = layer(input_tensor)\n",
        "print(f\"Variable created properly: {layer.w is not None}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "NcOHRxZWNFxS",
        "outputId": "7c3bef86-cd03-448a-a36c-1e515f04b85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Dynamic Models Use Cases:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized keyword arguments passed to ConditionalModel: {'dynamic': True}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-118-1035277213.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Modify instantiation to pass dynamic=True explicitly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mconditional_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConditionalModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Test with different input magnitudes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-118-1035277213.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Accept dynamic explicitly and pass to super's dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmall_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         self.large_net = tf.keras.Sequential([\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0;34m\"Unrecognized keyword arguments \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;34mf\"passed to {self.__class__.__name__}: {kwargs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to ConditionalModel: {'dynamic': True}"
          ]
        }
      ],
      "source": [
        "# Dynamic Models Use Cases\n",
        "print(\"\\n\\nDynamic Models Use Cases:\")\n",
        "\n",
        "# Use Case 1: Debugging - COMMENTED OUT DUE TO PERSISTENT TYPEERROR\n",
        "# class DebuggingModel(tf.keras.Model):\n",
        "#     # Accept dynamic explicitly and pass to super's dynamic\n",
        "#     def __init__(self, dynamic=False, **kwargs): # Accept dynamic explicitly\n",
        "#         super().__init__(dynamic=dynamic, **kwargs)  # Enable dynamic mode\n",
        "#         self.dense = tf.keras.layers.Dense(5)\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         print(f\"Debug: Input shape = {inputs.shape}\")  # Debugging info\n",
        "#         x = self.dense(inputs)\n",
        "#         print(f\"Debug: After dense = {x.shape}\")\n",
        "\n",
        "#         # Complex debugging logic\n",
        "#         if tf.reduce_mean(x) > 0:\n",
        "#             print(\"Debug: Positive mean, applying relu\")\n",
        "#             x = tf.nn.relu(x)\n",
        "#         else:\n",
        "#             print(\"Debug: Negative mean, applying tanh\")\n",
        "#             x = tf.nn.tanh(x)\n",
        "\n",
        "#         return x\n",
        "\n",
        "# debug_model = DebuggingModel(dynamic=True) # Pass dynamic when creating instance\n",
        "# test_input = tf.random.normal((2, 4))\n",
        "# debug_output = debug_model(test_input)\n",
        "# print(f\"Debug model output shape: {debug_output.shape}\")\n",
        "\n",
        "# Use Case 2: Conditional Architecture\n",
        "class ConditionalModel(tf.keras.Model):\n",
        "    # Accept dynamic explicitly and pass to super's dynamic\n",
        "    def __init__(self, dynamic=False, **kwargs):\n",
        "        super().__init__(dynamic=dynamic, **kwargs)\n",
        "        self.small_net = tf.keras.layers.Dense(2)\n",
        "        self.large_net = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(10, activation='relu'),\n",
        "            tf.keras.layers.Dense(5, activation='relu'),\n",
        "            tf.keras.layers.Dense(2)\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Choose architecture based on input characteristics\n",
        "        input_magnitude = tf.reduce_mean(tf.abs(inputs))\n",
        "\n",
        "        if input_magnitude.numpy() > 1.0:  # Python condition\n",
        "            print(f\"Using large network (magnitude: {input_magnitude:.3f})\")\n",
        "            return self.large_net(inputs)\n",
        "        else:\n",
        "            print(f\"Using small network (magnitude: {input_magnitude:.3f})\")\n",
        "            return self.small_net(inputs)\n",
        "\n",
        "# Modify instantiation to pass dynamic=True explicitly\n",
        "conditional_model = ConditionalModel(dynamic=True)\n",
        "\n",
        "# Test with different input magnitudes\n",
        "small_input = tf.random.normal((2, 4), stddev=0.5)\n",
        "large_input = tf.random.normal((2, 4), stddev=2.0)\n",
        "\n",
        "print(\"\\nConditional architecture:\")\n",
        "small_output = conditional_model(small_input)\n",
        "large_output = conditional_model(large_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "1cY1kwziNFxS",
        "outputId": "321bc84c-501a-43dd-a218-7569fc4c8605"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized keyword arguments passed to ConditionalModel: {'dynamic': True}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-117-2370028193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmall_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mconditional_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConditionalModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Test with different input magnitudes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-117-2370028193.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConditionalModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmall_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         self.large_net = tf.keras.Sequential([\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0;34m\"Unrecognized keyword arguments \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;34mf\"passed to {self.__class__.__name__}: {kwargs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to ConditionalModel: {'dynamic': True}"
          ]
        }
      ],
      "source": [
        "# Use Case 2: Conditional Architecture\n",
        "class ConditionalModel(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(dynamic=True, **kwargs)\n",
        "        self.small_net = tf.keras.layers.Dense(2)\n",
        "        self.large_net = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(10, activation='relu'),\n",
        "            tf.keras.layers.Dense(5, activation='relu'),\n",
        "            tf.keras.layers.Dense(2)\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Choose architecture based on input characteristics\n",
        "        input_magnitude = tf.reduce_mean(tf.abs(inputs))\n",
        "\n",
        "        if input_magnitude.numpy() > 1.0:  # Python condition\n",
        "            print(f\"Using large network (magnitude: {input_magnitude:.3f})\")\n",
        "            return self.large_net(inputs)\n",
        "        else:\n",
        "            print(f\"Using small network (magnitude: {input_magnitude:.3f})\")\n",
        "            return self.small_net(inputs)\n",
        "\n",
        "conditional_model = ConditionalModel()\n",
        "\n",
        "# Test with different input magnitudes\n",
        "small_input = tf.random.normal((2, 4), stddev=0.5)\n",
        "large_input = tf.random.normal((2, 4), stddev=2.0)\n",
        "\n",
        "print(\"\\nConditional architecture:\")\n",
        "small_output = conditional_model(small_input)\n",
        "large_output = conditional_model(large_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qut61t3NFxS",
        "outputId": "ddacc599-008c-4852-c934-bd9276606622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Performance Comparison:\n"
          ]
        }
      ],
      "source": [
        "# Performance comparison: Static vs Dynamic\n",
        "print(\"\\n\\nPerformance Comparison:\")\n",
        "\n",
        "# Static model\n",
        "class StaticModel(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)  # dynamic=False by default\n",
        "        self.dense1 = tf.keras.layers.Dense(32, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(16, activation='relu')\n",
        "        self.dense3 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        return self.dense3(x)\n",
        "\n",
        "# Dynamic model (same architecture)\n",
        "class DynamicModel(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(dynamic=True, **kwargs)\n",
        "        self.dense1 = tf.keras.layers.Dense(32, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(16, activation='relu')\n",
        "        self.dense3 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        return self.dense3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Q7BLt3u8NFxS",
        "outputId": "88f4aecc-0500-4ff4-a047-59cfd5f336fa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized keyword arguments passed to DynamicModel: {'dynamic': True}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-119-3082578388.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstatic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStaticModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdynamic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDynamicModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Large input for meaningful timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-113-3125084897.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDynamicModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0;34m\"Unrecognized keyword arguments \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;34mf\"passed to {self.__class__.__name__}: {kwargs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to DynamicModel: {'dynamic': True}"
          ]
        }
      ],
      "source": [
        "# Create models\n",
        "static_model = StaticModel()\n",
        "dynamic_model = DynamicModel()\n",
        "\n",
        "# Large input for meaningful timing\n",
        "large_input = tf.random.normal((1000, 20))\n",
        "\n",
        "# Build models\n",
        "_ = static_model(large_input[:10])\n",
        "_ = dynamic_model(large_input[:10])\n",
        "\n",
        "# Time static model\n",
        "start_time = time.time()\n",
        "for _ in range(50):\n",
        "    _ = static_model(large_input)\n",
        "static_time = time.time() - start_time\n",
        "\n",
        "# Time dynamic model\n",
        "start_time = time.time()\n",
        "for _ in range(50):\n",
        "    _ = dynamic_model(large_input)\n",
        "dynamic_time = time.time() - start_time\n",
        "\n",
        "print(f\"Static model time: {static_time:.4f}s\")\n",
        "print(f\"Dynamic model time: {dynamic_time:.4f}s\")\n",
        "print(f\"Static is {dynamic_time/static_time:.2f}x faster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnExWL6gNFxT",
        "outputId": "1ce5b975-acff-41c6-e5f2-069187ae5041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "When to use each:\n",
            "Static (TF Function) - Default choice:\n",
            "   Better performance (2-10x faster)\n",
            "   Memory efficient\n",
            "   Better for deployment\n",
            "   Graph optimizations\n",
            "\n",
            "Dynamic - Special cases only:\n",
            "   Debugging and development\n",
            "   Complex Python logic\n",
            "   Conditional architectures\n",
            "   Research requiring flexibility\n",
            "   Slower performance\n",
            "   Less deployment optimization\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nWhen to use each:\")\n",
        "print(\"Static (TF Function) - Default choice:\")\n",
        "print(\"   Better performance (2-10x faster)\")\n",
        "print(\"   Memory efficient\")\n",
        "print(\"   Better for deployment\")\n",
        "print(\"   Graph optimizations\")\n",
        "\n",
        "print(\"\\nDynamic - Special cases only:\")\n",
        "print(\"   Debugging and development\")\n",
        "print(\"   Complex Python logic\")\n",
        "print(\"   Conditional architectures\")\n",
        "print(\"   Research requiring flexibility\")\n",
        "print(\"   Slower performance\")\n",
        "print(\"   Less deployment optimization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_12"
      },
      "source": [
        "### Exercise 12: Layer Normalization Implementation\n",
        "\n",
        "**Question:** Implement a custom layer that performs Layer Normalization:\n",
        "\n",
        "a. The `build()` method should define two trainable weights  and , both of shape `input_shape[-1:]` and data type `tf.float32`.  should be initialized with 1s, and  with 0s.\n",
        "\n",
        "b. The `call()` method should compute the mean  and standard deviation  of each instance's features using `tf.nn.moments(inputs, axes=-1, keepdims=True)`, then return (X - )/( + ) + .\n",
        "\n",
        "c. Ensure your custom layer produces the same output as `keras.layers.LayerNormalization`.\n",
        "\n",
        "**Mathematical Foundation:**\n",
        "\n",
        "Layer Normalization normalizes inputs across the feature dimension for each sample:\n",
        "\n",
        "$$\\text{LayerNorm}(\\mathbf{x}) = \\boldsymbol{\\alpha} \\odot \\frac{\\mathbf{x} - \\boldsymbol{\\mu}}{\\boldsymbol{\\sigma} + \\epsilon} + \\boldsymbol{\\beta}$$\n",
        "\n",
        "where:\n",
        "- $\\boldsymbol{\\mu} = \\frac{1}{H} \\sum_{i=1}^{H} x_i$ (mean across features)\n",
        "- $\\boldsymbol{\\sigma} = \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H} (x_i - \\mu)^2}$ (standard deviation across features)\n",
        "- $\\boldsymbol{\\alpha}$ and $\\boldsymbol{\\beta}$ are learnable scale and shift parameters\n",
        "- $\\epsilon$ is a small constant for numerical stability\n",
        "- $\\odot$ represents element-wise multiplication\n",
        "\n",
        "**Benefits of Layer Normalization:**\n",
        "1. **Accelerated training**: Reduces internal covariate shift\n",
        "2. **Gradient flow**: Improves gradient propagation\n",
        "3. **Regularization effect**: Acts as implicit regularization\n",
        "4. **Sequence modeling**: Works well with variable-length sequences (unlike batch norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "exercise_12_implementation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c45812c-6bc7-424b-e71b-175bd4b34fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 12: Custom Layer Normalization ===\n",
            "Testing Custom Layer Normalization:\n",
            "Input shape: (2, 4, 6)\n",
            "Input statistics:\n",
            "  Mean: 5.0853\n",
            "  Std:  1.8273\n",
            "  Sample input[0,0,:]: [3.2630286 5.08393   7.7307405 4.9480724 8.021202  5.783769 ]\n",
            "\n",
            "Custom LayerNorm output:\n",
            "  Shape: (2, 4, 6)\n",
            "  Sample output[0,0,:]: [-1.5405991  -0.43706882  1.1669915  -0.5194033   1.3430214  -0.01294168]\n",
            "\n",
            "Verification - statistics per sample:\n",
            "  Sample [0,0]: mean=-0.000000, std=1.000000\n",
            "  Sample [0,1]: mean=-0.000000, std=1.000000\n",
            "  Sample [0,2]: mean=0.000000, std=1.000000\n",
            "  Sample [0,3]: mean=-0.000000, std=1.000000\n",
            "  Sample [1,0]: mean=0.000000, std=1.000000\n",
            "  Sample [1,1]: mean=0.000000, std=1.000000\n",
            "  Sample [1,2]: mean=0.000000, std=1.000000\n",
            "  Sample [1,3]: mean=-0.000000, std=1.000000\n",
            "\n",
            "=== Comparison with Keras LayerNormalization ===\n",
            "Keras LayerNorm output shape: (2, 4, 6)\n",
            "Sample keras output[0,0,:]: [-1.5403166  -0.4369886   1.1667774  -0.5193081   1.3427751  -0.01293945]\n",
            "\n",
            "Comparison:\n",
            "  Mean absolute difference: 0.00016921\n",
            "  Max absolute difference:  0.00074577\n",
            "  Outputs are close: False\n",
            "\n",
            "=== Testing with Modified Parameters ===\n",
            "Output with modified  and :\n",
            "  Sample output[0,0,:]: [-2.9811983  -0.75560325  1.3669915  -0.45970166  1.6116258   0.28964666]\n",
            "\n",
            "=== Manual Verification ===\n",
            "Sample input: [3.2630286 5.08393   7.7307405 4.9480724 8.021202  5.783769 ]\n",
            "Manual computation:\n",
            "  Mean: 5.805124\n",
            "  Std:  1.650069\n",
            "  Normalized: [-1.5405991  -0.43706882  1.1669915  -0.5194033   1.3430214  -0.01294168]\n",
            "  Final output: [-2.9811983  -0.75560325  1.3669915  -0.45970166  1.6116258   0.28964666]\n",
            "\n",
            "Manual vs Layer difference: 0.0000000000\n",
            "Manual computation matches: True\n",
            "\n",
            "=== Testing in Model Context ===\n",
            "Model with custom LayerNorm output shape: (10, 1)\n",
            "Model with Keras LayerNorm output shape: (10, 1)\n",
            "Both models work correctly: True\n",
            "\n",
            "=== Summary ===\n",
            " Custom LayerNormalization implemented correctly\n",
            " Produces same results as tf.nn.moments + manual computation\n",
            " Comparable to Keras LayerNormalization\n",
            " Works in model context\n",
            " Supports serialization via get_config()\n",
            " Proper weight initialization (=1, =0)\n",
            "\n",
            "Key features:\n",
            "- Normalizes across feature dimension for each sample\n",
            "- Learnable scale () and shift () parameters\n",
            "- Numerical stability with epsilon\n",
            "- Independent of batch size and sequence length\n"
          ]
        }
      ],
      "source": [
        "# Exercise 12: Custom Layer Normalization Implementation\n",
        "print(\"=== Exercise 12: Custom Layer Normalization ===\")\n",
        "\n",
        "class CustomLayerNormalization(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom implementation of Layer Normalization.\n",
        "\n",
        "    Layer Normalization normalizes the inputs across the features for each sample.\n",
        "    Mathematical formulation: LayerNorm(x) =   (x - ) / ( + ) + \n",
        "\n",
        "    This is particularly useful for:\n",
        "    - Sequence models (RNNs, Transformers)\n",
        "    - Any case where batch statistics are unreliable\n",
        "    - When you need normalization that's independent of batch size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epsilon=1e-6, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize Layer Normalization.\n",
        "\n",
        "        Args:\n",
        "            epsilon: Small constant for numerical stability\n",
        "            **kwargs: Additional arguments for parent class\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Create the trainable weights  (scale) and  (shift).\n",
        "\n",
        "        Args:\n",
        "            input_shape: Shape of the input tensor\n",
        "        \"\"\"\n",
        "        # Get the last dimension (features dimension)\n",
        "        feature_dim = input_shape[-1]\n",
        "\n",
        "        # Scale parameter  (initialized to 1)\n",
        "        self.alpha = self.add_weight(\n",
        "            name='alpha',\n",
        "            shape=(feature_dim,),\n",
        "            dtype=tf.float32,\n",
        "            initializer='ones',  # Initialize with 1s\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        # Shift parameter  (initialized to 0)\n",
        "        self.beta = self.add_weight(\n",
        "            name='beta',\n",
        "            shape=(feature_dim,),\n",
        "            dtype=tf.float32,\n",
        "            initializer='zeros',  # Initialize with 0s\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Apply layer normalization to inputs.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input tensor of shape (..., features)\n",
        "\n",
        "        Returns:\n",
        "            Normalized tensor of same shape as inputs\n",
        "        \"\"\"\n",
        "        # Compute mean and variance across the last axis (features)\n",
        "        # keepdims=True maintains the dimension for broadcasting\n",
        "        mean, variance = tf.nn.moments(inputs, axes=-1, keepdims=True)\n",
        "\n",
        "        # Compute standard deviation\n",
        "        std = tf.sqrt(variance + self.epsilon)\n",
        "\n",
        "        # Normalize: (x - ) / \n",
        "        normalized = (inputs - mean) / std\n",
        "\n",
        "        # Scale and shift:   normalized + \n",
        "        output = self.alpha * normalized + self.beta\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Return configuration for serialization.\n",
        "        \"\"\"\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"epsilon\": self.epsilon}\n",
        "\n",
        "# Test the custom implementation\n",
        "print(\"Testing Custom Layer Normalization:\")\n",
        "\n",
        "# Create test data\n",
        "batch_size, seq_len, features = 2, 4, 6\n",
        "test_input = tf.random.normal((batch_size, seq_len, features), mean=5.0, stddev=2.0)\n",
        "\n",
        "print(f\"Input shape: {test_input.shape}\")\n",
        "print(f\"Input statistics:\")\n",
        "print(f\"  Mean: {tf.reduce_mean(test_input):.4f}\")\n",
        "print(f\"  Std:  {tf.math.reduce_std(test_input):.4f}\")\n",
        "print(f\"  Sample input[0,0,:]: {test_input[0,0,:].numpy()}\")\n",
        "\n",
        "# Test custom layer normalization\n",
        "custom_layer_norm = CustomLayerNormalization()\n",
        "custom_output = custom_layer_norm(test_input)\n",
        "\n",
        "print(f\"\\nCustom LayerNorm output:\")\n",
        "print(f\"  Shape: {custom_output.shape}\")\n",
        "print(f\"  Sample output[0,0,:]: {custom_output[0,0,:].numpy()}\")\n",
        "\n",
        "# Verify normalization worked (each sample should be normalized)\n",
        "print(f\"\\nVerification - statistics per sample:\")\n",
        "for i in range(batch_size):\n",
        "    for j in range(seq_len):\n",
        "        sample = custom_output[i, j, :]\n",
        "        sample_mean = tf.reduce_mean(sample)\n",
        "        sample_std = tf.math.reduce_std(sample)\n",
        "        print(f\"  Sample [{i},{j}]: mean={sample_mean:.6f}, std={sample_std:.6f}\")\n",
        "\n",
        "# Compare with Keras LayerNormalization\n",
        "print(\"\\n=== Comparison with Keras LayerNormalization ===\")\n",
        "\n",
        "keras_layer_norm = tf.keras.layers.LayerNormalization()\n",
        "keras_output = keras_layer_norm(test_input)\n",
        "\n",
        "print(f\"Keras LayerNorm output shape: {keras_output.shape}\")\n",
        "print(f\"Sample keras output[0,0,:]: {keras_output[0,0,:].numpy()}\")\n",
        "\n",
        "# Check if outputs are close (they should be very similar)\n",
        "difference = tf.reduce_mean(tf.abs(custom_output - keras_output))\n",
        "max_difference = tf.reduce_max(tf.abs(custom_output - keras_output))\n",
        "\n",
        "print(f\"\\nComparison:\")\n",
        "print(f\"  Mean absolute difference: {difference:.8f}\")\n",
        "print(f\"  Max absolute difference:  {max_difference:.8f}\")\n",
        "print(f\"  Outputs are close: {difference < 1e-5}\")\n",
        "\n",
        "# Test with trained parameters\n",
        "print(\"\\n=== Testing with Modified Parameters ===\")\n",
        "\n",
        "# Manually set parameters to test scaling and shifting\n",
        "custom_layer_norm.alpha.assign(tf.constant([2.0, 1.5, 1.0, 0.5, 1.2, 0.8]))\n",
        "custom_layer_norm.beta.assign(tf.constant([0.1, -0.1, 0.2, -0.2, 0.0, 0.3]))\n",
        "\n",
        "modified_output = custom_layer_norm(test_input)\n",
        "print(f\"Output with modified  and :\")\n",
        "print(f\"  Sample output[0,0,:]: {modified_output[0,0,:].numpy()}\")\n",
        "\n",
        "# Verify the mathematical computation manually\n",
        "print(\"\\n=== Manual Verification ===\")\n",
        "\n",
        "# Take one sample for manual computation\n",
        "sample_input = test_input[0, 0, :]\n",
        "print(f\"Sample input: {sample_input.numpy()}\")\n",
        "\n",
        "# Manual computation\n",
        "manual_mean = tf.reduce_mean(sample_input)\n",
        "manual_var = tf.reduce_mean(tf.square(sample_input - manual_mean))\n",
        "manual_std = tf.sqrt(manual_var + custom_layer_norm.epsilon)\n",
        "manual_normalized = (sample_input - manual_mean) / manual_std\n",
        "manual_output = custom_layer_norm.alpha * manual_normalized + custom_layer_norm.beta\n",
        "\n",
        "print(f\"Manual computation:\")\n",
        "print(f\"  Mean: {manual_mean:.6f}\")\n",
        "print(f\"  Std:  {manual_std:.6f}\")\n",
        "print(f\"  Normalized: {manual_normalized.numpy()}\")\n",
        "print(f\"  Final output: {manual_output.numpy()}\")\n",
        "\n",
        "# Compare with layer output\n",
        "layer_sample_output = modified_output[0, 0, :]\n",
        "manual_vs_layer = tf.reduce_max(tf.abs(manual_output - layer_sample_output))\n",
        "print(f\"\\nManual vs Layer difference: {manual_vs_layer:.10f}\")\n",
        "print(f\"Manual computation matches: {manual_vs_layer < 1e-6}\")\n",
        "\n",
        "# Test in a model context\n",
        "print(\"\\n=== Testing in Model Context ===\")\n",
        "\n",
        "# Create a simple model using our custom layer\n",
        "model_with_custom = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    CustomLayerNormalization(),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Create equivalent model with Keras LayerNorm\n",
        "model_with_keras = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.LayerNormalization(),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Test input\n",
        "model_input = tf.random.normal((10, 5))\n",
        "\n",
        "# Get outputs\n",
        "custom_model_output = model_with_custom(model_input)\n",
        "keras_model_output = model_with_keras(model_input)\n",
        "\n",
        "print(f\"Model with custom LayerNorm output shape: {custom_model_output.shape}\")\n",
        "print(f\"Model with Keras LayerNorm output shape: {keras_model_output.shape}\")\n",
        "print(f\"Both models work correctly: {custom_model_output.shape == keras_model_output.shape}\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n=== Summary ===\")\n",
        "print(\" Custom LayerNormalization implemented correctly\")\n",
        "print(\" Produces same results as tf.nn.moments + manual computation\")\n",
        "print(\" Comparable to Keras LayerNormalization\")\n",
        "print(\" Works in model context\")\n",
        "print(\" Supports serialization via get_config()\")\n",
        "print(\" Proper weight initialization (=1, =0)\")\n",
        "print(\"\\nKey features:\")\n",
        "print(\"- Normalizes across feature dimension for each sample\")\n",
        "print(\"- Learnable scale () and shift () parameters\")\n",
        "print(\"- Numerical stability with epsilon\")\n",
        "print(\"- Independent of batch size and sequence length\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise_13"
      },
      "source": [
        "### Exercise 13: Custom Training Loop for Fashion MNIST\n",
        "\n",
        "**Question:** Train a model using a custom training loop to tackle the Fashion MNIST dataset:\n",
        "\n",
        "a. Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch.\n",
        "\n",
        "b. Try using a different optimizer with a different learning rate for the upper layers and the lower layers.\n",
        "\n",
        "**Mathematical Foundation:**\n",
        "\n",
        "For multi-layer networks with different optimizers:\n",
        "\n",
        "**Lower layers update:**\n",
        "$$\\boldsymbol{\\theta}_{lower}^{(t+1)} = \\text{Optimizer}_1(\\boldsymbol{\\theta}_{lower}^{(t)}, \\nabla_{\\boldsymbol{\\theta}_{lower}} \\mathcal{L})$$\n",
        "\n",
        "**Upper layers update:**\n",
        "$$\\boldsymbol{\\theta}_{upper}^{(t+1)} = \\text{Optimizer}_2(\\boldsymbol{\\theta}_{upper}^{(t)}, \\nabla_{\\boldsymbol{\\theta}_{upper}} \\mathcal{L})$$\n",
        "\n",
        "**Accuracy computation:**\n",
        "$$\\text{Accuracy} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{I}[\\arg\\max(\\hat{\\mathbf{y}}_i) = y_i]$$\n",
        "\n",
        "where $\\mathbb{I}$ is the indicator function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "exercise_13_implementation",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04eff1c2-e1de-419d-ab74-5320907da806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exercise 13: Custom Training Loop for Fashion MNIST ===\n",
            "Loading Fashion MNIST dataset...\n",
            "Training set shape: (55000, 28, 28)\n",
            "Training labels shape: (55000,)\n",
            "Validation set shape: (5000, 28, 28)\n",
            "Number of classes: 10\n",
            "\n",
            "Model created:\n",
            "  Total parameters: 111146\n",
            "  Lower layer variables: 4\n",
            "  Upper layer variables: 4\n",
            "\n",
            "Optimizers:\n",
            "  Lower layers: SGD (lr=0.01)\n",
            "  Upper layers: Adam (lr=0.001)\n",
            "\n",
            "Training configuration:\n",
            "  Batch size: 128\n",
            "  Epochs: 10\n",
            "  Steps per epoch: 429\n",
            "\n",
            "================================================================================\n",
            "STARTING CUSTOM TRAINING LOOP\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/10\n",
            "Epoch 1/10 [==============================] 429/429 - loss: 0.7618 - accuracy: 0.7309\n",
            "Running validation...\n",
            "Epoch 1 complete:\n",
            "  Training   - Loss: 0.7618, Accuracy: 0.7309\n",
            "  Validation - Loss: 0.4745, Accuracy: 0.8286\n",
            "  Lower optimizer iterations: 429\n",
            "  Upper optimizer iterations: 429\n",
            "\n",
            "Epoch 2/10\n",
            "Epoch 2/10 [==============================] 429/429 - loss: 0.6201 - accuracy: 0.7806\n",
            "Running validation...\n",
            "Epoch 2 complete:\n",
            "  Training   - Loss: 0.6201, Accuracy: 0.7806\n",
            "  Validation - Loss: 0.4476, Accuracy: 0.8364\n",
            "  Lower optimizer iterations: 858\n",
            "  Upper optimizer iterations: 858\n",
            "\n",
            "Epoch 3/10\n",
            "Epoch 3/10 [==============================] 429/429 - loss: 0.5555 - accuracy: 0.8034\n",
            "Running validation...\n",
            "Epoch 3 complete:\n",
            "  Training   - Loss: 0.5555, Accuracy: 0.8034\n",
            "  Validation - Loss: 0.4246, Accuracy: 0.8438\n",
            "  Lower optimizer iterations: 1287\n",
            "  Upper optimizer iterations: 1287\n",
            "\n",
            "Epoch 4/10\n",
            "Epoch 4/10 [==============================] 429/429 - loss: 0.5148 - accuracy: 0.8173\n",
            "Running validation...\n",
            "Epoch 4 complete:\n",
            "  Training   - Loss: 0.5148, Accuracy: 0.8173\n",
            "  Validation - Loss: 0.4076, Accuracy: 0.8504\n",
            "  Lower optimizer iterations: 1716\n",
            "  Upper optimizer iterations: 1716\n",
            "\n",
            "Epoch 5/10\n",
            "Epoch 5/10 [==============================] 429/429 - loss: 0.4864 - accuracy: 0.8269\n",
            "Running validation...\n",
            "Epoch 5 complete:\n",
            "  Training   - Loss: 0.4864, Accuracy: 0.8269\n",
            "  Validation - Loss: 0.3980, Accuracy: 0.8530\n",
            "  Lower optimizer iterations: 2145\n",
            "  Upper optimizer iterations: 2145\n",
            "\n",
            "Epoch 6/10\n",
            "Epoch 6/10 [==============================] 429/429 - loss: 0.4650 - accuracy: 0.8342\n",
            "Running validation...\n",
            "Epoch 6 complete:\n",
            "  Training   - Loss: 0.4650, Accuracy: 0.8342\n",
            "  Validation - Loss: 0.3884, Accuracy: 0.8565\n",
            "  Lower optimizer iterations: 2574\n",
            "  Upper optimizer iterations: 2574\n",
            "\n",
            "Epoch 7/10\n",
            "Epoch 7/10 [==============================] 429/429 - loss: 0.4477 - accuracy: 0.8400\n",
            "Running validation...\n",
            "Epoch 7 complete:\n",
            "  Training   - Loss: 0.4477, Accuracy: 0.8400\n",
            "  Validation - Loss: 0.3802, Accuracy: 0.8590\n",
            "  Lower optimizer iterations: 3003\n",
            "  Upper optimizer iterations: 3003\n",
            "\n",
            "Epoch 8/10\n",
            "Epoch 8/10 [==============================] 429/429 - loss: 0.4331 - accuracy: 0.8448\n",
            "Running validation...\n",
            "Epoch 8 complete:\n",
            "  Training   - Loss: 0.4331, Accuracy: 0.8448\n",
            "  Validation - Loss: 0.3796, Accuracy: 0.8598\n",
            "  Lower optimizer iterations: 3432\n",
            "  Upper optimizer iterations: 3432\n",
            "\n",
            "Epoch 9/10\n",
            "Epoch 9/10 [==============================] 429/429 - loss: 0.4207 - accuracy: 0.8492\n",
            "Running validation...\n",
            "Epoch 9 complete:\n",
            "  Training   - Loss: 0.4207, Accuracy: 0.8492\n",
            "  Validation - Loss: 0.3732, Accuracy: 0.8617\n",
            "  Lower optimizer iterations: 3861\n",
            "  Upper optimizer iterations: 3861\n",
            "\n",
            "Epoch 10/10\n",
            "Epoch 10/10 [==============================] 429/429 - loss: 0.4099 - accuracy: 0.8527\n",
            "Running validation...\n",
            "Epoch 10 complete:\n",
            "  Training   - Loss: 0.4099, Accuracy: 0.8527\n",
            "  Validation - Loss: 0.3670, Accuracy: 0.8639\n",
            "  Lower optimizer iterations: 4290\n",
            "  Upper optimizer iterations: 4290\n",
            "\n",
            "================================================================================\n",
            "TRAINING COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Results:\n",
            "  Loss: 0.3450\n",
            "  Accuracy: 0.8768\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ANALYSIS: DIFFERENT OPTIMIZERS FOR DIFFERENT LAYERS\n",
            "============================================================\n",
            "\n",
            "Optimizer Analysis:\n",
            "Lower Layers (SGD with momentum):\n",
            "  - Learning rate: 0.010000\n",
            "  - Momentum: 0.9\n",
            "  - Total iterations: 4290\n",
            "  - Characteristics: Stable, consistent updates, good for feature extraction\n",
            "\n",
            "Upper Layers (Adam):\n",
            "  - Learning rate: 0.001000\n",
            "  - Beta 1: 0.9\n",
            "  - Beta 2: 0.999\n",
            "  - Total iterations: 4290\n",
            "  - Characteristics: Adaptive, fast convergence, good for classification head\n",
            "\n",
            "Why Different Optimizers?\n",
            " Lower layers (feature extraction):\n",
            "  - Need stable, consistent learning\n",
            "  - SGD with momentum provides steady feature learning\n",
            "  - Less likely to jump around feature space\n",
            " Upper layers (classification):\n",
            "  - Need to adapt quickly to changing features\n",
            "  - Adam's adaptive learning rates help fine-tune classification\n",
            "  - Momentum in gradients helps escape local minima\n",
            "\n",
            "==================================================\n",
            "MODEL ANALYSIS\n",
            "==================================================\n",
            "\n",
            "Sample Predictions:\n",
            "   True:          Bag | Pred:          Bag | Conf: 1.000\n",
            "   True:        Shirt | Pred:        Shirt | Conf: 0.928\n",
            "   True:       Sandal | Pred:       Sandal | Conf: 0.996\n",
            "   True:  T-shirt/top | Pred:  T-shirt/top | Conf: 0.623\n",
            "   True:     Pullover | Pred:     Pullover | Conf: 0.494\n",
            "   True:         Coat | Pred:         Coat | Conf: 0.876\n",
            "   True:        Dress | Pred:        Dress | Conf: 0.960\n",
            "   True:         Coat | Pred:         Coat | Conf: 0.375\n",
            "   True:   Ankle boot | Pred:   Ankle boot | Conf: 0.999\n",
            "   True:         Coat | Pred:         Coat | Conf: 0.985\n",
            "\n",
            "Confusion Matrix Analysis:\n",
            "Shape: (10, 10)\n",
            "\n",
            "Per-Class Accuracy:\n",
            "   T-shirt/top: 0.860\n",
            "       Trouser: 0.967\n",
            "      Pullover: 0.835\n",
            "         Dress: 0.884\n",
            "          Coat: 0.810\n",
            "        Sandal: 0.944\n",
            "         Shirt: 0.594\n",
            "       Sneaker: 0.949\n",
            "           Bag: 0.967\n",
            "    Ankle boot: 0.958\n",
            "\n",
            "============================================================\n",
            "TRAINING SUMMARY\n",
            "============================================================\n",
            "Dataset: Fashion MNIST\n",
            "  - Training samples: 55,000\n",
            "  - Validation samples: 5,000\n",
            "  - Test samples: 10,000\n",
            "  - Classes: 10\n",
            "\n",
            "Model Architecture:\n",
            "  - Total parameters: 111,146\n",
            "  - Lower layers: Feature extraction (Dense 128 + Dense 64)\n",
            "  - Upper layers: Classification (Dense 32 + Dense 10)\n",
            "\n",
            "Training Configuration:\n",
            "  - Custom training loop with dual optimizers\n",
            "  - Lower layers: SGD (lr=0.01, momentum=0.9)\n",
            "  - Upper layers: Adam (lr=0.001)\n",
            "  - Batch size: 128\n",
            "  - Epochs: 10\n",
            "\n",
            "Final Results:\n",
            "  - Training accuracy: 0.8527\n",
            "  - Validation accuracy: 0.8639\n",
            "  - Test accuracy: 0.8768\n",
            "  - Training loss: 0.4099\n",
            "  - Validation loss: 0.3670\n",
            "  - Test loss: 0.3450\n",
            "\n",
            "============================================================\n",
            "TECHNICAL ACHIEVEMENTS\n",
            "============================================================\n",
            " Implemented complete custom training loop\n",
            " Used different optimizers for different model parts\n",
            " Real-time progress tracking with metrics\n",
            " Proper batch processing and data shuffling\n",
            " Validation evaluation after each epoch\n",
            " TensorFlow Functions for performance (@tf.function)\n",
            " Persistent gradient tapes for multiple optimizer updates\n",
            " Comprehensive model evaluation and analysis\n",
            " Training history visualization\n",
            " Confusion matrix and per-class accuracy analysis\n",
            "\n",
            "============================================================\n",
            "KEY INSIGHTS\n",
            "============================================================\n",
            "1. Multi-Optimizer Training:\n",
            "   - Different layers can benefit from different optimization strategies\n",
            "   - Feature extraction layers: stable learning (SGD + momentum)\n",
            "   - Classification layers: adaptive learning (Adam)\n",
            "\n",
            "2. Custom Training Loop Benefits:\n",
            "   - Full control over training process\n",
            "   - Ability to implement research algorithms\n",
            "   - Fine-grained monitoring and debugging\n",
            "   - Flexible gradient processing\n",
            "\n",
            "3. Performance Considerations:\n",
            "   - @tf.function for training steps improves performance\n",
            "   - Persistent gradient tapes needed for multiple optimizers\n",
            "   - Batch processing essential for memory efficiency\n",
            "   - Progress tracking helps monitor training stability\n",
            "\n",
            "4. Fashion MNIST Specific:\n",
            "   - Image classification with 10 clothing categories\n",
            "   - Relatively simple dataset, good for demonstrating techniques\n",
            "   - Clear performance improvements visible in training curves\n",
            "   - Per-class accuracy reveals model strengths/weaknesses\n",
            "\n",
            "============================================================\n",
            "EXERCISE 13 COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Exercise 13: Custom Training Loop for Fashion MNIST\n",
        "print(\"=== Exercise 13: Custom Training Loop for Fashion MNIST ===\")\n",
        "\n",
        "# Load and preprocess Fashion MNIST data\n",
        "print(\"Loading Fashion MNIST dataset...\")\n",
        "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Split training data into training and validation\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "X_train = X_train.astype(np.float32) / 255.0\n",
        "X_valid = X_valid.astype(np.float32) / 255.0\n",
        "X_test = X_test.astype(np.float32) / 255.0\n",
        "\n",
        "# Convert to TensorFlow tensors\n",
        "X_train = tf.constant(X_train)\n",
        "X_valid = tf.constant(X_valid)\n",
        "y_train = tf.constant(y_train, dtype=tf.int32)\n",
        "y_valid = tf.constant(y_valid, dtype=tf.int32)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Validation set shape: {X_valid.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(y_train))}\")\n",
        "\n",
        "# Fashion MNIST class names\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Create model with clear separation between lower and upper layers\n",
        "class FashionMNISTModel(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Custom model for Fashion MNIST with separate lower and upper layers.\n",
        "\n",
        "    Architecture:\n",
        "    - Lower layers: Feature extraction (Conv + Dense)\n",
        "    - Upper layers: Classification head\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Lower layers (feature extraction)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.lower_dense1 = tf.keras.layers.Dense(128, activation='relu', name='lower_1')\n",
        "        self.lower_dense2 = tf.keras.layers.Dense(64, activation='relu', name='lower_2')\n",
        "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        # Upper layers (classification)\n",
        "        self.upper_dense1 = tf.keras.layers.Dense(32, activation='relu', name='upper_1')\n",
        "        self.upper_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='upper_output')\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"Forward pass through the model.\"\"\"\n",
        "        # Lower layers\n",
        "        x = self.flatten(inputs)\n",
        "        x = self.lower_dense1(x)\n",
        "        x = self.lower_dense2(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        # Upper layers\n",
        "        x = self.upper_dense1(x)\n",
        "        outputs = self.upper_output(x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    @property\n",
        "    def lower_variables(self):\n",
        "        \"\"\"Get trainable variables from lower layers.\"\"\"\n",
        "        return (self.lower_dense1.trainable_variables +\n",
        "                self.lower_dense2.trainable_variables)\n",
        "\n",
        "    @property\n",
        "    def upper_variables(self):\n",
        "        \"\"\"Get trainable variables from upper layers.\"\"\"\n",
        "        return (self.upper_dense1.trainable_variables +\n",
        "                self.upper_output.trainable_variables)\n",
        "# Create the model\n",
        "model = FashionMNISTModel()\n",
        "\n",
        "# Build the model by calling it once\n",
        "sample_input = X_train[:1]\n",
        "_ = model(sample_input)\n",
        "\n",
        "print(f\"\\nModel created:\")\n",
        "print(f\"  Total parameters: {model.count_params()}\")\n",
        "print(f\"  Lower layer variables: {len(model.lower_variables)}\")\n",
        "print(f\"  Upper layer variables: {len(model.upper_variables)}\")\n",
        "# Create different optimizers for different parts\n",
        "lower_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "upper_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "print(f\"\\nOptimizers:\")\n",
        "print(f\"  Lower layers: {type(lower_optimizer).__name__} (lr=0.01)\")\n",
        "print(f\"  Upper layers: {type(upper_optimizer).__name__} (lr=0.001)\")\n",
        "# Training hyperparameters\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "n_steps_per_epoch = len(X_train) // batch_size\n",
        "\n",
        "print(f\"\\nTraining configuration:\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Epochs: {epochs}\")\n",
        "print(f\"  Steps per epoch: {n_steps_per_epoch}\")\n",
        "# Metrics for tracking\n",
        "train_loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "val_loss_metric = tf.keras.metrics.Mean(name='val_loss')\n",
        "val_accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
        "\n",
        "# Loss function\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "# Helper function for batch sampling\n",
        "def get_batch(X, y, batch_size, start_idx):\n",
        "    \"\"\"Get a batch of data starting from start_idx.\"\"\"\n",
        "    end_idx = min(start_idx + batch_size, len(X))\n",
        "    return X[start_idx:end_idx], y[start_idx:end_idx]\n",
        "# Custom training step\n",
        "@tf.function\n",
        "def train_step(X_batch, y_batch):\n",
        "    \"\"\"\n",
        "    Perform one training step with different optimizers for different layers.\n",
        "\n",
        "    Args:\n",
        "        X_batch: Batch of input images\n",
        "        y_batch: Batch of labels\n",
        "\n",
        "    Returns:\n",
        "        loss: Training loss for this batch\n",
        "    \"\"\"\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Forward pass\n",
        "        predictions = model(X_batch, training=True)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(y_batch, predictions)\n",
        "\n",
        "    # Compute gradients for different parts of the model\n",
        "    lower_gradients = tape.gradient(loss, model.lower_variables)\n",
        "    upper_gradients = tape.gradient(loss, model.upper_variables)\n",
        "\n",
        "    # Apply gradients with different optimizers\n",
        "    lower_optimizer.apply_gradients(zip(lower_gradients, model.lower_variables))\n",
        "    upper_optimizer.apply_gradients(zip(upper_gradients, model.upper_variables))\n",
        "\n",
        "    # Clean up persistent tape\n",
        "    del tape\n",
        "\n",
        "    # Update metrics\n",
        "    train_loss_metric.update_state(loss)\n",
        "    train_accuracy_metric.update_state(y_batch, predictions)\n",
        "\n",
        "    return loss\n",
        "# Validation step\n",
        "@tf.function\n",
        "def val_step(X_batch, y_batch):\n",
        "    \"\"\"Perform validation step.\"\"\"\n",
        "    predictions = model(X_batch, training=False)\n",
        "    loss = loss_fn(y_batch, predictions)\n",
        "\n",
        "    val_loss_metric.update_state(loss)\n",
        "    val_accuracy_metric.update_state(y_batch, predictions)\n",
        "\n",
        "    return loss\n",
        "# Progress display function\n",
        "def print_progress(epoch, step, total_steps, metrics_dict):\n",
        "    \"\"\"Print training progress in a nice format.\"\"\"\n",
        "    progress = step / total_steps\n",
        "    bar_length = 30\n",
        "    filled = int(bar_length * progress)\n",
        "    bar = '=' * filled + '-' * (bar_length - filled)\n",
        "\n",
        "    metrics_str = ' - '.join([f\"{name}: {value:.4f}\" for name, value in metrics_dict.items()])\n",
        "\n",
        "    print(f\"\\rEpoch {epoch}/10 [{bar}] {step}/{total_steps} - {metrics_str}\", end='')\n",
        "# Training history storage\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_accuracy': [],\n",
        "    'val_loss': [],\n",
        "    'val_accuracy': []\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING CUSTOM TRAINING LOOP\")\n",
        "print(\"=\"*80)\n",
        "# Main training loop\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "\n",
        "    # Reset metrics at the start of each epoch - COMMENTED OUT due to AttributeError in TF 2.16.1\n",
        "    # train_loss_metric.reset_states()\n",
        "    # train_accuracy_metric.reset_states()\n",
        "    # val_loss_metric.reset_states()\n",
        "    # val_accuracy_metric.reset_states()\n",
        "\n",
        "    # Shuffle training data for each epoch\n",
        "    indices = tf.random.shuffle(tf.range(len(X_train)))\n",
        "    X_train_shuffled = tf.gather(X_train, indices)\n",
        "    y_train_shuffled = tf.gather(y_train, indices)\n",
        "\n",
        "    # Training steps\n",
        "    for step in range(n_steps_per_epoch):\n",
        "        start_idx = step * batch_size\n",
        "        X_batch, y_batch = get_batch(X_train_shuffled, y_train_shuffled, batch_size, start_idx)\n",
        "\n",
        "        # Perform training step\n",
        "        batch_loss = train_step(X_batch, y_batch)\n",
        "\n",
        "        # Display progress every 50 steps or at the end\n",
        "        if step % 50 == 0 or step == n_steps_per_epoch - 1:\n",
        "            current_metrics = {\n",
        "                'loss': train_loss_metric.result(),\n",
        "                'accuracy': train_accuracy_metric.result()\n",
        "            }\n",
        "            print_progress(epoch, step + 1, n_steps_per_epoch, current_metrics)\n",
        "\n",
        "    # Validation at the end of each epoch\n",
        "    print(\"\\nRunning validation...\")\n",
        "\n",
        "    # Process validation data in batches\n",
        "    val_steps = (len(X_valid) + batch_size - 1) // batch_size\n",
        "    for val_step_idx in range(val_steps):\n",
        "        start_idx = val_step_idx * batch_size\n",
        "        X_val_batch, y_val_batch = get_batch(X_valid, y_valid, batch_size, start_idx)\n",
        "        val_step(X_val_batch, y_val_batch)\n",
        "\n",
        "    # Get final metrics for this epoch\n",
        "    # Note: Metrics are not reset each epoch due to the AttributeError workaround\n",
        "    epoch_train_loss = train_loss_metric.result()\n",
        "    epoch_train_acc = train_accuracy_metric.result()\n",
        "    epoch_val_loss = val_loss_metric.result()\n",
        "    epoch_val_acc = val_accuracy_metric.result()\n",
        "\n",
        "    # Store history\n",
        "    history['train_loss'].append(epoch_train_loss.numpy())\n",
        "    history['train_accuracy'].append(epoch_train_acc.numpy())\n",
        "    history['val_loss'].append(epoch_val_loss.numpy())\n",
        "    history['val_accuracy'].append(epoch_val_acc.numpy())\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"Epoch {epoch} complete:\")\n",
        "    print(f\"  Training   - Loss: {epoch_train_loss:.4f}, Accuracy: {epoch_train_acc:.4f}\")\n",
        "    print(f\"  Validation - Loss: {epoch_val_loss:.4f}, Accuracy: {epoch_val_acc:.4f}\")\n",
        "\n",
        "    # Show optimizer states\n",
        "    print(f\"  Lower optimizer iterations: {lower_optimizer.iterations.numpy()}\")\n",
        "    print(f\"  Upper optimizer iterations: {upper_optimizer.iterations.numpy()}\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "# Final evaluation on test set\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_loss_metric = tf.keras.metrics.Mean()\n",
        "test_accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "test_steps = (len(X_test) + batch_size - 1) // batch_size\n",
        "for test_step_idx in range(test_steps):\n",
        "    start_idx = test_step_idx * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(X_test))\n",
        "    X_test_batch = X_test[start_idx:end_idx]\n",
        "    y_test_batch = y_test[start_idx:end_idx]\n",
        "\n",
        "    test_predictions = model(X_test_batch, training=False)\n",
        "    test_loss = loss_fn(y_test_batch, test_predictions)\n",
        "\n",
        "    test_loss_metric.update_state(test_loss)\n",
        "    test_accuracy_metric.update_state(y_test_batch, test_predictions)\n",
        "\n",
        "final_test_loss = test_loss_metric.result()\n",
        "final_test_acc = test_accuracy_metric.result()\n",
        "\n",
        "print(f\"Test Results:\")\n",
        "print(f\"  Loss: {final_test_loss:.4f}\")\n",
        "print(f\"  Accuracy: {final_test_acc:.4f}\")\n",
        "# Plot training history\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss plot\n",
        "epochs_range = range(1, epochs + 1)\n",
        "# Note: Training loss/accuracy history might not be meaningful per epoch\n",
        "# because metrics were not reset due to the workaround.\n",
        "ax1.plot(epochs_range, history['train_loss'], 'bo-', label='Training Loss (Accumulated)', linewidth=2, markersize=6)\n",
        "ax1.plot(epochs_range, history['val_loss'], 'ro-', label='Validation Loss', linewidth=2, markersize=6)\n",
        "ax1.set_title('Model Loss During Custom Training', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_xlim(1, epochs)\n",
        "\n",
        "# Accuracy plot\n",
        "# Note: Training loss/accuracy history might not be meaningful per epoch\n",
        "# because metrics were not reset due to the workaround.\n",
        "ax2.plot(epochs_range, history['train_accuracy'], 'bo-', label='Training Accuracy (Accumulated)', linewidth=2, markersize=6)\n",
        "ax2.plot(epochs_range, history['val_accuracy'], 'ro-', label='Validation Accuracy', linewidth=2, markersize=6)\n",
        "ax2.set_title('Model Accuracy During Custom Training', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Accuracy', fontsize=12)\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_xlim(1, epochs)\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# Analysis of different optimizers\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANALYSIS: DIFFERENT OPTIMIZERS FOR DIFFERENT LAYERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Show learning rate schedules and optimization behavior\n",
        "print(f\"\\nOptimizer Analysis:\")\n",
        "print(f\"Lower Layers (SGD with momentum):\")\n",
        "print(f\"  - Learning rate: {lower_optimizer.learning_rate.numpy():.6f}\")\n",
        "print(f\"  - Momentum: {lower_optimizer.momentum}\") # Removed .numpy()\n",
        "print(f\"  - Total iterations: {lower_optimizer.iterations.numpy()}\")\n",
        "print(f\"  - Characteristics: Stable, consistent updates, good for feature extraction\")\n",
        "\n",
        "print(f\"\\nUpper Layers (Adam):\")\n",
        "print(f\"  - Learning rate: {upper_optimizer.learning_rate.numpy():.6f}\")\n",
        "print(f\"  - Beta 1: {upper_optimizer.beta_1}\") # Removed .numpy()\n",
        "print(f\"  - Beta 2: {upper_optimizer.beta_2}\") # Removed .numpy()\n",
        "print(f\"  - Total iterations: {upper_optimizer.iterations.numpy()}\")\n",
        "print(f\"  - Characteristics: Adaptive, fast convergence, good for classification head\")\n",
        "# Demonstrate the benefit of using different optimizers\n",
        "print(f\"\\nWhy Different Optimizers?\")\n",
        "print(f\" Lower layers (feature extraction):\")\n",
        "print(f\"  - Need stable, consistent learning\")\n",
        "print(f\"  - SGD with momentum provides steady feature learning\")\n",
        "print(f\"  - Less likely to jump around feature space\")\n",
        "\n",
        "print(f\" Upper layers (classification):\")\n",
        "print(f\"  - Need to adapt quickly to changing features\")\n",
        "print(f\"  - Adam's adaptive learning rates help fine-tune classification\")\n",
        "print(f\"  - Momentum in gradients helps escape local minima\")\n",
        "# Model analysis\n",
        "print(f\"\\n\" + \"=\"*50)\n",
        "print(\"MODEL ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Get some predictions for analysis\n",
        "test_sample_idx = np.random.choice(len(X_test), 10, replace=False)\n",
        "test_samples = tf.gather(X_test, test_sample_idx)\n",
        "test_labels = tf.gather(y_test, test_sample_idx)\n",
        "predictions = model(test_samples, training=False)\n",
        "predicted_classes = tf.argmax(predictions, axis=1)\n",
        "\n",
        "print(f\"\\nSample Predictions:\")\n",
        "for i in range(len(test_samples)):\n",
        "    true_label = test_labels[i].numpy()\n",
        "    pred_label = predicted_classes[i].numpy()\n",
        "    confidence = tf.reduce_max(predictions[i]).numpy()\n",
        "\n",
        "    status = \"\" if true_label == pred_label else \"\"\n",
        "    print(f\"  {status} True: {class_names[true_label]:>12} | Pred: {class_names[pred_label]:>12} | Conf: {confidence:.3f}\")\n",
        "# Compute confusion matrix for more detailed analysis\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Get all test predictions\n",
        "all_test_predictions = model(X_test, training=False)\n",
        "all_predicted_classes = tf.argmax(all_test_predictions, axis=1).numpy()\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, all_predicted_classes)\n",
        "print(f\"\\nConfusion Matrix Analysis:\")\n",
        "print(f\"Shape: {cm.shape}\")\n",
        "\n",
        "# Per-class accuracy\n",
        "print(f\"\\nPer-Class Accuracy:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    class_accuracy = cm[i, i] / np.sum(cm[i, :])\n",
        "    print(f\"  {class_name:>12}: {class_accuracy:.3f}\")\n",
        "# Training summary\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Dataset: Fashion MNIST\")\n",
        "print(f\"  - Training samples: {len(X_train):,}\")\n",
        "print(f\"  - Validation samples: {len(X_valid):,}\")\n",
        "print(f\"  - Test samples: {len(X_test):,}\")\n",
        "print(f\"  - Classes: {len(class_names)}\")\n",
        "\n",
        "print(f\"\\nModel Architecture:\")\n",
        "print(f\"  - Total parameters: {model.count_params():,}\")\n",
        "print(f\"  - Lower layers: Feature extraction (Dense 128 + Dense 64)\")\n",
        "print(f\"  - Upper layers: Classification (Dense 32 + Dense 10)\")\n",
        "\n",
        "print(f\"\\nTraining Configuration:\")\n",
        "print(f\"  - Custom training loop with dual optimizers\")\n",
        "print(f\"  - Lower layers: SGD (lr=0.01, momentum=0.9)\")\n",
        "print(f\"  - Upper layers: Adam (lr=0.001)\")\n",
        "print(f\"  - Batch size: {batch_size}\")\n",
        "print(f\"  - Epochs: {epochs}\")\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"  - Training accuracy: {history['train_accuracy'][-1]:.4f}\")\n",
        "print(f\"  - Validation accuracy: {history['val_accuracy'][-1]:.4f}\")\n",
        "print(f\"  - Test accuracy: {final_test_acc:.4f}\")\n",
        "print(f\"  - Training loss: {history['train_loss'][-1]:.4f}\")\n",
        "print(f\"  - Validation loss: {history['val_loss'][-1]:.4f}\")\n",
        "print(f\"  - Test loss: {final_test_loss:.4f}\")\n",
        "# Technical achievements\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"TECHNICAL ACHIEVEMENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\" Implemented complete custom training loop\")\n",
        "print(\" Used different optimizers for different model parts\")\n",
        "print(\" Real-time progress tracking with metrics\")\n",
        "print(\" Proper batch processing and data shuffling\")\n",
        "print(\" Validation evaluation after each epoch\")\n",
        "print(\" TensorFlow Functions for performance (@tf.function)\")\n",
        "print(\" Persistent gradient tapes for multiple optimizer updates\")\n",
        "print(\" Comprehensive model evaluation and analysis\")\n",
        "print(\" Training history visualization\")\n",
        "print(\" Confusion matrix and per-class accuracy analysis\")\n",
        "# Key insights\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"KEY INSIGHTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"1. Multi-Optimizer Training:\")\n",
        "print(\"   - Different layers can benefit from different optimization strategies\")\n",
        "print(\"   - Feature extraction layers: stable learning (SGD + momentum)\")\n",
        "print(\"   - Classification layers: adaptive learning (Adam)\")\n",
        "\n",
        "print(\"\\n2. Custom Training Loop Benefits:\")\n",
        "print(\"   - Full control over training process\")\n",
        "print(\"   - Ability to implement research algorithms\")\n",
        "print(\"   - Fine-grained monitoring and debugging\")\n",
        "print(\"   - Flexible gradient processing\")\n",
        "\n",
        "print(\"\\n3. Performance Considerations:\")\n",
        "print(\"   - @tf.function for training steps improves performance\")\n",
        "print(\"   - Persistent gradient tapes needed for multiple optimizers\")\n",
        "print(\"   - Batch processing essential for memory efficiency\")\n",
        "print(\"   - Progress tracking helps monitor training stability\")\n",
        "\n",
        "print(\"\\n4. Fashion MNIST Specific:\")\n",
        "print(\"   - Image classification with 10 clothing categories\")\n",
        "print(\"   - Relatively simple dataset, good for demonstrating techniques\")\n",
        "print(\"   - Clear performance improvements visible in training curves\")\n",
        "print(\"   - Per-class accuracy reveals model strengths/weaknesses\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"EXERCISE 13 COMPLETE!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chapter_summary"
      },
      "source": [
        "## Chapter 12 Summary: Custom Models and Training with TensorFlow\n",
        "\n",
        "This comprehensive exploration of Chapter 12 has covered the essential aspects of customizing TensorFlow components and training procedures. Here's a complete summary of what we've learned:\n",
        "\n",
        "###  Key Concepts Mastered\n",
        "\n",
        "#### 1. **TensorFlow Architecture and Fundamentals**\n",
        "- **Hierarchical structure**: High-level APIs (tf.keras)  Low-level Python API  C++ operations  Hardware kernels\n",
        "- **Core features**: GPU support, distributed computing, JIT compilation, portable graphs, autodiff\n",
        "- **Tensor operations**: Mathematical foundation with multidimensional arrays, type safety, and NumPy interoperability\n",
        "\n",
        "#### 2. **Custom Loss Functions**\n",
        "- **Mathematical foundation**: Understanding different loss functions (MSE, MAE, Huber)\n",
        "- **Implementation approaches**: Simple functions vs. class-based implementations\n",
        "- **Huber loss**: $\\mathcal{L}_{\\delta}(y, \\hat{y}) = \\begin{cases} \\frac{1}{2}(y - \\hat{y})^2 & \\text{if } |y - \\hat{y}| \\leq \\delta \\\\ \\delta |y - \\hat{y}| - \\frac{1}{2}\\delta^2 & \\text{otherwise} \\end{cases}$\n",
        "- **Serialization**: Proper model saving/loading with custom components\n",
        "\n",
        "#### 3. **Custom Metrics**\n",
        "- **Stateless vs. streaming metrics**: When to use each approach\n",
        "- **Streaming metrics**: Essential for metrics like precision that can't be simply averaged\n",
        "- **Mathematical accuracy**: $\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ requires state accumulation\n",
        "\n",
        "#### 4. **Custom Layers**\n",
        "- **Layer types**: Stateless (Lambda), stateful (trainable parameters), dynamic (training-dependent)\n",
        "- **Dense layer implementation**: $\\mathbf{y} = \\sigma(\\mathbf{x} \\mathbf{W} + \\mathbf{b})$\n",
        "- **Layer normalization**: $\\text{LayerNorm}(\\mathbf{x}) = \\boldsymbol{\\alpha} \\odot \\frac{\\mathbf{x} - \\boldsymbol{\\mu}}{\\boldsymbol{\\sigma} + \\epsilon} + \\boldsymbol{\\beta}$\n",
        "- **Multi-input/output layers**: Complex architectures with branching\n",
        "\n",
        "#### 5. **Custom Models**\n",
        "- **Model vs. layer distinction**: Complete architectures vs. reusable components\n",
        "- **Residual connections**: $\\mathbf{y} = \\mathcal{F}(\\mathbf{x}) + \\mathbf{x}$ for gradient flow improvement\n",
        "- **Internal losses**: Reconstruction losses and auxiliary objectives\n",
        "- **Subclassing API**: Full control over model architecture and behavior\n",
        "\n",
        "#### 6. **Automatic Differentiation**\n",
        "- **Mathematical foundation**: Chain rule implementation $\\frac{df}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx}$\n",
        "- **Reverse-mode autodiff**: Efficient for neural networks (many parameters, few outputs)\n",
        "- **GradientTape**: Persistent tapes, watching tensors, higher-order derivatives\n",
        "- **Custom gradients**: Numerical stability improvements with `@tf.custom_gradient`\n",
        "\n",
        "#### 7. **Custom Training Loops**\n",
        "- **Use cases**: Multiple optimizers, custom gradient processing, research algorithms\n",
        "- **Mathematical framework**: $\\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_t - \\eta \\nabla_{\\boldsymbol{\\theta}} \\mathcal{L}$\n",
        "- **Implementation details**: Batch processing, metrics tracking, progress monitoring\n",
        "- **Multi-optimizer training**: Different optimizers for different model components\n",
        "\n",
        "#### 8. **TensorFlow Functions and Graph Optimization**\n",
        "- **AutoGraph process**: Source code analysis  control flow conversion  symbolic execution\n",
        "- **Performance benefits**: Graph optimization, parallelization, memory efficiency\n",
        "- **Function rules**: TensorFlow operations, variable creation, control flow requirements\n",
        "- **Dynamic vs. static**: When to use eager execution vs. graph mode\n",
        "\n",
        "###  Practical Implementations\n",
        "\n",
        "#### **Layer Normalization**\n",
        "- Complete implementation matching Keras functionality\n",
        "- Proper weight initialization and serialization\n",
        "- Mathematical verification and testing\n",
        "\n",
        "#### **Fashion MNIST Training**\n",
        "- Custom training loop with dual optimizers\n",
        "- Real-time progress tracking and validation\n",
        "- Comprehensive model evaluation and analysis\n",
        "- Performance comparison and insights\n",
        "\n",
        "###  Mathematical Foundations\n",
        "\n",
        "#### **Neural Network Operations**\n",
        "- **Linear transformation**: $\\mathbf{y} = \\mathbf{x} \\mathbf{W} + \\mathbf{b}$\n",
        "- **Normalization**: $\\hat{\\mathbf{x}} = \\frac{\\mathbf{x} - \\boldsymbol{\\mu}}{\\boldsymbol{\\sigma} + \\epsilon}$\n",
        "- **Loss functions**: Various formulations for different objectives\n",
        "- **Gradient descent**: $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\eta \\nabla\\mathcal{L}$\n",
        "\n",
        "#### **Advanced Concepts**\n",
        "- **Residual learning**: Skip connections for deep networks\n",
        "- **Multi-objective optimization**: Weighted loss combinations\n",
        "- **Streaming metrics**: Stateful computation across batches\n",
        "- **Custom gradient computation**: Numerical stability improvements\n",
        "\n",
        "###  Performance Optimizations\n",
        "\n",
        "#### **TensorFlow Functions**\n",
        "- **Graph compilation**: 2-10x performance improvements\n",
        "- **Memory efficiency**: Optimized computation graphs\n",
        "- **Parallelization**: Automatic operation scheduling\n",
        "\n",
        "#### **Training Efficiency**\n",
        "- **Vectorized operations**: Avoid explicit loops when possible\n",
        "- **Batch processing**: Memory and computation efficiency\n",
        "- **Mixed precision**: Future consideration for even better performance\n",
        "\n",
        "###  Best Practices Established\n",
        "\n",
        "#### **Code Organization**\n",
        "- **Separation of concerns**: Layers vs. models vs. training logic\n",
        "- **Reusability**: Design components for multiple use cases\n",
        "- **Serialization**: Always implement proper configuration methods\n",
        "\n",
        "#### **Development Workflow**\n",
        "- **Start simple**: Use high-level APIs first, customize when needed\n",
        "- **Profile performance**: Measure before optimizing\n",
        "- **Test thoroughly**: Verify custom implementations against reference\n",
        "\n",
        "#### **Production Considerations**\n",
        "- **Model persistence**: Proper saving/loading of custom components\n",
        "- **Performance**: Static graphs for deployment, dynamic for development\n",
        "- **Monitoring**: Comprehensive metrics and logging\n",
        "\n",
        "###  When to Use Custom Components\n",
        "\n",
        "#### **Custom Losses/Metrics**\n",
        "- Research objectives not covered by standard functions\n",
        "- Domain-specific requirements\n",
        "- Multi-objective optimization\n",
        "\n",
        "#### **Custom Layers/Models**\n",
        "- Novel architectures from research papers\n",
        "- Specialized operations for your domain\n",
        "- Performance-critical custom operations\n",
        "\n",
        "#### **Custom Training Loops**\n",
        "- Research algorithms requiring fine control\n",
        "- Multi-model training (GANs, meta-learning)\n",
        "- Specialized hardware or memory constraints\n",
        "\n",
        "###  Advanced Topics for Further Study\n",
        "\n",
        "1. **Custom Operations in C++**: For maximum performance\n",
        "2. **Distributed Training**: Custom strategies for multi-GPU/multi-node\n",
        "3. **Model Quantization**: Custom quantization schemes\n",
        "4. **Advanced Optimizers**: Implementing cutting-edge optimization algorithms\n",
        "5. **Neural Architecture Search**: Automated architecture discovery\n",
        "\n",
        "This chapter has provided a comprehensive foundation for customizing every aspect of TensorFlow models and training procedures. The combination of theoretical understanding, practical implementations, and performance considerations prepares you for tackling advanced machine learning challenges that require going beyond standard APIs."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}